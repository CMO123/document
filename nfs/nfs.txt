现在不想系统的看nfs, 就一点一点的写点零星的理解

在看inode, 这里介绍nfs作为一个客户端对inode的支持，首先是nfs_fhget(super_block, nfs_fh, nfs_fattr),根据nfs_fh和nfs_fattr在super_block中创建一个nfs_inode, (哪里有创建代码?) 然后根据nfs_fh和nfs_fattr初始化它. 还有无效和删除inode
    * nfs4_evict_inode(inode) 这里面包含pagecache, data, layout, delegation, 还有间接acl_cache, access

inode管理的数据应该可以和nfs_inode数据结构配合说一下:
* fileid / nfs_fh
* flags
* cache_validity , read_cache_jiffies, attrtimeo, ..
* access_cache, access_cache_entry_lru, 
* nfs_page_tree  (脏页,而没有写回的页)
* nfs4_cached_acl
* open_files, silly_count
* open_states, nfs_delegation
* pnfs_layout_hdr

这里管理的数据包括以下:
* cache: 
    数据缓存的时间等(nfs_zap_caches_locked(inode)), 这里缓存的包括attr, data, atime, access, acl, pagecache
    nfs_revalidate_inode(nfs_server, inode) 重新验证inode是否有效
    nfs_update_inode(inode, nfs_fattr) 这里修改nfs_fattr中对应的inode属性信息, 但好像没有数据相关的. 这里大量的操作在修改nfs_inode->cache_validaty. 为何这里没有触动数据的修改?  这里还有nfs_inode->flags的NFS_INO_REVAL_PAGECACHE,这是干什么的? 还有NFS_INO_INVALID_DATA, 这里data和pagecache还不一回事?

* acl: 
    这个非常简单， 因为这里没有使用,在其他操作中可能会使用

* attr: 
    设置和修改attr, 每次都需要调用SETATTR/GETATTR operation? 

* page cache: 
    在改变文件大小时，刷新address_space
    nfs_invalidate_mapping(inode, address_space) 把address_space释放掉? 还有nfs_revalidate_mapping(inode, address_space)对上面函数封装，它好像只在file/dir操作中使用.

* lock context: 
    nfs lock使用nfs_lock_context表示锁的使用者. 下面可看出这里不是一般的文件锁

* access :
    这是一个比较新鲜的东西,它管理nfs_inode->access_cache, 这里是nfs_access_entry(这个directory专用?)  nfs_access_entry就是对rpc_cred和mode的包装, 
    alloc_nfs_open_context(dentry, mode) 
    nfs_open_context中还包含nfs_lock_context, 这个应该不是普通的文件锁,还是每个锁都有一个nfs_open_context? 还有它使用nfs4_state. file->private_data指向nfs_open_context. nfs_inode->open_files是一个nfs_open_context的链表.

    这里插入一个流程性的说明:
    nfs_release(inode, file) 这应该是在syscall中调用
    > nfs_file_clear_open_context(file) 清楚file带的nfs_open_context
     > __put_nfs_open_context(nfs_open_context, flag) 释放nfs_open_context
      > nfs_sb_deactive(super_block) 这里要释放对super_block的使用,同样也是对nfs_server的释放
       > deactive_super(super_block) 当nfs_server->active变为0时,才有这个操作,当然在创建nfs_open_context时使用对应的操作
        > deactivate_super(super_block) 这里到了/fs/super.c中,释放super_block. 减小super_block->s_active, 如果它为1,则继续: down_write(s_umount); 
         > deactivate_locked_super(super_block) 这里执行释放super_block的操作,减小super_block->s_active, 如果减为0, 释放super_block: kill_sb, put_super等等.
    这个流程说明了如果在关闭一个文件时，可能导致文件系统的卸载. (对于 umount -l的情况下可使用)


* fscache 这个就不说了

最后发现nfs模块的初始化函数就在这里，好器重inode..., 这里面的各种cache还是够把人弄晕的.看了这些，好像对inode理解一些，但还是缺少一些inode的系统了解,还有dcache/namei的理解.

忽然想起来pnfs如果要挂载data server,把mount放到哪里呢?
file.c
这里面应该是实现file相关的syscall调用的函数,实际上就是一些包装,但对于read/write还是有些考究. 实现了file_operations nfs_file_operations, address_space_operations nfs_file_aops, 当然还有nfs4_file_inode_operations, 不过都使用一般nfs函数.
nfs_write_begin/nfs_write_end 对write.c中包装, 这里还有read/modify/write和modify/write/read的操作说明，什么意思呢? 考虑到写要先读数据，改了之后写回.可以直接写回，然后再读没有写覆盖的数据? 读改写是把数据读出来，再写入，否则不读.  这里没有搬数据操作，只有设置page的标志,启动后端的写数据操作.

这里还有大量的IO操作里不顺，为何都看了page的相关文件操作，还是不能理顺呢? 难道非要把所有的page操作都看完吗?


dir.c
然后是dir操作, 复杂，不看了.
