* nfs4filelayoutdev.c

** stripetype4 
   #+BEGIN_SRC 
	STRIPE_SPARSE = 1,
	STRIPE_DENSE = 2   
   #+END_SRC

** nfs4_pnfs_ds_addr
   #+BEGIN_SRC 
	struct sockaddr_storage	da_addr;
	size_t			da_addrlen;
	struct list_head	da_node;  /* nfs4_pnfs_dev_hlist dev_dslist */
	char			*da_remotestr;	/* human readable addr+port */   
   #+END_SRC

** nfs4_pnfs_ds 
   #+BEGIN_SRC 
	struct list_head	ds_node;  /* nfs4_pnfs_dev_hlist dev_dslist */
	char			*ds_remotestr;	/* comma sep list of addrs */
	struct list_head	ds_addrs;
	struct nfs_client	*ds_clp;
	atomic_t		ds_count;
	unsigned long		ds_state;
#define NFS4DS_CONNECTING	0	/* ds is establishing connection */   
   #+END_SRC

** nfs4_file_layout_dsaddr
   #+BEGIN_SRC 
	struct nfs4_deviceid_node	id_node;
	u32				stripe_count;
	u8				*stripe_indices;
	u32				ds_num;
	struct nfs4_pnfs_ds		*ds_list[1];   
   #+END_SRC

** nfs4_filelayout_segment
   #+BEGIN_SRC 
	struct pnfs_layout_segment generic_hdr;
	u32 stripe_type;
	u32 commit_through_mds;
	u32 stripe_unit;
	u32 first_stripe_index;
	u64 pattern_offset;   //它所表示的范围的开始文件偏移
	struct nfs4_file_layout_dsaddr *dsaddr; /* Point to GETDEVINFO data */
	unsigned int num_fh;
	struct nfs_fh **fh_array;   
   #+END_SRC

** _same_data_server_addrs_locked(list_head dsaddrs1, dsaddrs2)
   - list_head是nfs4_pnfs_ds->ds_addrs, 里面应该是nfs4_pnfs_ds_addr
   - 遍历2个链表, 比较nfs4_pnfs_ds_addr->da_addr 
   > same_sockaddr(sockaddr, nfs4_pnfs_ds_addr->da_addr)

** _data_server_lookup_locked(list_head)
   - nfs4_data_server_cache链表中是所有的nfs4_pnfs_ds
   - 遍历链表, 查找nfs4_pnfs_ds 
   > _same_data_server_addrs_locked(nfs4_pnfs_ds->ds_addr, list_head)

** nfs4_ds_connect(nfs_server, nfs4_pnfs_ds)
   - 建立对应nfs4_pnfs_ds里面ip地址的nfs_client  
   - 遍历nfs4_pnfs_ds->ds_addr链表中的nfs4_pnfs_ds_addr 
   > nfs4_set_ds_client(nfs_server->nfs_client, nfs4_pnfs_ds_addr->da_addr, da_addrlen, IPOROTO_TCP, datasever_timeo, dataserver_retrans)
   - 只要有一个成功,就可以返回
   - 建立session, 或者说等待创建完成
   > nfs4_init_ds_session(nfs_client, nfs_server->nfs_client->cl_lease_time)
   - 把创建的nfs_client给nfs4_pnfs_ds

   - 对于nfs4.1, nfs_client的过程包括
   - 创建rpc_clnt, 只要cred/ip
   - 建立exchange_id, 设置nfs_client->cl_state的NFS4CLNT_LEASE_CONFIRM, 虽然会检查trunk,但只是重用nfs_client
   - 然后创建session过程. 在创建nfs_client时设置NFS4CLNT_LEASE_EXPIRED, 创建session就是启动state manager任务,让他处理NFS4CLNT_LEASE_EXPIRED

** destroy_ds(nfs4_pnfs_ds)
   - 实现是nfs_client 
   > nfs_put_client(nfs4_pnfs_ds->nfs_client)
   - 释放nfs4_pnfs_ds->ds_addrs中的nfs4_pnfs_ds_addr
   - 然后是nfs4_pnfs_ds->ds_remotestr, 应该是rpc消息中返回的

** nfs4_fl_free_deviceid(nfs4_file_layout_dsaddr)
   - 在layoutget中获取的,在pnfs_layout_segment中使用,表示多个ds
   - 对应一个nfs4_deviceid_node
   - 遍历nfs4_file_layout_dsaddr->ds_list指针数组,里面是nfs4_pnfs_ds 
   - 减小nfs4_pnfs_ds->ds_count计数,如果为0, 释放 
   > destroy_ds(nfs4_pnfs_ds)
   - 释放其他资源, 没有针对nfs4_deviceid_node的释放?

** nfs_pnfs_remotestr(list_head, gfp_flags)
   - list_head中是nfs4_pnfs_ds_addr, 把这些ip地址格式化到一个字符串
   - {nfs4_pnfs_ds_addr->da_remotestr, .}

** nfs4_pnfs_ds_add(list_head, gfp_flags)
   - 根据nfs4_pnfs_ds_addr链表,创建nfs4_pnfs_ds
   - 先准备remotestr 
   > nfs4_pnfs_remotestr(list_head, gfp_flags)
   - 然后根据list_head查找已有的nfs4_pnfs_ds 
   > _data_server_lookup_locked(list_head)
   - 如果找不到,使用新创建的
   - 把它放到全局nfs4_data_server_cache链表中

** decode_ds_addr(net, xdr_stream, gfp_flags)
   - 解析getdeviceid中的一个ip地址, 转化为nfs4_pnfs_ds_addr
   - 格式应该是[tcp|tcp6]ip.port

** pnfs_device
   #+BEGIN_SRC 
	struct nfs4_deviceid dev_id;
	unsigned int  layout_type;
	unsigned int  mincount;
	unsigned int  maxcount;	/* gdia_maxcount */
	struct page **pages;
	unsigned int  pgbase;
	unsigned int  pglen;	/* reply buffer length */   
   #+END_SRC

** xdr 
   #+BEGIN_SRC 
   struct netaddr4 {
           /* see struct rpcb in RFC 1833 */
           string na_r_netid<>; /* network id */
           string na_r_addr<>;  /* universal address */
   };

   typedef netaddr4 multipath_list4<>;
   
   struct nfsv4_1_file_layout_ds_addr4 {
           uint32_t  nflda_stripe_indices<>  数组大小就是stripe count
           multipath_list4 nflda_multipath_ds_list<>  这是二维数组,第一维是数据分布，第二维是数据分发备份.
   }
   
   struct device_addr4 {
           layouttype4             da_layout_type;
           opaque                  da_addr_body<>;
   };

   #+END_SRC

** decode_device(inode, pnfs_device, gfp_t)
   - 处理get_deviceid的数据, 在pnfs_device->pages里面, 应该是上面的da_addr_body数据
   - 先处理nflda_stripe_indices数组
   - 创建nfs4_file_layout_dsaddr, 里面的deviceid已经解析出来
   - 初始化nfs4_deviceid_node, 它关联nfs_client, nfs4_deviceid, pnfs_layoutdriver_type
   > nfs4_init_deviceid_node(nfs4_file_layout_dsaddr->nfs4_deviceid_node, nfs_client->pnfs_curr_ld, nfs_client, pnfs_device->nfs4_deviceid)
   - 开始解析nflda_multipath_ds_list, 2维数组解析
   > decode_ds_addr(net, p, gfp_flags)
   - 把list_head放到nfs4_file_layout_dsaddr->ds_list[i]中
   - 这里的list_head链表表示数据的多条链路备份
   > nfs4_pnfs_ds_add(list_head, gfp_flags)
  
** decode_and_add_device(inode, pnfs_device, gfp_flags)
   - 解析pnfs_device数据, 获取nfs4_file_layout_dsaddr
   > decode_device(inode, pnfs_device, gfp_flags)
   - 构造完成后,放到hash表中
   > nfs4_insert_deviceid_node(nfs4_file_layout_dsaddr->nfs4_deviceid_node)

** filelayout_get_device_info(inode, nfs4_deviceid, rpc_cred, gfp_flags)
   - 获取nfs4_deviceid对应的信息,放到nfs4_file_layout_dsaddr中
   - 使用pnfs_device管理rpc请求使用的参数
   - 发送rpc请求 
   > nfs4_proc_getdeviceinfo(nfs_server, pnfs_device, rpc_cred)
   - 处理结果 
   > decode_and_add_device(inode, pnfs_device, gfp_flags)

** nfs4_fl_put_deviceid(nfs4_file_layout_dsaddr)
   - 使用pnfs_layoutdriver_type->free_deviceid_node回调函数释放
   > nfs4_put_deviceid_node(nfs4_file_layout_dsaddr->nfs4_deviceid_node)
   - 通过nfs4_deviceid_node管理他的释放和创建

** nfs4_fl_calc_j_index(pnfs_layout_segment, offset)
   - offset是文件偏移?
   - 获取segment内部偏移
   > tmp = offset - nfs4_filelayout_segment->stripe_unit
   - 计算stripe的索引
   > tmp /= nfs4_filelayout_segment->stripe_unit + nfs4_filelayout_segment->first_stripe_index
   - 计算在stripe index数组的索引 
   > tmp /= nfs4_filelayout_segment->stripe_count

** nfs4_fl_calc_ds_index(pnfs_layout_segment, j)
   - 获取nfs4_filelayout_segment->nfs4_file_layout_dsaddr->stripe_indices[j]
   - stripe对应的在ds addr数组中的索引

** nfs4_fl_select_ds_fh(pnfs_layout_segment, j)
   - 在第j个stripe index中,使用的nfs_fh
   - 如果是STRIPE_SPARSE
   - 所有的ds使用相同的nfs_fh, nfs4_filelayout_segment->num_fh == 1, 只有一个文件
   - 或者一个stripe index指向的多路ds使用同样的nfs_fh
   > nfs4_fl_calc_ds_index(nfs4_filelayout_segment, j)
   - 否则,每个ds使用自己的nfs_fh? 
   > nfs4_filelayout_segment->fh_array[j]

** nfs4_wait_ds_connect(nfs4_pnfs_ds)
   - 等待nfs4_pnfs_ds->ds_state的NFS4DS_CONNECTING??

** nfs4_clear_ds_conn_bit(nfs4_pnfs_ds)
   - nfs4_pnfs_ds存储一个stripe的数组
   - 虽然它有多路ds, 但只有其中的一个
   - 清除nfs4_pnfs_ds->ds_state的NFS4DS_CONNECTING, 唤醒等待的任务
   > wake_up_bit(&ds->ds_state, NFS4DS_CONNECTING)

** nfs4_fl_prepare_ds(pnfs_layout_segment, ds_idx)
   - ds_idx是stripe的索引,对应nfs4_filelayout_segment->nfs4_pnfs_ds指针数组
   - 检查nfs4_filelayout_segment的nfs4_deviceid_node是否不可用 
   > filelayout_test_devid_unavailable(nfs4_deviceid_node)
   - 如果nfs4_pnfs_ds->nfs_client有效,直接使用
   - 否则创建它
   - 设置nfs4_pnfs_ds->ds_state的NFS4DS_CONNECTING
   - 如果已经设置,别人在创建,等待nfs4_pnfs_ds 
   > nfs4_wait_ds_connect(nfs4_pnfs_ds)
   - 否则创建nfs_client 
   > nfs4_ds_connect(nfs_server, nfs4_pnfs_ds)
   - 如果失败, 设置整个nfs4_deviceid_node无效??
   > nfs4_mark_deviceid_unavailable(nfs4_deviceid_node)

* nfs4filelayout.c 

** filelayout_get_dense_offset(nfs4_filelayout_segment, offset)
   - offset是文件偏移
   - 如果是STRIPE_SPARSE, 每个ds使用自己的nfs_fh/文件,因为他支持空洞,所以数据的文件偏移不用转换
   - 如果是STRIPE_DENSE, 在一个ds上的数据在文件中的位置是压缩的
   - 把offset对应的偏移转换为ds中文件的偏移
   > offset -= nfs4_filelayout_segment->pattern_offset
   - 计算stripe的索引
   - stripe_no = offset /= (stripe_unit * stripe_count)
   - 计算总的偏移
   > stripe_no * stripe_unit + offset % stripe_unit
   - 一个stripe包含stripe_count个块,每个块大小是stripe_unit
   - 每个块对应一个nfs4_pnfs_ds,  nfs4_file_layout_dsaddr->stripe_count就是stripe中的块数

** filelayout_get_dserver_offset(pnfs_layout_segment, loff_t)
   - 如果是STRIPE_DENSE
   > filelayout_get_dense_offset(pnfs_layout_segment, offset)
   - 否则不改变offset

** filelayout_reset_write(nfs_write_data)
   - 设置nfs_pgio_header->flags的NFS_IOHDR_REDO
   - 如果第一次设置,这里发送普通的读操作
   > pnfs_write_done_resend_to_mds(inode, nfs_pgio_header->list_head, nfs_pgio_completion_ops, nfs_direct_req)
   - 在rpc的rpc_call_prepare/rpc_call_done的错误处理中使用

** filelayout_reset_read(nfs_read_data)
   - 和上面相似 

** filelayout_fenceme(inode, pnfs_layout_hdr)
   - 释放inode的pnfs资源, pnfs_layout_hdr->plh_flags应该有NFS_LAYOUT_RETURN
   - 去掉这个标志,如果原来有, 发送layoutreturn请求 
   > pnfs_return_layout(inode)

** filelayout_async_handle_error(rpc_task, nfs4_state, nfs_client, pnfs_layout_segment)
   - 处理返回的错误, rpc_task->tk_status
   - NFS4ERR_DELEG_REVOKED / NFS4ERR_ADMIN_REVOKED / NFS4ERR_BAD_STATEID, delegation失效
   > nfs_remove_bad_delegation(nfs4_state->nfs_inode)
   - 启动nograce的状态恢复, 直接释放delegation
   - 如果是NFS4ERR_OPENMODE, 直接nograce恢复这个nfs4_state 
   - 这里的恢复使用的nfs_client是inode对应的,mds,而不是ds
   - nfs4_schedule_stateid_recovery(nfs_server, nfs4_state)
   - 如果是NFS4ERR_EXPIRED
   - 对于nfs4_stateid有效,启动nograce恢复,和上面一样
   - 对于nfs4_stateid无效,启动lease恢复, NFS4CLNT_CHECK_LEASE
   > nfs4_schedule_lease_recovery(nfs_client)
   - 如果是NFS4ERR_BADSESSION/NFS4ERR_BADSLOT等, 重新创建session 
   > nfs4_schedule_session_recovery(nfs4_session, tk_status)
   - 如果是NFS4ERR_PNFS_NO_LAYOUT/STALE/ISDIR等,释放layout, 使用普通的nfs
   > pnfs_destroy_layout(inode)
   - 还要唤醒其他任务?
   > rpc_wake_up(nfs4_slot_table->slot_tbl_waitq)
   - 如果是ECONNREFUSED/EHOSTDOWN等rpc错误, 同样使用普通nfs
   - 设置nfs4_deviceid_node的无效, 设置pnfs_layout_hdr->plh_flags的NFS_LAYOUT_RETURN
   - 谁会释放layout??
   > nfs4_mark_deviceid_unavailable(nfs4_deviceid_node)
   
** filelayout_read_done_cb(rpc_task, nfs_read_data)
   - 处理nfs_read_data的错误 
   > filelayout_async_handle_error(rpc_task, nfs_read_data->nfs4_readargs->nfs_open_context->nfs4_state, nfs_client, nfs_pgio_header->pnfs_layout_segment)
   - 上面的nfs_client是ds的
   - 如果上面返回-NFS4ERR_RESET_TO_MDS, 调用普通nfs操作 
   > filelayout_reset_read(nfs_read_data)
   - 如果返回-EAGAIN, 重新发送rpc, 重新从rpc_call_prepare开始
   > rpc_reset_call_prepare(rpc_task)

   - 读结果处理的3层回调
   - 在read rpc_task的rpc_call_done 
   > nfs_readpage_result_common(rpc_task, nfs_read_data)
   > nfs_readpage_result(rpc_task, nfs_read_data)
   - 使用nfs_rpc_ops的回调read_done(rpc_task, nfs_read_data)
   > nfs4_read_done
   - 使用nfs_read_data->read_done_cb
   > filelayout_read_done_cb(rpc_task, nfs_read_data)
 
** filelayout_set_layoutcommit(nfs_write_data)
   - layoutcommit可以发送给mds, 也可以发送给ds?
   - 如果nfs4_filelayout_segment->commit_through_mds !=0 或者写返回的是NFS_FILE_SYNC
   - 表示不需要sync/commit
   - 否则,设置inode/pnfs_layout_segment的标志
   > pnfs_set_layoutcommit(nfs_write_data)

** filelayout_test_devid_unavailable(nfs4_deviceid_node)
   - 检查layout是否失效
   - nfs4_deviceid_node->flags的NFS_DEVICEID_INVALID
   > filelayout_test_devid_unavailable(nfs4_deviceid_node)
   - 还有nfs4_deviceid_node->flags的NFS_DEVICEID_UNAVAILABLE
   > nfs4_test_deviceid_unavailable(nfs4_deviceid_node)

** filelayout_reset_to_mds(pnfs_layout_segment)
   - 检查pnfs_layout_segment的nfs4_deviceid_node 
   > filelayout_test_devid_unavailable(nfs4_deviceid_node)

** filelayout_read_prepare(rpc_task, data)
   - 处理nfs_read_data的请求
   - 检查nfs_open_context->flags的NFS_CONTEXT_BAD, 直接返回-EIO
   - 检查layout的有效性 
   > filelayout_reset_to_mds(nfs_read_data->nfs_pgio_header->pnfs_layout_segment)
   - 如果无效,使用普通nfs方式 
   > filelayout_reset_read(nfs_read_data)
   > rpc_exit(rpc_task, 0)
   - 设置nfs_read_data->read_done_cb = filelayout_read_done_cb
   - 处理错误rpc的错误
   - 处理sequence, 这里的nfs4_session是ds的
   > nfs41_setup_sequence(nfs4_session, nfs4_sequence_args, res, rpc_task)
   - 选一个可用的nfs4_stateid, 和普通的nfs一样
   > nfs4_set_rw_stateid(nfs4_readargs->nfs4_stateid, nfs_open_context, nfs_lock_context, FMODE_READ)

** filelayout_read_call_done(rpc_task, nfs_read_data)
   - 如果nfs_pgio_header->flags有NFS_IOHDR_REDO, 而且返回结果rpc_task->tk_status == 0
   - 说明使用普通nfs方式完成,可直接返回
   - 否则调用原来的rpc回调 
   > nfs_pgio_header->mds_ops->rpc_call_done(rpc_task, nfs_read_data)

** filelayout_read_count_stats(rpc_task, nfs_read_data)
   > rpc_count_iostats(rpc_task, rpc_iostats)

** filelayout_read_release(data)
   - 这里只是包装普通nfs的rpc_call_release
   - 释放layout
   - 检查是否return layout
   > filelayout_fenceme(inode, pnfs_layout_hdr)
   - 释放ds nfs_client 
   > nfs_put_client(nfs_read_data->ds_clp)
   - 真正的释放 
   > nfs_read_data->nfs_pgio_header->mds_ops->rpc_release(nfs_read_data)

** 总结 
   - 上面3个组成一个rpc_call_ops filelayout_read_call_ops, 应该放到nfs_rpc_ops

** filelayout_write_done_cb(rpc_task, nfs_write_data)
   - 处理rpc的错误 
   > filelayout_async_handle_error(rpc_task, nfs_open_context->nfs4_state, nfs_write_data->ds_clp, pnfs_layout_segment)
   - 如果返回NFS4ERR_RESET_TO_MDS, 使用普通nfs方式
   > filelayout_reset_write(nfs_write_data)
   - 如果是-EAGAIN, 重启rpc 
   > rpc_reset_call_prepare(rpc_task)
   - 设置commit标志 
   > filelayout_set_layoutcommit(nfs_write_data)

   - 这个函数像read一样,也是3层回调实现

** prepare_to_resend_writes(nfs_commit_data)
   - nfs_commit_data用来提交commit请求
   - 修改nfs_commit_data->nfs_writeverf->verifier->data[0] ++
   - 保证它和原来write返回的不一样

** filelayout_commit_done_cb(rpc_task, nfs_commit_data)
   - 处理commit的rpc结果? 
   > filelayout_async_handle_error(rpc_task, NULL, nfs_client, nfs_write_data->pnfs_layout_segment)
   - 如果是NFS4ERR_RESET_TO_MDS, 修改verifier, 重新发送写操作?? 
   > prepare_to_resend_writes(nfs_write_data)
   - 如果是EGAGIN, 重启rpc 
   > rpc_restart_call_prepare(rpc_task)

** filelayout_write_prepare(rpc_task, nfs_write_data)
   - 检查nfs_open_context->flags的NFS_CONTEXT_BAD, 直接返回-EIO
   - 检查layout的有效性
   > filelayout_reset_to_mds(pnfs_layout_segment)
   - 如果无效,直接使用普通nfs
   > filelayout_reset_to_write(nfs_write_data)
   - 设置sequence/nfs4_slot, 哪里设置的ds nfs_client??
   > nfs41_setup_sequence(nfs_write_data->ds_clp->nfs4_session, ..)
   - 选择nfs4_stateid 
   > nfs4_set_rw_stateid(nfs4_stateid, nfs_open_context, nfs_lock_context, FMODE_WRITE)

** filelayout_write_call_done(rpc_task, data)
   - 和上面read一样
   > nfs_write_data->nfs_pgio_header->mds_ops->rpc_call_done(nfs_write_data)

** filelayout_write_count_stats(rpc_task, data)
   > rpc_count_iostats(rpc_task, rpc_iostats)

** filelayout_write_release(data)
   - 释放nfs_write_data的layout资源 
   > filelayout_fenceme(inode, pnfs_layout_hdr)
   > nfs_put_client(nfs_write_data->ds_clp)
   - nfs_write_data->nfs_pgio_header->mds_ops->rpc_release(nfs_write_data)

** filelayout_write_commit_done(rpc_task, data)
   - 看来commit也是发送给ds
   - 直接回调 
   > nfs_commit_data->mds_ops->rpc_call_done(rpc_task, nfs_commit_data)

** filelayout_commit_count_stats(rpc_task, data)
   - 这个rpc_iostate是mds的nfs_client
   > rpc_count_iostats(rpc_task, rpc_iostats)

** filelayout_commit_release(calldata)
   - 这里回调更多? 
   - 这个回调是什么???
   > nfs_commit_data->completion_ops->completion(nfs_commit_data)
   - 释放pnfs_layout_segment, ds nfs_client
   > nfs_commitdata_release(nfs_commit_data)

** 总结
   - 上面针对write和commit也都有一套rpc_call_ops
   - 还有在nfs_write_data/nfs_commit_data/nfs_read_data中使用的回调函数,在rpc完成后使用

** filelayout_read_pagelist(nfs_read_data)
   - 提交nfs_read_data的rpc请求
   - 首先pnfs使用的资源
   - 选择ds nfs4_pnfs_ds
   - 计算stripe index
   > nfs4_fl_calc_j_index(pnfs_layout_segment, offset)
   - 获取ds index
   > nfs4_fl_calc_ds_index(pnfs_layout_segment, j)
   - 获取nfs4_pnfs_ds
   > nfs4_fl_prepare_ds(pnfs_layout_segment, idx)
   - 如果无法创建nfs4_pnfs_ds, 返回PNFS_NOT_ATTEMPTED
   - 获取nfs_fh 
   > nfs4_fl_select_ds_fh(pnfs_layout_segment, j)
   - 计算文件偏移, 在nfs_readargs->offset
   > filelayout_get_dserver_offset(pnfs_layout_segment, offset)
   - 发起rpc请求 
   > nfs_initiate_read(nfs4_pnfs_ds->nfs_client->rpc_clnt, nfs_read_data, filelayout_read_call_ops, RPC_TASK_SOFTCONN)
   - 如果问题问题,返回PNFS_ATTEMPTED

   - 原来的rpc_call_ops保存在nfs_read_data->mds_ops中, 在doio中已经转移

** filelayout_write_pagelist(nfs_write_data, sync)
   - 这个函数和上面的函数都是pnfs_layoutdriver_type中的回调函数
   - 获取nfs4_pnfs_ds资源
   > nfs4_fl_calc_j_index(pnfs_layout_segment, offset)
   > nfs4_fl_calc_ds_index(pnfs_layout_segment, j)
   > nfs4_fl_prepare_ds(pnfs_layout_segment, idx)
   - 如果无法获取nfs_client, 返回PNFS_NOT_ATTEMPTED
   - 设置nfs_write_data->write_done_cb = filelayout_write_done_cb?
   - read是在rpc_call_prepare中, 这里提前了?
   - 准备nfs_fh/offset 
   > nfs4_fl_select_ds_fh(pnfs_layout_segment, j)
   > filelayout_get_dserver_offset(pnfs_layout_segment, offset)
   - 发送rpc请求 
   > nfs_initiate_write(rpc_clnt, nfs_write_data, filelayout_write_call_ops, sync, RPC_TASK_SOFTCONN)

** filelayout_check_layout(pnfs_layout_hdr, nfs4_filelayout_segment, nfs4_layoutget_res, nfs4_deviceid, gfp_flags)
   - 在layoutget中获取的结构后,检查其有效性?
   - nfs4_layoutget_res->pnfs_layout_range必须是(0, NFS4_MAX_UNIT64)??
   - nfs4_layoutget_res->pattern_offset < pnfs_layout_segment->offset, pattern_offset是segment覆盖的范围
   - stripe_unit 是 PAGE_SIZE倍数
   - 查找缓存的nfs4_deviceid_node, 是否有对应nfs4_deviceid的
   > nfs4_find_get_deviceid(pnfs_layoutdriver_type, nfs_client, nfs4_deviceid)
   - 如果没有, 需要获取deviceinfo, nfs4_file_layout_dsaddr
   > filelayout_get_device_info(pnfs_layout_hdr->inode, nfs4_deviceid, rpc_cred, gfp_flags)
   - 检查nfs4_deviceid_node是否不可使用
   > filelayout_test_devid_unavailable(nfs4_file_layout_dsaddr->nfs4_deviceid_node)
   - nfs4_filelayout_segment->first_stripe_index 不能超过 nfs4_file_layout_dsaddr->stripe_count, stripe的个数
   - 有到了stripe方式
   - 如果使用STRIPE_SPARSE, 所有的ds使用相同的nfs_fh,或者使用自己的nfs_fh
   - nfs4_filelayout_segment->num_fh == nfs4_file_layout_dsaddr->ds_num
   - 如果是STRIPE_DENSE, 一个stripe使用一个nfs_fh
   - nfs4_filelayout_segment->num_fh == nfs4_file_layout_dsaddr->stripe_count
   - nfs4_filelayout_segment->stripe_unit必须是wsize/rsize的倍数

** filelayout_free_fh_array(nfs4_filelayout_segment)
   - 释放nfs_fh数组

** _filelayout_free_lseg(nfs4_filelayout_segment)
   > filelayout_free_fh_array(nfs4_filelayout_segment)
   > kfree(nfs4_filelayout_segment)

** xdr
   #+BEGIN_SRC 


   struct LAYOUTGET4resok {
           bool               logr_return_on_close;
           stateid4           logr_stateid;
           layout4            logr_layout<>;
   };

   const NFL4_UFLG_MASK            = 0x0000003F;
   const NFL4_UFLG_DENSE           = 0x00000001;
   const NFL4_UFLG_COMMIT_THRU_MDS = 0x00000002;
   const NFL4_UFLG_STRIPE_UNIT_SIZE_MASK
                                   = 0xFFFFFFC0;

   typedef uint32_t nfl_util4;
   
   struct nfsv4_1_file_layout4 {
            deviceid4      nfl_deviceid;
            nfl_util4      nfl_util;
            uint32_t       nfl_first_stripe_index;
            offset4        nfl_pattern_offset;
            nfs_fh4        nfl_fh_list<>;
   };

   #+END_SRC

** filelayout_decode_layout(pnfs_layout_hdr, nfs4_filelayout_segment, nfs4_layoutget_res, nfs4_deviceid)
   - 解析layoutget返回的结果
   - 先获取deviceid, 16字节的数据
   - 然后是nfl_util
   - 设置nfs4_filelayout_segment->comit_through_mds, stripe_type, stripe_unit
   - 然后是nfl_first_stripe_index / pattern_offset
   - 然后是nfs_fh数组

** filelayout_free_lseg(pnfs_layout_segment)
   - 释放pnfs_layout_segment
   - 如果iomode == IOMODE_RW, 需要释放commit数据？ 
   - nfs4_filelayout->pnfs_ds_commit_info->buckets???
   > _filelayout_free_lseg(nfs4_filelayout_segment)

** filelayout_alloc_commit_info(pnfs_layout_segment, nfs_commit_info, gfp_t)
   - 在写操作时准备pnfs_ds_commit_info
   - 如果nfs4_filelayout_segment->commit_through_mds !=0, commit发送给mds, 直接返回
   - nfs_commit_info索隐nfs4_filelayout->pnfs_ds_commit_info, 这里就是初始化它
   - 如果nfs_commit_info->pnfs_ds_commit_info->nbuckets !=0, 直接退出, 已经有人使用它
   - 创建pnfs_commit_bucket数组
   - 如果nfs4_filelayout_segment->stripe_type == STRIPE_SPARSE, 每个nfs4_pnfs_ds使用一个, nfs4_file_layout_dsaddr->ds_num
   - 否则一个stripe使用一个, nfs4_file_layout_dsaddr->stripe_count
   - 设置nfs_commit_info->pnfs_ds_commit_info->buckets/nbuckets

** filelayout_alloc_lseg(pnfs_layout_hdr, nfs4_layoutget_res)
   - 根据nfs4_layoutget_res创建nfs4_filelayout_segment
   > filelayout_decode_layout(pnfs_layout_hdr, nfs4_filelayout_segment, nfs4_layoutget_res, nfs4_deviceid, gfp_flags)
   - nfs4_filelayout_segment不会保存nfs4_deviceid, 而是直接获取nfs4_file_layout_dsaddr
   > filelayout_check_layout(pnfs_layout_hdr, nfs4_filelayout_segment, nfs4_layoutget_res, nfs4_deviceid, gfp_flags)
   - 这里只是获取deviceinfo, 还没有建立对应的nfs_client

** filelayout_pg_test(nfs_pageio_descriptor, nfs_page, nfs_page)
   - 检查是否可以合并nfs_page的请求
   - 检查pnfs_layout_segment的范围,没有实质检查
   > pnfs_generic_pg_test(nfs_pageio_descriptor, nfs_page, nfs_page)
   > nfs_generic_pg_test(nfs_pageio_descriptor, .)
   - 2个nfs_page必须在一个stripe中,也就是必须发送到一个相同的设备!!
   - req_offset(nfs_page) / nfs4_filelayout_segment->stripe_unit
   - 在这里, nfs4_filelayout_segment和nfs4_filelayout差不多了. 反正只有一个nfs4_filelayout_segment

** filelayout_pg_init_read(nfs_pageio_descriptor, nfs_page)
   - unaligned page不会处理  nfs_page->wb_offset != nfs_page->wb_pgbase
   > nfs_pageio_reset_read_mds(nfs_pageio_descriptor)
   - 这里是获取pnfs_layout_segment
   > pnfs_update_layout(inode, nfs_open_context, 0, NFS4_MAX_UNIT64, IOMODE_READ, GFP_KERNEL)
   - 如果无法获取,使用普通nfs方式
   > nfs_pageio_reset_read_mds(nfs_pageio_descriptor)
   - 在aops->readpage中处理page时使用,把nfs_page放到nfs_pageio_descriptor的队列中

** filelayout_pg_init_write(nfs_pageio_descriptor, nfs_page)
   - 准备pnfs_layout_segment 
   > pnfs_update_layout(inode, nfs_open_context, 0, NFS4_MAX_UNIT64, IOMODE_RW, GFP_NOFS)
   - 这里要求的pnfs_layout_range直接是整个文件范围!!
   - 然后创建pnfs_ds_commit_info, 追踪commit信息???
   > nfs_init_cinfo(nfs_commit_info, inode, nfs_direct_req)
   > filelayout_alloc_commit_info(pnfs_layout_segment, nfs_commit_info, GFP_NOFS)

** 总结
   - 上面实现2套nfs_pageio_ops, 准备或提交nfs_pageio
   - 由于只有一个nfs4_filelayout_segment, 所有只会有一套nfs4_file_layout_dsaddr, 在发起rpc请求之前,才会初始化nfs4_pnfs_ds->nfs_client

   - 整个写操作
   
   - nfs_pageio_descriptor是局部遍历,用来收集nfs_page
   - writepage使用nfs_rpc_ops->write_pagio_init初始化nfs_pageio_descriptor
   > pnfs_pageio_init_write(nfs_pageio_descriptor, inode, ioflags, nfs_pgio_completion_ops)
   - nfs_pgio_completion_ops是公共的,用来处理nfs_pgio_header, 用来处理IO完成之后的结果
   - nfs_pageio_ops = pnfs_layoutdriver_type->pg_write_ops = filelayout_pg_write_ops
   - 这里的函数接口在pagelist中使用,处理nfs_page

   - 使用共用的接口开始遍历address_space
   > write_cache_pages(address_space, writeback_control, nfs_writepages_callback, nfs_pageio_descriptor)
   - 对于每个需要写回的page, 使用回调函数处理 
   > nfs_writepages_callback( 
   > nfs_do_writepage(page, writeback_control, nfs_pageio_descriptor)
   - 把它放到nfs_pageio_descriptor链表中
   - 找到nfs_page, 这里必须有, 锁住nfs_page的PG_BUSY
   > nfs_find_and_lock_request(page, nonblock)
   - 设置page的PG_writeback, 开始IO 
   > nfs_pageio_add_request(nfs_pageio_descriptor, nfs_page)
   > __nfs_pageio_add_request(nfs_pageio_descriptor, nfs_page)
   > nfs_pageio_do_add_request(nfs_pageio_descriptor, nfs_page)

   - 在收集nfs_page时, 尽量合并多个nfs_page,一起请求
   - 如果nfs_page是nfs_pageio_descriptor的第一个,需要初始化nfs_pgio_descriptor
   > nfs_pageio_descriptor->nfs_pageio_ops->pg_init(nfs_pageio_descriptor, nfs_page)
   > filelayout_pg_init_write(nfs_pageio_descriptor, nfs_page)
   - 计算需要的pnfs_layout_segment
   - 里面会创建对应的pnfs_layout_hdr/pnfs_layout_segment/nfs4_deviceid_node等
   > pnfs_upate_layout(nfs_pageio_descriptor->inode, nfs_page->nfs_open_context, 0, NFS4_MAX_UNIT64, IOMODE_RW, GFP_NOFS)
   - 创建pnfs使用的commit资源
   > filelayout_alloc_commit_info(pnfs_layout_segment, nfs_commit_info, GFP_NOFS)

   - 合并时,同样调用nfs_pageio_ops->pg_test 
   > filelayout_pg_test(nfs_pageio_descriptor, nfs_page prev, nfs_page next)
   - 检查nfs_page是否处于一个stripe,  stripe大小是nfs4_filelayout_segment->stripe_unit
   - 如果能合并,page就算处理完成,这时可以释放page的PG_lock

   - 提交完成,或合并失败时,会发送nfs_pageio_descriptor
   > nfs_pageio_complete(nfs_pageio_descriptor)
   > nfs_pageio_doio(nfs_pageio_descriptor)
   - 同样使用pnfs的接口 
   > nfs_pageio_descriptor->nfs_pageio_ops->pg_doio(nfs_pageio_descriptor)
   > pnfs_generic_pg_writepages(nfs_pageio_descriptor)
   - 首先创建nfs_pgio_header
   - 这里提供释放nfs_ppio_header的接口，下面看怎么释放他
   > nfs_pgheader_init(nfs_pageio_descriptor, nfs_pgio_header, pnfs_writehdr_free)
   - 构造nfs_write_data, 为rpc做准备
   > nfs_generic_flush(nfs_pageio_descriptor, nfs_pgio_header)
   - 肯定是一次write多个page
   > nfs_flush_one(nfs_pageio_descriptor, nfs_pgio_header)
   - 转移nfs_page给nfs_pgio_header
   - 准备rpc的参数
   > nfs_write_rpcsetup(nfs_write_data, nfs_pageio_descriptor->pg_count, 0, nfs_pageio_descriptor->pg_ioflags, nfs_commit_info)
   - 这里会设置rpc的回调, 给nfs_pageio_descriptor, 向里传递
   - nfs_pageio_descriptor->pg_rpc_callops = nfs_write_common_ops

   - 处理nfs_write_data 
   > pnfs_do_multiple_writes(nfs_pageio_descriptor, nfs_pgio_header->rpc_list, nfs_pageio_descriptor->pg_ioflags)
   - 针对链表的每个nfs_write_data操作, 上面传递了共用的rpc_call_ops
   > pnfs_try_to_write_data(nfs_write_data, nfs_pageio_descriptor->pg_rpc_callops, pnfs_layout_segment, how)

   - 使用pnfs_layoutdriver_type->write_pagelist, 处理nfs_write_data
   > filelayout_write_pagelist(nfs_write_data, how)
   - 根据io位置, 找到对应的nfs4_deviceid_node 
   > nfs4_fl_calc_j_index(pnfs_layout_segment, offset)
   > nfs4_fl_calc_ds_index(pnfs_layout_segment, j)
   - 根据nfs4_deviceid_node获取nfs4_pnfs_ds
   - 在获取了nfs4_filelayout_segment信息时,会检查他返回到deviceid数组是否有效
   - 检查的方式就是获取nfs4_deviceid_node对应的nfs4_file_layout_dsaddr
   - 这里面是ds的网络地址
   - 这里会建立rpc_clnt的链接
   > nfs4_fl_prepare_ds(pnfs_layout_segment, idx)
   > nfs4_ds_connect(nfs_server, nfs4_pnfs_ds
   - 设置nfs_write_data->write_done_cb, 这是在write完成之后的处理

   - 发送rpc请求 
   > nfs_initiate_write(nfs4_pnfs_ds->nfs_client->rpc_clnt, nfs_write_data, filelayout_write_call_ops, sync, RPC_TASK_SOFTCONN)
   - 注意上面的rpc_task的回调函数,不是nfs_pageio_descriptor的
   - 原来的nfs_pgio_header->mds_ops中

   - 把nfs_write_data的信息给rpc_message
   - nfs_rpc_ops->write_setup(nfs_write_data, rpc_message)
   > nfs4_proc_write_setup(nfs_write_data, rpc_message)
   - 这里设置rpc_message->rpc_proc = nfs4_procedures[NFSPROC4_CLNT_WRITE)
   - 还有nfs_write_data->timestamp,用来更新lease?
   - 初始化sequence,然后启动rpc
   
   - rpc_call_preare = filelayout_write_prepare(rpc_task, nfs_write_data)
   - 检查nfs_open_context的有效性,layout/deviceid的有效性
   > filelayout_reset_to_mds(nfs_write_data->nfs_pgio_header->pnfs_layout_segment)
   - 如果上面的资源失效,使用普通的方式
   > filelayout_reset_write(nfs_write_data)
   - 分配nfs4_slot资源
   > nfs41_setup_sequence(nfs_write_data->nfs_client->nfs4_session,nfs4_sequence_args, .)
   - 选择可用的stateid 
   > nfs4_set_rw_stateid(nfs_write_data->nfs_writeargs->nfs4_stateid, nfs_write_data->nfs_writeargs->nfs_open_context, nfs_lock_context, FMODE_WRITE)

   - rpc_call_done = filelayout_write_call_done(rpc_task, nfs_write_data)
   - 通知原来的rpc回调接口
   - 开始若干层的回调
   - nfs_write_data->nfs_pgio_header->rpc_call_ops->rpc_call_ops(rpc_task, nfs_write_data)
   > nfs_writeback_done_common()
   > nfs_writeback_done(rpc_task, nfs_write_data)
   > nfs_rpc_ops->write_done(rpc_task, nfs_write_data)
   > nfs4_write_done(rpc_task, nfs_write_data)
   - 检查sequence, 释放nfs4_slot资源 
   > nfs4_sequence_done(rpc_task, nfs_write_data->nfs4_sequence_res)
   - 如果在写的过程中,有state恢复操作, 原来使用的stateid无效,需要重新发送写请求
   > nfs4_write_stateid_changes(rpc_task, nfs_write_data->nfs_writeargs)
   - 回调nfs_write_data->write_done_cb 
   > filelayout_write_done_cb(rpc_task, nfs_write_data)
   - 检查write返回的结果
   - 记录commit信息
   > filelayout_set_layoutcommit(nfs_write_data)
   - 最后检查write的generic的结果, 如果没有同步写回,还需要重新发送

   - rpc_release = filelayout_write_release(rpc_task, nfs_write_data)
   - 检查是否要释放layout 
   > filelayout_fenceme(inode, pnfs_layout_hdr)
   - 检查pnfs_layout_hdr->plh_flags的NFS_LAYOUT_RETURN
   - 只有在io错误时,才设置这个标志
   > pnfs_return_layout(inode)
   - 释放ds的nfs_client的计数
   > nfs_put_client(nfs_write_data->ds_clp)
   - 调用原来的释放操作 
   > nfs_write_data->nfs_pgio_header->rpc_call_ops->rpc_release(nfs_write_data)
   - nfs_writeback_release_common
   > 检查结果, 记录commit信息
   > nfs_write_need_commit(nfs_write_data)
   - 如果是NFS_DATA_SYNC,而且没有使用pnfs, 就不用commit
   - 如果是NFS_FILE_SYNC,不需要commit
   - 设置nfs_pgio_header->verf = nfs_write_data->verf
   - 还有nfs_pgio_heaer->flags的NFS_IOHDR_NEED_COMMIT 
   - 而且下面不再释放nfs_page
   - 如果已经有了, 直接比较verf
   - 如果不一样,设置NFS_IOHDR_NEED_RESCHED, 这就是错误了??
   - 释放write使用的资源 
   > nfs_writedata_release(nfs_write_data)
   - nfs_open_context, pagevec
   - 减小nfs_pgio_header->refcnt
   - 如果减为0,说明一个nfs_pageio_descriptor处理完成
   > nfs_pgio_header->nfs_pgio_completions_ops->completion(nfs_pgio_header)

   - 这个接口还是在writepage中传递过来的 
   - nfs_async_write_completion_ops->completion 
   > nfs_write_completion(nfs_pgio_header)
   - 准备nfs_commit_info
   > nfs_init_cinfo_inode(nfs_commit_info, nfs_pgio_header->inode)
   - 遍历他的nfs_page
   > 如果nfs_pgio_header->flags有NFS_IOHDR_NEED_RESCHED, 需要重新写 
   > nfs_mark_request_dirty(nfs_page)
   - 如果有NFS_IOHDR_NEED_COMMIT
   - 把verf给nfs_page->wb_verf, 把它给commit info 
   > nfs_mark_request_commit(nfs_page, nfs_pgio_header->pnfs_layout_segment, nfs_commit_info)
   - 否则可以释放它
   - 释放page/nfs_page的关系
   > nfs_inode_remove_request(nfs_page)
   - 主要是处理page->private, 去掉nfs_page->wb_flags的PG_MAPPED
   > nfs_unlock_request(nfs_page)
   - 释放nfs_page的PG_BUSY, 唤醒等待的任务
   - 释放page的PG_writeback 
   > nfs_end_page_writeback(nfs_page->page)
   - 释放自己
   > nfs_release_request(nfs_page)
   - 最后释放nfs_pgio_header, nfs_pgio_header->release()
   > pnfs_writehdr_free(nfs_pgio_header)
   - 释放pnfs资源
   > pnfs_put_lseg(pnfs_layout_segment)
   - 减小pnfs_layout_segment->pls_refcount, 如果减为0 
   > pnfs_layout_remove_lseg(pnfs_layout_hdr, pnfs_layout_segment)
   > pnfs_free_lseg(pnfs_layout_segment)
   - 然后是普通的释放内存
   - nfs_writehdr_free(nfs_pgio_header)

   - write的方式 how:
   - FLUSH_STABLE, FLUSH_COND_STABLE决定rpc参数nfs_writeargs->stable
   - FLUSH_SYNC表示是否等待结果
   - FLUSH_LOWPRI对应RPC_PRIORITY_LOW, FLUSH_HIGHPRIO对应RPC_PRIORITY_HIGH
   - nfs_pageio_descriptor->pg_ioflags决定这些
   - 根据writeback_control决定pg_ioflags
   > wb_priority(writeback_control)
   - 如果是for_reclaim, 使用FLUSH_HIGHPRI|FLUSH_STABLE
   - 如果是update/background, 使用FLUSH_LOWPRI|FLUSH_COND_STABLE

   - 普通情况是FLUSH_COND_STABLE
   - 对于FLUSH_COND_STABLE, 只有nfs_mds_commit_info中有nfs_page时才使用
   - 如果一开始就是FILE_SYNC, 也就不可能有commit状态的nfs_page, 所以会一直没有!
     
** select_bucket_index(nfs4_filelayout_segment, j)
   - 获取nfs4_file_layout_dsaddr中nfs4_pnfs_ds的索引
   - 在nfs4_filelayout_segment->stripe_type是STRIPE_SPARSE时, 它是stripe计数 
   > nfs4_fl_calc_ds_index(pnfs_layout_hdr, j)

** filelayout_clear_request_commit(nfs_page, nfs_commit_info)
   - 释放nfs_page
   - 如果nfs_page->wb_flags没有PG_COMMIT_TO_DS, 不用处理commit
   - 否则释放pnfs commit资源??
   - 设置nfs_commit_info->pnfs_ds_commit_info->nwritten --
   - 如果nfs_page->wb_list只有一个, 它是链表的最后一个, 释放pnfs_commit_bucket->pnfs_layout_segment
   - 释放nfs_page->wb_list, 在哪个队列??
   > nfs_request_remove_commit_list(nfs_page, nfs_commit_info)
   > pnfs_put_lseg(pnfs_layout_segment)

** filelayout_choose_commit_list(nfs_page, pnfs_layout_segment, nfs_commit_info)
   - 给nfs_page选一个list_head, 记录commit状态
   - 如果nfs4_filelayout_segment->commit_through_mds !=0, commit发给mds
   - 使用nfs_commit_info->mds->list
   - 否则，根据nfs_page的文件偏移,找到stripe index 
   > nfs4_fl_calc_j_index(pnfs_layout_segment, req_offset(page))
   - 根据stripe index, 找到bucket索引
   > select_bucket_index(nfs4_filelayout_segment, j)
   - 使用nfs_commit_info->pnfs_ds_commit_info->buckets[i]
   - 设置nfs_page->wb_flags的PG_COMMIT_TO_DS标志
   - 增加pnfs_ds_commit_info->nwritten

** filelayout_mark_request_commit(nfs_page, pnfs_layout_segment, nfs_commit_info)
   - 先查找list_head 
   > filelayout_choose_commit_list(nfs_page, pnfs_layout_segment, nfs_commit_info)
   - 把nfs_page放回队列中, 设置nfs_page->wb_flags的PG_CLEAN
   > nfs_request_add_commit_list(nfs_page, list_head, nfs_commit_info)
   

** calc_ds_index_from_commit(pnfs_layout_segment, i)
   - i应该是pnfs_commit_bucket数组的索引
   - 如果nfs4_filelayout_segment->stripe_type是STRIPE_SPARSE, 返回i
   - 否则查询对应的nfs4_pnfs_ds索引
   > nfs4_fl_calc_ds_index(pnfs_layout_segment, i)
   - stripe的使用方式,决定了ds数组的使用方式??

** select_ds_fh_from_commit(pnfs_layout_segment, i)
   - 选择i对应的nfs_fh, 给commit使用

** filelayout_initiate_commit(nfs_commit_data, how)
   - 发送commit请求
   - 计算ds索引,找到nfs4_pnfs_ds/nfs_client
   > calc_ds_index_from_commit(pnfs_layout_segment, nfs_commit_data->ds_commit_index)
   - 检查对应的nfs_pnfs_ds是否可用,如果有问题,重新创建nfs_client
   > nfs4_fl_prepare_ds(pnfs_layout_segment, idx)
   - 如果没有找到nfs4_pnfs_ds 
   > prepare_to_resend_writes(nfs_commit_data)
   > filelayout_commit_release(nfs_commit_data)
   - 否则继续
   - 设置nfs_commit_data->commit_done_cb = filelayout_commit_done_cb
   - 找到对应的nfs_fh 
   > select_ds_fh_from_commit(pnfs_layout_segment, nfs_commit_data->ds_commit_index)
   - 发送rpc请求 
   > nfs_initiate_commit(nfs4_pnfs_ds->nfs_client->rpc_clnt, nfs_commit_data, filelayout_commit_call_ops, how, RPC_TASK_SOFTCONN)

** transfer_commit_list(list_head src, list_head dst, nfs_commit_info, max)
   - src链表是nfs_commit_info中的某个队列
   - 遍历里面的nfs_page 
   - 锁住nfs_page 
   > nfs_lock_request(nfs_page)
   - 从nfs_commit_info中释放 
   > nfs_request_remove_commit_list(nfs_page, nfs_commit_info)
   - 去掉nfs_page->wb_flags的PG_COMMIT_TO_DS
   - 把它放到dst链表中

** filelayout_scan_ds_commit_list(pnfs_commit_bucket, pnfs_commit_bucket, max)
   - 从pnfs_commit_bucket->written中获取一些nfs_page, 放到pnfs_commit_bucket->committing链表中
   > transfer_commit_list(pnfs_commit_bucket->written, pnfs_commit_bucket->committing, nfs_commit_info, max)
   - 修改pnfs_commit_bucket->nwritten / ncommitting

** filelayout_scan_commit_lists(nfs_commit_info, max)
   - 获取max个等待commit的nfs_page
   - 遍历所有的nfs_commit_info->pnfs_ds_commmit_info->pnfs_commit_bucket数组
   > filelayout_scan_ds_commit_list(pnfs_commit_bucket, nfs_commit_info)

** filelayout_recover_commit_reqs(list_head, nfs_commit_info)
   - 把所有的pnfs_commit_bucket->written队列上的nfs_page,放到List_head中
   - 遍历pnfs_ds_commit_info的所有pnfs_commit_bucket
   > transfer_commit_list(pnfs_commit_bucket->written, list_head, nfs_commit_info, 0)

** alloc_ds_commits(nfs_commit_info, list_head)
   - 遍历nfs_commit_info->pnfs_ds_commit_info->pnfs_commit_bucket数组
   - 如果pnfs_commit_bucket->committing不是空,有nfs_page需要提交
   - 创建对应的nfs_commit_data, 设置ds_commit_index/pnfs_layout_segment
   > nfs_commitdata_alloc()
   - 把pnfs_commit_bucket->pages放到list_head中
   - 再次遍历, 提交committing链表 
   > nfs_retry_commit(pnfs_commit_bucket->committing, pnfs_layout_segment, nfs_commit_info)
   
** filelayout_commit_pagelist(inode, list_head, how, nfs_commit_info)
   - 遍历nfs_commit_info中需要commit的list_head, 构造对应的nfs_commit_data, 然后集体发送rpc请求
   - 参数list_head里面是mds的nfs_page, 准备一个nfs_commit_data 
   > nfs_commitdata_alloc()
   - 然后是pnfs_commit_bucket的
   > alloc_ds_commits(nfs_commit_info, list_head)
   - 如果没有创建新的nfs_commit_info, 也就没有commit的必要
   > nfs_commit_info->completion_ops->error_cleanup(inode)
   - 遍历上面创建的nfs_commit_data 
   - 如果nfs_commit_data->pnfs_layout_segment有效, 它是发送给ds的 
   > nfs_init_commit(nfs_commit_data, pnfs_commit_bucket->committing, pnfs_layout_segment, nfs_commit_info)
   - 提交commit请求 
   > filelayout_initiate_commit(nfs_commit_info, how)
   - 否则是发送给mds的
   > nfs_init_commit(nfs_commit_data, mds_page, NULL, nfs_commit_info)
   > nfs_initiate_commit(nfs_client, nfs_commit_data, nfs_commit_data->mds_ops, how, 0)

** filelayout_free_deviceid_node(nfs4_deviceid_node)
   - 释放nfs4_file_layout_dsaddr
   > nfs4_fl_free_deviceid(nfs4_file_layout_dsaddr)
   - 包含它的remotestr, nfs4_pnfs_ds数组等

** filelayout_alloc_layout_hdr(inode, gfp_flags)
   - 创建nfs4_filelayout
   - 在创建pnfs_layout_segment时,先查找pnfs_layout_hdr
   - 如果找不到, 调用这里的回调创建一个

** filelayout_free_layout_hdr(pnfs_layout_hdr)
   - 释放nfs4_filelayout

** filelayout_get_ds_info(inode)
   - 准备nfs_commit_info, 获取nfs_inode->pnfs_layout_hdr=>nfs4_layout->pnfs_ds_commit_info

** 总结
   - STRIPE_SPARSE和STRIPE_DENSE的区别
   - 前者使用stripe index索引ds index, 每个ds使用自己的nfs_fh
   - 后者stripe和ds对应, 都是用独自的nfs_fh

** pnfs_commit_bucket
   #+BEGIN_SRC 
	struct list_head written;
	struct list_head committing;
	struct pnfs_layout_segment *wlseg;
	struct pnfs_layout_segment *clseg;   
   #+END_SRC

** pnfs_ds_commit_info
   #+BEGIN_SRC 
	int nwritten;
	int ncommitting;
	int nbuckets;
	struct pnfs_commit_bucket *buckets;   
   #+END_SRC

** nfs4_filelayout
   #+BEGIN_SRC 
	struct pnfs_layout_hdr generic_hdr;
	struct pnfs_ds_commit_info commit_info;   
   #+END_SRC

** nfs_mds_commit_info 
   #+BEGIN_SRC 
	atomic_t rpcs_out;
	unsigned long		ncommit;
	struct list_head	list;   
   #+END_SRC

** nfs_commit_info
   #+BEGIN_SRC 
	spinlock_t			*lock;
	struct nfs_mds_commit_info	*mds;
	struct pnfs_ds_commit_info	*ds;
	struct nfs_direct_req		*dreq;	/* O_DIRECT request */
	const struct nfs_commit_completion_ops *completion_ops;   
   #+END_SRC

** 总结

   - commit操作
   - 在write的rpc完成后,设置需要commit的nfs_page 
   > filelayout_set_layoutcommit(nfs_write_data)
   - 如果nfs4_filelayout_segment->commit_through_mds !=0
   - write返回的nfs_writeverf->nfs3_stable_how == NFS_FILE_SYNC, 不需要pnfs的commit操作
  
   - 设置nfs_inode->flags的NFS_INO_LAYOUTCOMMIT
   - 设置pnfs_layout_segment->pls_flags的NFS_LSEG_LAYOUTCOMMIT
   - 更新pnfs_layout_hdr->plh_lwb = nfs_write_data->mds_offset = nfs_writeres->count
   - 设置inode 
   > mark_inode_dirty_sync(inode)

   - 在释放nfs_pgio_header时,如果nfs_page的数据需要commit, 暂时不会释放它
   > nfs_mark_request_commit(nfs_page, pnfs_layout_segment, nfs_commit_info)
   - 首先把它放到pnfs的commit管理中
   > pnfs_layoutdriver_type->mark_request_commit()
   > filelayout_mark_request_commit(nfs_page, pnfs_layout_segment, nfs_commit_info)
   - 需要把它放到ds专门的链表中
   - 选择合适的链表
   > filelayout_choose_commit_list(nfs_page, pnfs_layout_segment, nfs_commit_info)
   - 如果nfs4_filelayout_segment->commit_through_mds !=0
   - 直接返回nfs_commit_info->nfs_mds_commit_info->list
   - 使用一个mds的队列
   - 否则根据IO的位置,选择一个合适的pnfs_commit_bucket
   - 计算stripe偏移
   > nfs4_fl_calc_j_index(pnfs_layout_segment, offset)
   - 计算ds的索引
   > select_bucket_index(nfs4_filelayout_segment, j)
   - 使用nfs_commit_info->pnfs_ds_commit_info->buckets[i]->written队列
   - 设置nfs_page->wb_flags的PG_COMMIT_TO_DS标志
   - 增加pnfs_ds_commit_info->nwritten

   - 找到list_head, 把nfs_page放到队列中
   > nfs_request_add_commit_list(nfs_page, list_head, nfs_commit_info)
   - 设置nfs_page->wb_flags的PG_CLEAN?
   > nfs_list_add_request(nfs_page, list_head)
   - 增加nfs_commit_info->nfs_mds_commit_info->ncommit
   - 更新inode 
   > __mark_inode_dirty(inode, I_DIRTY_DATASYNC)


   - nfs_commit_info/pnfs_ds_commit_info的创建
   - nfs_commit_info就是一个指针的集和,用来传递参数
   > nfs_init_cinfo(nfs_commit_info, inode, nfs_direct_req)
   > nfs_init_cinfo_from_inode(nfs_commit_info, inode)
   - nfs_mds_commit_info使用nfs_inode->commit_info
   - nfs_pgio_header使用nfs_commit_completion_ops
   - pnfs_ds_commit_info有点特殊 
   > pnfs_get_ds_info(inode)
   - 一个inode只使用一个pnfs_layout_segment, 而且它嵌在nfs4_filelayout中
   > pnfs_layoutdriver_type->get_ds_info(inode)
   - filelayout_get_ds_info(inode)
   > nfs4_filelayout->pnfs_ds_commit_info


   - 在初始化nfs_pageio_descriptor中, 获取pnfs_layout_segment, 就可以创建对应的pnfs_ds_commit_info 
   > filelayout_alloc_commit_info(pnfs_layout_segment, nfs_commit_info, GFP_NOFS)


   - 触发commit操作
   > nfs_commit_inode(inode, how)
   - 设置nfs_inode->flags的NFS_INO_COMMIT,表示开始commit
   > nfs_commit_set_lock(nfs_inode, may_wait)
   - 如果已经设置,而且how没有FLUSH_SYNC, 直接返回
   - 否则等待这个标志
   > out_of_line_wait_on_bit_lock(nfs_inode->flags, NFS_INO_COMMIT, nfs_wait_bit_killable, TASK_KILLABLE)
   
   - 收集nfs_commit_info 
   > nfs_init_cinfo_from_inode(nfs_commit_info, inode)
   - 收集nfs_page
   > nfs_scan_commit_inode, list_head, nfs_commit_info)
   - nfs_commit_info->nfs_mds_commit_info->ncommit表示需要commit的nfs_page数量
   - 首先处理nfs_mds_commit_info 
   > nfs_scan_commit_list(nfs_mds_commit_info->list, list_head, nfs_commit_info, max)
   - 移动链表 
   > nfs_request_remove_commit_list(nfs_page, nfs_commit_info)
   - nfs_page->wb_flags必须没有PG_CLEAN,否则需要写回数据
   - 减小nfs_mds_commit_info->ncommit
   > nfs_list_add_request(nfs_page, list_head)

   - 然后处理pnfs_ds_commit_info 
   > pnfs_scan_commit_lists(inode, nfs_commit_info, max-ret)
   - pnfs_layoutdriver_type->scan_commit_lists(nfs_commit_info, max)
   > filelayout_scan_commit_lists(nfs_commit_info, max)
   - 遍历pnfs_ds_commit_info的所有pnfs_commit_bucket
   > filelayout_scan_ds_commit_list(pnfs_commit_bucket, nfs_commit_info, max)
   - 转移nfs_page
   - 里面并没有把nfs_page放到外部的list_head中
   - 而是给pnfs_commit_bucket->committing链表
   > transfer_commit_list(pnfs_commit_bucket->written, committing, nfs_commit_info, max)
   - 修改pnfs_ds_commit->nwritten / ncommitting计数

   - 收集完成后,开始提交nfs_page 
   > nfs_generic_commit_list(inode, list_head, how, nfs_commit_info)

   - 首先处理ds的list_head 
   > pnfs_commit_list(inode, list_head, how, nfs_commit_info)
   - pnfs_layoutdriver_type->commit_pagelist(inode, list_head, how, nfs_commit_info)
   > filelayout_commit_pagelist(inode, list_head, how, nfs_commit_info)
   - 这里把mds的链表也传进来,所以它和ds的链表同样处理

   - 对于mds,什么都不设置
   - 构造nfs_commit_data
   > nfs_commitdata_alloc()
   - 对于ds, 遍历所有的pnfs_commit_bucket
   > alloc_ds_commits(nfs_commit_info, list)
   - 对于pnfs_commit_bucket->committing不为空的,才需要commit 
   > nfs_commitdata_alloc()
   - 设置nfs_commit_data->ds_commit_index, pnfs_layout_segment
   - 现在得到一个队列的nfs_commit_data

   - 遍历nfs_commit_data链表
   - 对于mds, 应该使用普通的nfs操作
   > nfs_init_commit(nfs_commit_data, mds_pages, NULL, nfs_commit_info)
   - 发送rpc请求
   > nfs_initiate_commit(nfs_client, nfs_commit_data, nfs_commit_data->mds_ops, how, 0)

   - 对于ds, 初始化需要pnfs
   > nfs_init_commit(nfs_commit_data, pnfs_commit_bucket[index]->committing, nfs_commit_data->pnfs_layout_segment, nfs_commit_info)
   - 使用filelayout方式发送 
   > filelayout_initiate_commit(nfs_commit_data, how)
   - 获取对应的nfs4_pnfs_ds 
   > nfs4_fl_prepare_ds(pfns_layout_segment, ds_idx)
   - 设置nfs_commit_data->commit_done_cb = filelayout_commit_done_cb
   - 计算nfs_fh 
   > select_ds_fh_from_commit(pnfs_layout_segment, ds_commit_index)
   - 发送rpc 
   > nfs_initiate_commit(nfs4_pnfs_ds->nfs_client->rpc_clnt, nfs_commit_data, filelayout_commit_call_ops, how, RPC_TASK_SOFTCONN)
   - 这里还有初始化操作 
   > nfs_rpc_ops->commit_setup(nfs_commit_data, rpc_message)
   - nfs4_proc_commit_setup(nfs_commit_data, rpc_message
   - 设置rpc_message->rpc_proc = nfs4_procedures[NFS4PROC_CLNT_COMMIT]
   - 初始化sequence参数
   - 最后启动rpc 
   > rpc_run_task(rpc_task_setup)
   - 如果how包括FLUSH_SYNC, 需要等待rpc完成

   - 上面有2套rpc_call_ops
   - 一个是mds使用的
   - nfs_commit_ops
   - nfs_commit_preapre
   - nfs_commit_done
   - nfs_commit_release

   - 首先是prepare 
   > nfs_commit_prepare
   - nfs_rpc_ops->commit_rpc_prepare(rpc_task, nfs_commit_data)
   > nfs4_proc_commit_rpc_prepare(rpc_task, nfs_commit_data)
   - 获取nfs4_slot资源

   - nfs_commit_done(rpc_task, nfs_commit_data)
   > nfs_rpc_ops->commit_done(rpc_task, nfs_commit_data)
   > nfs4_commit_done(rpc_task, nfs_commit_data)
   - 处理sequence, 释放nfs4_slot
   - nfs_commit_data->commit_done_cb(rpc_task, nfs_commit_data)
   > nfs_commit_done_cb(rpc_task, nfs_commit_data)
   - 处理rpc的错误, 可能重新写nfs_page,也可能重新启动rpc 

   > nfs_commit_release(rpc_task, nfs_commit_done)
   - 直接处理回调
   - 这是从nfs_commit_info中传递过来
   - 在创建nfs_commit_data时设置
   - nfs_commit_completion_ops->completion(nfs_commit_data)
   > nfs_commit_release_pages(nfs_commit_data)
   - 遍历nfs_commit_data->pages中的nfs_page 
   - 从链表中释放
   > nfs_list_remove_request(nfs_page)
   - bdi的统计信息
   > nfs_clear_page_commit(nfs_page->wb_page)
   - 如果status < 0, 设置nfs_open_context的错误
   - 这是严重错误?
   > nfs_inode_remove_request(nfs_page)
   - 然后比较nfs_writeverf
   - 如果一样,可以释放nfs_page
   - 否则设置nfs_page->page的PG_dirty
   - nfs_open_context->flags的NFS_CONTEXT_RESEND_WRITES, 谁使用它?
   - 然后减小nfs_commit_info->nfs_mds_commit_info->rpcs_out
   - 它表示处理中的nfs_commit_data的数量 
   - 如果减为0, 释放nfs_inode->flags的标志 NFS_INO_COMMIT
   > nfs_commit_clear_lock(nfs_inode)
   - 最后释放nfs_commit_data
   > nfs_commitdata_release(nfs_commit_data)
   

   - 对于filelayout来说
   - filelayout_commit_call_ops
   - filelayout_commit_prepare(rpc_task, nfs_commit_data)
   > 分配nfs4_slot资源

   - filelayout_write_commit_done(rpc_task, nfs_commit_data)
   > nfs_commit_data->mds_ops->rpc_call_done(rpc_task, nfs_data)
   - 和上面的一样,但使用的nfs_commit_data->commit_done_cb是filelayout_commit_done_cb

   - filelayout_commit_release(rpc_task, nfs_commit_data)
   - 调用普通的回调函数 
   > nfs_commit_data->nfs_commit_completion_ops->completion(nfs_commit_data)
   - 释放pnfs_layout_segment计数
   > pnfs_put_lseg(nfs_commit_data->pnfs_layout_segment)
   - 释放nfs_commit_data 
   > nfs_commitdata_release(nfs_commit_data)
   > nfs_commmit_free(nfs_commit_data)

** nfs4_layoutcommit_data
   #+BEGIN_SRC 
	struct rpc_task task;
	struct nfs_fattr fattr;
	struct list_head lseg_list;
	struct rpc_cred *cred;
	struct nfs4_layoutcommit_args args;
	struct nfs4_layoutcommit_res res;   
   #+END_SRC

** 总结

   - nfs_inode的layoutcommit, 它是发给mds的请求? 

   - 在write的回调中设置inode的commit标志
   > filelayout_write_done_cb(rpc_task, nfs_write_data)
   - 如果需要更新, 在nfs_inode/pnfs_layout_segment中标注
   > filelayout_set_layoutcommit(nfs_write_data)
   > pnfs_set_layoutcommit(nfs_write_data)
   - 设置nfs_inode->flags的NFS_INO_LAYOUTCOMMIT


   - 在提交inode时使用layoutcommit处理ds的数据
   - 在sync文件时使用

   > pnfs_layoutcommit_inode(inode, sync)
   - nfs_inode->flags的NFS_INO_LAYOUTCOMMIT标志表示需要发送layoutcommit请求
   - 创建nfs4_layoutcommit_data
   - 设置nfs_inode->flags的NFS_INO_LAYOUTCOMMITTING标志,开始commit
   - 如果sync!=0, 而且别人已经设置它,就先等待完成 
   > wait_on_bit_lock(nfs_inode->flags, NFS_INO_LAYOUTCOMMITTING, nfs_wait_bit_killable, TASK_KILLABLE)
   - 如果可以继续, 先去掉nfs_inode->NFS_INO_LAYOUTCOMMIT标志
   - 收集需要commit的pnfs_layout_segment
   - 根据pnfs_layout_segment->pls_flags的NFS_LSEG_LAYOUTCOMMIT标志
   - 收集起来后,也去掉NFS_LSEG_LAYOUTCOMMIT标志
   > pnfs_list_write_lseg(inode, nfs4_layoutcommit_data->lseg_list)
   - nfs4_layoutcommit_args->lastbywritten = pnfs_layout_hdr->plh_lwb, 表示写的范围
   - nfs4_layoutcommit_res->nfs_server = nfs_inode->nfs_server, 这是mds 
   > nfs4_proc_layoutcommit(nfs4_layoutcommit_data, sync)
   - 如果sync!=0, 等待rpc_task

   - rpc_call_ops nfs4_layoutcommit_ops
   
   > nfs4_layoutcommit_prepare
   - 获取nfs4_slot资源
   > nfs41_setup_sequence(nfs4_session, .)

   > nfs4_layoutcommit_done
   - 释放nfs4_slot资源
   - 根据返回的nfs_fattr更新inode 
   > nfs_post_op_update_inode_force_wcc(inode, nfs_fattr)
  
   > nfs4_layoutcommit_release
   - 释放nfs4_layoutcommit_data
   > pnfs_layoutdriver_type->cleanup_layoutcommit(nfs4_layoutcommit_data)
   - 只有block layout有这个函数
   - 然后释放pnfs_layout_segment的commit标志
   > pnfs_list_write_lseg_done(inode, nfs4_layoutcommit_data->lseg_list)
   - 遍历链表里的pnfs_layout_segment
   - 怎么没有去掉标志?
   - 去掉nfs_inode->flags的NFS_INO_LAYOUTCOMMITTING, 唤醒等待的任务
   > wake_up_bit(bitlock, NFS_INO_LAYOUTCOMMITTING)
