* 统一术语
  - FS空间:行对于log数据而言, 包括metadata和data
  - log队列: 文件系统的log使用的磁盘空间是一段连续的磁盘块，可能和FS使用一个磁盘,可能使用独立的磁盘。空间作为一个环形队列使用，可以不断添加xfs_log_item/xlog_in_core, 如果这些xfs_log_item写回FS空间，可以释放对应的log队列的尾部数据



* trans
** xfs_trans 
   #+begin_src 
	unsigned int		t_magic;	/* magic number */
	xfs_log_callback_t	t_logcb;	/* log callback struct */
	unsigned int		t_type;		/* transaction type */
	unsigned int		t_log_res;	/* amt of log space resvd */
	unsigned int		t_log_count;	/* count for perm log res */
	unsigned int		t_blk_res;	/* # of blocks resvd */
	unsigned int		t_blk_res_used;	/* # of resvd blocks used */
	unsigned int		t_rtx_res;	/* # of rt extents resvd */
	unsigned int		t_rtx_res_used;	/* # of resvd rt extents used */
	struct xlog_ticket	*t_ticket;	/* log mgr ticket */
	xfs_lsn_t		t_lsn;		/* log seq num of start of
						 * transaction. */
	xfs_lsn_t		t_commit_lsn;	/* log seq num of end of
						 * transaction. */
	struct xfs_mount	*t_mountp;	/* ptr to fs mount struct */
	struct xfs_dquot_acct   *t_dqinfo;	/* acctg info for dquots */
	unsigned int		t_flags;	/* misc flags */
	int64_t			t_icount_delta;	/* superblock icount change */
	int64_t			t_ifree_delta;	/* superblock ifree change */
	int64_t			t_fdblocks_delta; /* superblock fdblocks chg */
	int64_t			t_res_fdblocks_delta; /* on-disk only chg */
	int64_t			t_frextents_delta;/* superblock freextents chg*/
	int64_t			t_res_frextents_delta; /* on-disk only chg */
#ifdef DEBUG
	int64_t			t_ag_freeblks_delta; /* debugging counter */
	int64_t			t_ag_flist_delta; /* debugging counter */
	int64_t			t_ag_btree_delta; /* debugging counter */
#endif
	int64_t			t_dblocks_delta;/* superblock dblocks change */
	int64_t			t_agcount_delta;/* superblock agcount change */
	int64_t			t_imaxpct_delta;/* superblock imaxpct change */
	int64_t			t_rextsize_delta;/* superblock rextsize chg */
	int64_t			t_rbmblocks_delta;/* superblock rbmblocks chg */
	int64_t			t_rblocks_delta;/* superblock rblocks change */
	int64_t			t_rextents_delta;/* superblocks rextents chg */
	int64_t			t_rextslog_delta;/* superblocks rextslog chg */
	struct list_head	t_items;	/* log item descriptors */
	xfs_trans_header_t	t_header;	/* header for in-log trans */
	struct list_head	t_busy;		/* list of busy extents */
	unsigned long		t_pflags;	/* saved process flags state */

   #+end_src

** xfs_trans_header
   #+begin_src 
	uint		th_magic;		/* magic number */
	uint		th_type;		/* transaction type */
	__int32_t	th_tid;			/* transaction id (unused) */
	uint		th_num_items;		/* num items logged by trans */
	//在transaction的log的最前头,说明它后面的信息.
   #+end_src

** xfs_log_item 
   #+begin_src 
	struct list_head		li_ail;		/* AIL pointers */
	xfs_lsn_t			li_lsn;		/* last on-disk lsn */
	struct xfs_log_item_desc	*li_desc;	/* ptr to current desc*/
	struct xfs_mount		*li_mountp;	/* ptr to fs mount */
	struct xfs_ail			*li_ailp;	/* ptr to AIL */
	uint				li_type;	/* item type */
	uint				li_flags;	/* misc flags */
	struct xfs_log_item		*li_bio_list;	/* buffer item list */
	void				(*li_cb)(struct xfs_buf *,
						 struct xfs_log_item *);
							/* buffer item iodone */
							/* callback func */
	const struct xfs_item_ops	*li_ops;	/* function list */

	/* delayed logging */
	struct list_head		li_cil;		/* CIL pointers */
	struct xfs_log_vec		*li_lv;		/* active log vector */
	xfs_lsn_t			li_seq;		/* CIL commit seq */   
   #+end_src

** xfs_log_item_desc 
   #+begin_src 
	struct xfs_log_item	*lid_item;
	struct list_head	lid_trans;
	unsigned char		lid_flags;   
   #+end_src

** xlog_op_header
   #+begin_src 
	__be32	   oh_tid;	/* transaction id of operation	:  4 b */
	__be32	   oh_len;	/* bytes in data region		:  4 b */
	__u8	   oh_clientid;	/* who sent me this		:  1 b */
	__u8	   oh_flags;	/*				:  1 b */
	__u16	   oh_res2;	/* 32 bit align			:  2 b */
   #+end_src

** xlog_ticket
   #+begin_src 
	struct list_head   t_queue;	 /* reserve/write queue */
	struct task_struct *t_task;	 /* task that owns this ticket */
	xlog_tid_t	   t_tid;	 /* transaction identifier	 : 4  */
	atomic_t	   t_ref;	 /* ticket reference count       : 4  */
	int		   t_curr_res;	 /* current reservation in bytes : 4  */
	int		   t_unit_res;	 /* unit reservation in bytes    : 4  */
	char		   t_ocnt;	 /* original count		 : 1  */
	char		   t_cnt;	 /* current count		 : 1  */
	char		   t_clientid;	 /* who does this belong to;	 : 1  */
	char		   t_flags;	 /* properties of reservation	 : 1  */
	uint		   t_trans_type; /* transaction type             : 4  */

        /* reservation array fields */
	uint		   t_res_num;                    /* num in array : 4 */
	uint		   t_res_num_ophdrs;		 /* num op hdrs  : 4 */
	uint		   t_res_arr_sum;		 /* array sum    : 4 */
	uint		   t_res_o_flow;		 /* sum overflow : 4 */
	xlog_res_t	   t_res_arr[XLOG_TIC_LEN_MAX];  /* array of res : 8 * 15 */    

	// xlog_ticket->t_trans_type = xfs_trans->t_type, 都不会保存到xlog中.
   #+end_src

** xlog 
   #+begin_src 
	/* The following fields don't need locking */
	struct xfs_mount	*l_mp;	        /* mount point */
	struct xfs_ail		*l_ailp;	/* AIL log is working with */
	struct xfs_cil		*l_cilp;	/* CIL log is working with */
	struct xfs_buf		*l_xbuf;        /* extra buffer for log
						 * wrapping */
	struct xfs_buftarg	*l_targ;        /* buftarg of log */
	struct delayed_work	l_work;		/* background flush work */
	uint			l_flags;
	uint			l_quotaoffs_flag; /* XFS_DQ_*, for QUOTAOFFs */
	struct list_head	*l_buf_cancel_table;
	int			l_iclog_hsize;  /* size of iclog header */
	int			l_iclog_heads;  /* # of iclog header sectors */
	uint			l_sectBBsize;   /* sector size in BBs (2^n) */
	int			l_iclog_size;	/* size of log in bytes */
	int			l_iclog_size_log; /* log power size of log */
	int			l_iclog_bufs;	/* number of iclog buffers */
	xfs_daddr_t		l_logBBstart;   /* start block of log */
	int			l_logsize;      /* size of log in bytes */
	int			l_logBBsize;    /* size of log in BB chunks */

	/* The following block of fields are changed while holding icloglock */
	wait_queue_head_t	l_flush_wait ____cacheline_aligned_in_smp;
						/* waiting for iclog flush */
	int			l_covered_state;/* state of "covering disk
						 * log entries" */
	xlog_in_core_t		*l_iclog;       /* head log queue	*/
	spinlock_t		l_icloglock;    /* grab to change iclog state */
	int			l_curr_cycle;   /* Cycle number of log writes */
	int			l_prev_cycle;   /* Cycle number before last
						 * block increment */
	int			l_curr_block;   /* current logical log block */
	int			l_prev_block;   /* previous logical log block */

	/*
	 * l_last_sync_lsn and l_tail_lsn are atomics so they can be set and
	 * read without needing to hold specific locks. To avoid operations
	 * contending with other hot objects, place each of them on a separate
	 * cacheline.
	 */
	/* lsn of last LR on disk */
	atomic64_t		l_last_sync_lsn ____cacheline_aligned_in_smp;
	/* lsn of 1st LR with unflushed * buffers */
	atomic64_t		l_tail_lsn ____cacheline_aligned_in_smp;

	struct xlog_grant_head	l_reserve_head;
	struct xlog_grant_head	l_write_head;

	/* The following field are used for debugging; need to hold icloglock */
#ifdef DEBUG
	char			*l_iclog_bak[XLOG_MAX_ICLOGS];
#endif
   
   #+end_src

** xlog_grant_head
   - head是xlog_grant_head->grant, 它类型是atomic64, 分成2个域,cycle和space,每个使用4字节
   - 根据xfs_log_item的粒度, space是字节为单位

   #+begin_src 
	spinlock_t		lock ____cacheline_aligned_in_smp;
	struct list_head	waiters;
	atomic64_t		grant;   
   #+end_src

** xlog_rec_header
   #+begin_src 
	__be32	  h_magicno;	/* log record (LR) identifier		:  4 */
	__be32	  h_cycle;	/* write cycle of log			:  4 */
	__be32	  h_version;	/* LR version				:  4 */
	__be32	  h_len;	/* len in bytes; should be 64-bit aligned: 4 */
	__be64	  h_lsn;	/* lsn of this LR			:  8 */
	__be64	  h_tail_lsn;	/* lsn of 1st LR w/ buffers not committed: 8 */
	__le32	  h_crc;	/* crc of log record                    :  4 */
	__be32	  h_prev_block; /* block number to previous LR		:  4 */
	__be32	  h_num_logops;	/* number of log operations in this LR	:  4 */
	__be32	  h_cycle_data[XLOG_HEADER_CYCLE_SIZE / BBSIZE];
	/* new fields */
	__be32    h_fmt;        /* format of log record                 :  4 */
	uuid_t	  h_fs_uuid;    /* uuid of FS                           : 16 */
	__be32	  h_size;	/* iclog size				:  4 */   
   #+end_src

** xlog_rec_ext_header
   #+begin_src 
	__be32	  xh_cycle;	/* write cycle of log			: 4 */
	__be32	  xh_cycle_data[XLOG_HEADER_CYCLE_SIZE / BBSIZE]; /*	: 256 */
   #+end_src

** xlog_in_core2
   #+begin_src 
	xlog_rec_header_t	hic_header;
	xlog_rec_ext_header_t	hic_xheader;
	char			hic_sector[XLOG_HEADER_SIZE];
   #+end_src

** xlog_in_core
   #+begin_src 
	wait_queue_head_t	ic_force_wait;
	wait_queue_head_t	ic_write_wait;
	struct xlog_in_core	*ic_next;
	struct xlog_in_core	*ic_prev;
	struct xfs_buf		*ic_bp;
	struct xlog		*ic_log;
	int			ic_size;
	int			ic_offset;
	int			ic_bwritecnt;
	unsigned short		ic_state;
	char			*ic_datap;	/* pointer to iclog data */

	/* Callback structures need their own cacheline */
	spinlock_t		ic_callback_lock ____cacheline_aligned_in_smp;
	xfs_log_callback_t	*ic_callback;
	xfs_log_callback_t	**ic_callback_tail;

	/* reference counts need their own cacheline */
	atomic_t		ic_refcnt ____cacheline_aligned_in_smp;
	xlog_in_core_2_t	*ic_data;
#define ic_header	ic_data->hic_header
   #+end_src

** xfs_ail_cursor
   #+begin_src 
	struct list_head	list;
	struct xfs_log_item	*item;   
   #+end_src

** xfs_ail 
   #+begin_src 
	struct xfs_mount	*xa_mount;
	struct task_struct	*xa_task;
	struct list_head	xa_ail;
	xfs_lsn_t		xa_target;
	xfs_lsn_t		xa_target_prev;
	struct list_head	xa_cursors;
	spinlock_t		xa_lock;
	xfs_lsn_t		xa_last_pushed_lsn;
	int			xa_log_flush;
	struct list_head	xa_buf_list;
	wait_queue_head_t	xa_empty;   
   #+end_src

** xfs_cil_ctx 
   #+begin_src 
	struct xfs_cil		*cil;
	xfs_lsn_t		sequence;	/* chkpt sequence # */
	xfs_lsn_t		start_lsn;	/* first LSN of chkpt commit */
	xfs_lsn_t		commit_lsn;	/* chkpt commit record lsn */
	struct xlog_ticket	*ticket;	/* chkpt ticket */
	int			nvecs;		/* number of regions */
	int			space_used;	/* aggregate size of regions */
	struct list_head	busy_extents;	/* busy extents in chkpt */
	struct xfs_log_vec	*lv_chain;	/* logvecs being pushed */
	xfs_log_callback_t	log_cb;		/* completion callback hook. */
	struct list_head	committing;	/* ctx committing list */   
   #+end_src

** xfs_cil
   #+begin_src 
	struct xlog		*xc_log;
	struct list_head	xc_cil;
	spinlock_t		xc_cil_lock;
	struct xfs_cil_ctx	*xc_ctx;
	struct rw_semaphore	xc_ctx_lock;
	struct list_head	xc_committing;
	wait_queue_head_t	xc_commit_wait;
	xfs_lsn_t		xc_current_sequence;
	struct work_struct	xc_push_work;
	xfs_lsn_t		xc_push_seq;
	//用于追踪committed log item, 但没有写到log中.
	//delayed log mount option
   #+end_src

** 总结
   - 针对每一个操作,xfs都计算需要reserve的空间
   - xfs_trans在释放时,同时释放xfs_busy_list

* xfs_log_recover.c 

** xlog_buf_bbcount_valid(xlog, bbcount)
   - 检查bbcount是否有效, 表示要访问的xlog数据的block数量
   - bbcount > 0 && bbcount <= xlog->l_logBBsize

** xlog_get_bp(xlog, nbblks)
   - 创建xfs_buf读取数据
   - 要读的数据量是nbblks, 使用xlog->l_sectBBsize对齐. 
   > nbblks = round_up(nbblks + xlog->l_sectBBsize -1, xlog->l_sectBBsize)
   - 如果nbblks>1, 它多分配l_secBBsize的空间, 在读的时候可能开始地址不是l_secBBsize对齐的,xfs_buf空间可能不够用.
   - 下面创建xfs_buf时提供了假的xfs_buf_map
   > xfs_buf_get_uncached(xlog->xfs_mount->m_logdev_targp, nbblks, 0)

** xlog_put_bp(xfs_buf)
   - 释放xfs_buf 
   > xfs_buf_free(xfs_buf)

** xlog_align(xlog, xfs_daddr_t, nbblks, xfs_buf)
   - 返回xfs_buf在内存中的指针,根据xfs_daddr_t计算xfs_buf内部偏移
   - offset = xfs_daddr_t & (xlog->l_sectBBsize - 1)
   - 返回xfs_buf->b_addr + offset

** xlog_bread_noalign(xlog, xfs_addr_t blk_no, nbblks, xfs_buf)
   - blk_no是xlog数据区的内部偏移, nbblks要读取的block数量
   - blk_no向下对齐l_sectBBsize, nbblks向上对齐.
   - 这里就有问题, 可能只读一部分!!
   - 设置xfs_buf的磁盘偏移 xfs_buf->xfs_buf_map[0]->bm_bn = xlog->l_logBBstart + xfs_addr_t
   - 为何不设置xfs_buf->b_bn??
   > XFS_BUF_SET_ADDR(xfs_buf, xlog->l_logBBsize + xfs_addr_t)
   - 读标志 xfs_buf->b_flags的XBF_READ, xfs_buf->b_io_length = nbblks
   > XFS_BUF_READ(xfs_buf)
   - 发起bio
   > xfsbdstrat(xlog->xfs_mount, xfs_buf)
   - 等待io完成, 使用xfs_buf->b_iowait， 这里没有使用xfs_buf->b_ops
   > xfs_buf_iowait(xfs_buf)

** xlog_bread(xlog, xfs_addr_t, nbblks, xfs_buf, xfs_caddr_t)
   - 先读回数据
   > xlog_bread_noalign(xlog, blk_no, nbblks, xfs_buf)
   - 处理sectorsize内部偏移, 返回内存指针.
   > xlog_align(xlog, xfs_daddr_t, nbblks, xfs_buf)

** xlog_bread_offset(xlog, xfs_addr_t blk_no, nbblks, xfs_buf, xfs_caddr_t offset)
   - 把(blk_no, nbblks)中的数据读到offset指向的内存
   - 把xfs_buf使用的内存指针保存起来  xfs_buf->b_addr / xfs_buf->b_length
   - 然后把offset指向的内存给xfs_buf, 需要分配page指针数组, 处理页内偏移
   > xfs_buf_associate_memory(xfs_buf, offset, nbblks)
   - 读回数据, 使用一个xfs_buf_map
   > xlog_bread_noalign(xlog, xfs_addr_t, nbblks, xfs_buf)
   - 然后回复xfs_buf之前的内存指针
   > xfs_buf_associate_memory(xfs_buf, orig_offset, orig_len)

** xlog_bwrite(xlog, xfs_daddr_t, nbblks, xfs_buf)
   - 和上面的读类似
   - 使用第一个xfs_buf_map, 设定磁盘地址
   > XFS_BUF_SET_ADDR(xfs_buf, xlog->l_logBBstart + xfs_daddr_t)
   - 清除xfs_buf->b_flags的标志, READ/WRITE,ASYNC,SYNCIO,FUA,FLUSH等..
   - xfs_buf->b_hold ++,  
   - xfs_buf->b_io_length = nbblks, 为何不设置xfs_buf_map->bm_len
   - 读回数据, 同步操作, bio完成后才返回.  和read完全一样!
   > xfs_bwrite(xfs_buf)
   - 释放xfs_buf 
   > xfs_buf_relse(xfs_buf)

** xlog_header_check_recover(xfs_mount, xlog_rec_header)
   - 检查xlog_rec_header是否有效
   - xlog_rec_header->h_magicno = 0xFEEDbabe
   - xlog_rec_header->h_fmt == XLOG_FMT
   - xlog_rec_header->h_fs_uuid == xfs_mount->xfs_super->sb_uuid

** xlog_header_check_mount(xfs_mount, xfs_rec_header)
   - 检查xfs_rec_header是否有效
   - 只检查xfs_rec_header->h_fs_uuid == xfs_sb->sb_uuid
   - 为何之类只检查uuid/magic??

** xfs_recover_iodone(xfs_buf)
   - 如果xfs_buf->b_error !=0, 有错误,关闭文件系统,但它也不能卸载?!
   > xfs_buf_ioerror_alert(xfs_buf, __func__)
   > xfs_force_shutdown(xfs_mount, SHUTDOWN_META_IO_ERROR)
   - 如果没问题,完成回调函数
   > xfs_buf_ioend(xfs_buf, 0)
   - 在xfs_buf->b_iodone中使用, 仅仅检查错误,然后使用xfs_buf的通用回调??!!

** xlog_find_cycle_start(xlog, xfs_buf, xfs_daddr_t first_blk, xfs_daddr_t last_blk, cycle)
   - 使用2分查找去磁盘中查找, 范围是(first_blk, last_blk), 找到使用cycle的第一个block
   - 读取一个block的数据
   > xlog_bread(xlog, mid_blk, 1, xfs_buf, offset)
   - xlog_in_core对应一个xlog_rec_header??  一个xlog_rec_header包含多个block??
   - 在第一个block的开头是XLOG_HEADER_MAGIC_NUM/xlog_rec_header), 其他的block是cycle/block的xfs_lsn_t
   > xlog_get_cycle(xfs_lsn_t)
   - 最后last_blk指向的block是第一使用cycle的. 这里要保证block的cycle是有序的

** xlog_find_verify_cycle(xlog, xfs_daddr_t start_blk, nbblks, stop_on_cycle_no, xfs_daddr_t new_blk)
   - 检查(start_blk,nbblks)范围内的block, 如果发现cycle==stop_on_cycle_no, 返回它的位置给new_blk, 如果找不到返回-1
   - 首先创建一个xfs_buf, 首先设定大小是fsb, 如果失败,减半. 
   - 这个值不能超过xlog->l_logBBsize, 不能低于xlog->l_sectBBsize
   > xlog_get_bp(xlog, bufblks)
   - 从start_blk开始扫描xlog设备, 每次读取xfs_buf能容纳的数据
   > xlog_bread(xlog, i, bcount, xfs_buf, xfs_caddr_t)
   - 遍历这些block, 找到cycle 
   > xlog_get_cycle(xfs_caddr_t) 
   - 比较cycle  = stop_on_cycle_no, 返回对应的blk地址

** xlog_find_verify_log_record(xlog, xfs_daddr_t start_blk, xfs_addr_t last_blk, extra_bblks)
   - 这里应该是找到一个xlog_rec_header, 检查它是否有效. 首先找到第一个block, 验证xlog_rec_header, 检查xlog的大小.
   - 从last_blk向前遍历, 找到XLOG_HEADER_MAGIC_NUM的block
   - 准备一个xfs_buf, 大小是last_blk - start_blk
   > xlog_get_bp(xlog, num_blks)
   - 如果失败,大小改为1个block, 每次读取一个block, 处理一个
   - 读取数据
   > xlog_bread(xlog, start_blk, num_blks, xfs_buf, xfs_caddr_t)
   - 检查block的开头, 如果是XLOG_HEADER_MAGIC_NUM, 这就是xlog_rec_header
   - 如果找不到,可能碰到队列边界, 直接退出.
   - 检查xlog_rec_header是否有效, 它可能仅仅是一部分,所以只检查uuid
   > xlog_header_check_mount(xlog->xfs_mount, xlog_rec_header)
   - 最后需要检查这个xlog的大小
   - xlog_rec_header->h_size / XLOG_HEADER_CYCLE_SIZE + xlog_rec_header->h_len = last_blk - head_blk
   - 如果不相同, 修改last_blk = head_blk, 也就是丢弃当前的xlog_rec_header

** xlog_find_head(xlog, xfs_addr_t return_head_blk)
   - 找xlog数据区的头
   - 检查xlog中是否仅仅使用一部分,也就是还有一部分cycle=0. 
   - xlog数据不会删除,所以如果用过cycle肯定变为 !=0
   > xlog_find_zeroed(xlog, first_blk)
   - 上面找到first_blk不应该是0, 因为mkfs会写入一个假的xlog
   - 如果找到了,直接返回它,也就是head_blk, tail_blk也就是0. 可以从head_blk开始写数据.
   - 如果上面找不到,需要遍历xlog数据区
   - 先找到第一个block, 准备xfs_buf 
   > xlog_get_bp(xlog, 1)
   - 读回数据, 获取内存指针offset
   > xlog_bread(xlog, 0, 1, xfs_buf, offset)
   - 还有first_half_cycle 
   > xlog_get_cycle(offset) 
   - 准备最后一个block, 使用同一个xfs_buf??
   > xlog_bread(xlog, last_blk, 1, xfs_buf, offset)
   - 还有last_half_cycle
   > xlog_get_cycle(offset)
   - 队列中的cycle理想情况最多只有2种,每次写数据循环到数组头部,cycle增加.在cycle不一样的地方,就是队列的头尾
   - 但是xlog写的时候没有保证order,可能后面写进去,但系统崩溃,导致cycle错误. 但这种错误情况不会太多,在一个xlog_in_core范围内.
   - 这里先找到cycle的变化处,然后向前搜索一个范围, 如果搜索不到乱序的,就使用cycle断开的地方.
   - 如果first_half_cycle == last_half_cycle, 说明队列没有循环使用. 如果有错误,也是发生在数组头尾. 要是错误发生在中间,数组头尾肯定会差1
   - 否则first_half_cycle == last_half_cycle+1, 因为2者是挨着的. 需要先找到cycle变化的地方
   - 先找到last_half_cycle的第一个block, 下面的范围是(0, logBBsize)
   > xlog_find_cycle_start(xlog, xfs_buf, first_blk, head_blk, last_half_cycle)
   - 这是找到队列的头尾,再向前遍历一个范围, 大小由xlog_in_core决定.
   > XLOG_TOTAL_REC_SHIFT(xlog_rec_header)
   - 顺序遍历,找到使用stop_on_cycle的第一个block
   > xlog_find_verify_cycle(xlog, start_block, num_scan_bblks, stop_on_cycle, new_blk)
   - 如果8个超过xlog区域的头,需要转到尾部.
   - 找到head_blk, 检查前一个xlog_rec_header
   > xlog_find_verify_log_record(xlog, start_blk, head_blk, 0)

** xlog_find_tail(xlog, xfs_daddr_t head_blk, xfs_daddr_t tail_blk)
   - 查找xlog队列的头和尾.
   - 一般情况,应该只恢复一个xlog_in_core?? 所以队列分成2部分,一部分是有效数据,就是xlog_in_core的数据,另一部分是无效数据,就是其余的数据.
   - 也不能这么说, 这样log数据区只需要2个xlog_in_core就够了???
   - 这里找的头尾是无效数据使用的.
   - 先找到头
   > xlog_find_head(xlog, head_blk)
   - 前一个xlog_rec_header就是有效数据
   - 准备一个xfs_buf, 装一个block,向前遍历block
   > xlog_get_bp(xlog, 1)
   - 读block
   > xlog_bread(xlog, i, 1, xfs_buf, offset)
   - 如果上面head_blk ==0, 这里可能xlog还没有使用,第一个block的cycle==0, tail_blk = 0
   - 检查它的cycle == 0
   > xlog_get_cycle(offset)
   - 如果不是初始化的情况,查找前面一个xlog_rec_header
   - 从上面找到的head_blk向后遍历
   > xlog_bread(xlog, i, 1, xfs_buf, offset)
   - 找到xlog_rec_header, xlog_rec_header->h_tail_lsn表示xlog的尾
   - 这个h_tail_lsn根据ail决定????
   - 设置xlog->l_prev_block,指向前一个xlog_rec_header
   - l_curr_block 指向当前xlog_rec_header, head_blk,也就是可以写数据的空间.
   - xlog->l_curr_cycle表示当前cycle, 也就是队列每次经过数组边界都要加1. 它使用的是前面有效数据的cycle
   - xlog->l_tail_lsn = xlog_rec_header->h_tail_lsn, 也就是空闲空间的尾
   - xlog->l_last_sync_lsn = xlog_rec_header->h_lsn, 这个应该是最后一个有效块
   - 设置xlog->l_reserve_head->grant (xlog_grant_head), 指向当前的位置(xlog->l_curr_cycle, xlog->l_curr_block), 同样xlog->l_write_head->grant
   - 检查head xlog_rec_header中的xlog数据, 如果是umount操作,就不用recover?
   - xlog_rec_header->h_num_logops == 1, 而且是XLOG_UMOUNT_TRANS
   - 设置xlog->l_tail_lsn = (xlog->l_curr_cycle, head_blk), xlog->l_last_sync_lsn, 也就是(l_curr_cycle,l_curr_block)
   - 最后如果有umount的xlog, head_blk和tail_blk一样.
   - 设置xlog->xfs_mount->m_flags的XFS_MOUNT_WAS_CLEAN

** xlog_find_zeroed(xlog, xfs_daddr_t)
   - 检查xlog里面是cycle=0的block, 也就是没有使用的.

** xlog_add_record(xlog, xfs_caddr_t, cycle, block, tail_cycle, tail_block)
   - xfs_caddr_t指向的内存是一个block?? 
   - 初始化xlog_rec_header
   - magicno, cycle, version=2
   - h_lsn是(cycle, block), h_tail_lsn是(tail_lsn, tail_block)

** xlog_write_log_records(xlog, cycle, start_block, blocks, tail_cycle, tail_block)
   - 写到xlog中数据
   - 准备一个xfs_buf, 大小是blocks. 如果分配失败或者> xlog->l_logBBsize, 减半,但不能< xlog->l_sectBBsize
   > xlog_get_bp(xlog, blocks)
   - 遍历(start_block, blocks), 其中每个block头部都是xlog_rec_header
   - 使用xlog_buf先读取出block? 需要吗??
   > xlog_bread_offset(xlog, align, sectbb, xfs_buf, offset)
   - 初始化每个block的xlog_rec_header, 只有当前的block是变的,其他都不变.
   > xlog_add_record(xlog, offset, cycle, i+j, tail_cycle, tail_block)
   - 写回磁盘
   > xlog_bwrite(xlog, start_block, endcount, xfs_buf)
   - 遍历这些block, 每个头部都是xlog_rec_header, 设置cycle, xfs_lsn_t
   > xlog_add_record(xlog, offset, cycle, i+j, tail_cycle, tail_block)

** xlog_clear_stale_blocks(xlog, xfs_lsn_t tail_lsn)
   - 在写xlog数据时,不能保证完全有序.所以在发生crash时,要清除乱序的磁盘空间.
   - 获取xlog的头和尾的地址 head_cycle/head_block, tail_cycle/tail_block
   - head是根据xlog->l_curr_cycle, l_curr_block
   - 首先计算xlog的空闲空间长度, head_block和tail_block之间的无效数据的距离
   - 如果head_cycle == tail_cycle, head_blk > tail_block
   - head_blk表示需要写数据的开头, 可以说它指向空闲空间, 或者没有有效数据的空间,它前面都是有效数据, head_blk可以说是有效数据的尾,有效数据的头,也就是空间空间的尾,在xlog_rec_header->h_tail_lsn中.
   - tail_distance = tail_block + l_logBBsize - head_block
   - 否则 tail_distance = tail_block - head_block
   - 当然不能把整个xlog空间都写了,只写一个xlog_in_core的范围??
   > XLOG_TOTAL_REC_SHIFT(xlog)
   - XLOG_TOTAL_REC_SHIFT是256k*8, 这是在内存中的log数据长度?? 它和xlog->l_logBBsize什么关系?
   - 设置(head_block, max_distance)之间的block
   - 如果(head_block, max_distance)没有超过xlog->l_logBBsize, 直接设置, 使用head_cycle-1, 下次查找队列边界时,肯定找到这个地方.
   > xlog_write_log_records(xlog, head_cycle-1, head_block, max_distance, tail_cycle, tail_block)
   - 如果超过,分成2部分,
   - 对于尾部的部分使用head_cycle-1, 对于头部部分使用head_cycle.
   > xlog_write_log_records(xlog, head_cycle, 0, distance, tail_cycle, tail_block)
   - 对于l_tail_lsn都是使用参数tail_lsn,这是有效数据的尾/头

** xfs_trans_header
   #+begin_src 
	uint		th_magic;		/* magic number */
	uint		th_type;		/* transaction type */
	__int32_t	th_tid;			/* transaction id (unused) */
	uint		th_num_items;		/* num items logged by trans */
	//在transaction的log的最前头,说明它后面的信息.
   #+end_src

** xlog_recover_item
   #+begin_src 
	struct list_head	ri_list;
	int			ri_type;
	int			ri_cnt;	/* count of regions found */
	int			ri_total;	/* total regions */
	xfs_log_iovec_t		*ri_buf;	/* ptr to regions buffer */   
   #+end_src

** xlog_recover 
   #+begin_src 
	struct hlist_node	r_list;
	xlog_tid_t		r_log_tid;	/* log's transaction id */
	xfs_trans_header_t	r_theader;	/* trans header for partial */
	int			r_state;	/* not needed */
	xfs_lsn_t		r_lsn;		/* xact lsn */
	struct list_head	r_itemq;	/* q for items */   
   #+end_src

** xlog_recover_find_tid(hlist_head, xlog_tid)
   - hlist_head队列是xlog_recover->r_list队列
   - 找一个xlog_recover->r_log_tid == xlog_tid
   - xlog_tid属于一个xlog_op_header, hlist_head只是一个暂时的数据结构.

** xlog_recover_new_tid(hlist_head, xlog_tid, xfs_lsn_t)
   - 创建一个xlog_recover, 设置tid/xfs_lsn_t
   - 把xlog_recover放到hlist_head中

** xlog_recover_add_item(list_head)
   - 创建一个xlog_recover_item
   - 把它xlog_recover_item->ri_list放到参数list_head中

** xlog_recover_add_to_cont_trans(xlog, xlog_recover, xfs_caddr_t, int len)
   - 一个trans的xlog数据可能分成多份,使用xlog_recover_item缓存起来,一块处理.
   - 这里要把(xfs_caddr_t,len)的数据给xlog_recover_item
   - 但一个trans数据包包括2部分,头部是xfs_trans_header,后面是数据.每一份数据都使用xlog_op_header包装.
   - 如果xlog_recover->r_itemq是空,给它补充xlog_recover_item
   > xlog_recover_add_item(xlog_recover->r_itemq)
   - 数据是xlog_trans_header, 给xlog_recover->xlog_trans_header
   - 否则把数据给xlog_recover->r_itemq队列上最后一个xlog_recover_item
   - xlog_recover_item->xfs_log_iovec保存数据,这里使用xlog_recover_item->xfs_log_iovec[xlog_recover_item->ri_cnt-1]
   - 重新给它分配内存,扩大它的长度

** xlog_recover_add_to_trans(xlog, xlog_recover, xfs_caddr_t, len)
   - 这个函数和上面有什么差别?? 
   - 如果xlog_recover->r_itemq是空, 需要新的xlog_recover_item索引数据
   - 这里len不能超过sizeof(xfs_trans_header), xfs_trans_header会单独包装??
   - 如果len == sizeof(xfs_trans_header),需要为后面分配xlog_recover_item
   > xlog_recover_add_item(xlog_recover->r_itemq)
   - 把数据复制给xlog_recover->xfs_trans_header. 可能len不够,下次复制.
   - 如果xlog_recover->r_itemq不是空,已经有xfs_trans_header
   - 先检查是否需要创建新的xlog_recover_item
   - 最后一个xlog_recover_item->ri_total !=0, 而且ri_cnt == ri_total, 最后一个正在使用.
   - 如果最后一个在使用,创建新的xlog_recover_item
   > xlog_recover_add_item(xlog_recover->r_itemq)
   - 如果新创建xlog_recover_item, 分配xfs_log_iovec指针数组
   - 参数指向的数据头部是xlog_inode_log_format, 为什么出来这个???
   - xlog_recover_item->ri_total = xfs_inode_log_format->ilf_size, 创建xfs_log_iovec数组
   - 使用xfs_log_iovec索引参数(xfs_caddr_t, len)
   - 这里和上一个函数区别是它不会重复使用xfs_log_iovec,而且创建新的xlog_recover_item

** xlog_recover_reorder_trans(xlog, xlog_recover, int pass)
   - 排序xlog_recover->r_itemq上的xlog_recover_item. 
   - 把非cancelled的buf的xlog_recover_item放到最前面
   - xlog_recover_item的第一个xfs_log_iovec中说明这个xlog_recover_item中数据的格式, 但没有一个公共的头部. 应该是所有的数据结构都有共同的数据成员, 也就是第一个type
   > ITEM_TYPE(xlog_recover_item)
   - 如果是XFS_LI_BFS, 它是xfs_buf_log_format, 如果xfs_buf_log_format->blf_flags & XFS_BLF_CANCEL ==0, 把它放到链表头
   - 其他的XFS_LI_INODE/XFS_LI_DQUOT/XFS_LI_EFD/XFS_EFI都放到最后.
   - 因为在第2阶段处理xfs_buf_log_format时,对于非cancelled的,先检查它是否有对应的cancelled的,就不用处理. 对于cancelled的, 只要删除它在hash表中的项. 所以先处理非cancel的

** xfs_buf_cancel
   #+begin_src 
	xfs_daddr_t		bc_blkno;
	uint			bc_len;
	int			bc_refcount;
	struct list_head	bc_list;
	//在log recover过程中,管理xfs_buf_log_item??
   #+end_src
   
** xlog_recover_buffer_pass1(xlog, xlog_recover_item)
   - 处理xlog_recover_item, 它里面是xfs_buf_log_format, 只处理XFS_BLF_CANCEL类型的
   - xlog_recover_item->xfs_log_iovec[0]的数据是xfs_buf_log_format
   - xfs_buf_log_format->blf_flags & XFS_BLF_CANCEL ==0, 直接返回
   - xlog->l_buf_cancel_table是hash表,根据xlog_recover_item创建xfs_buf_cancel, 添加到hash表中
   - 首先查找是否已经存在,比较xfs_buf_cancel->bc_blkno 和 xfs_buf_log_format->blf_blkno, bc_len
   - 如果有, xfs_buf_cancel->bc_refcount ++
   - 如果没有,创建一个xfs_buf_cancel, 添加到队列中

** xlog_check_buffer_cancelled(xlog, xfs_daddr_t, uint len, ushort flags)
   - 根据(xfs_daddr_t, len)查找xfs_buf_cancel.
   - 如果找到,而且参数flags & XFS_BLF_CANCEL !=0), --xfs_buf_cancel->bc_refcount,  如果减为0,释放它.
   - 如果找到返回1, 否则返回0
   - 在处理xfs_buf_log_format是,会检查它是否需要删除. 如果要删除,就不再继续. 对于要cancelled buf log, 就释放它在hash列表中的索引,保证最后数据的一致性.

** xfs_buf_log_format 
   #+begin_src 
	unsigned short	blf_type;	/* buf log item type indicator */
	unsigned short	blf_size;	/* size of this item */
	ushort		blf_flags;	/* misc state */
	ushort		blf_len;	/* number of blocks in this buf */
	__int64_t	blf_blkno;	/* starting blkno of this buf */
	unsigned int	blf_map_size;	/* used size of data bitmap in words */
	unsigned int	blf_data_map[XFS_BLF_DATAMAP_SIZE]; /* dirty bitmap */
        //这个数据结构表示一个buf的修改方式,具体修改数据在后面. (blf_blkno, blf_len)表示buf的磁盘位置??
        //blf_data_map是一个位图,每一位表示128byte.
        //bitmap中连续的设置区域,对应一个xfs_log_iovec, 数据一块存放.
   #+end_src

** xlog_recover_do_inode_buffer(xfs_mount, xlog_recover_item, xfs_buf, xfs_buf_log_format)
   - recovery的block里面是inode,这里仅仅recover di_next_unlinked
   - 设置xfs_buf->b_ops = xfs_inode_buf_ops
   - xfs_buf中inode的数量 inodes_per_buf = xfs_buf->b_io_length >> xfs_mount->sb_inodelog (xfs_mount->sb_inodesize)
   - 遍历xfs_buf中的xfs_inode, 检查xfs_inode->di_next_unlinked的位置是否在位图中标记出来
   - 如果它在buf中的偏移被位图设置,去对应的xfs_log_iovec中取出数据
   - 使用它更新xfs_buf中对应的数据
   - 这里有2份这样的数据, xfs_buf是完整连续的,对应磁盘数据. xlog_recover_item对应xlog的数据,离散的.

** xfs_da_blkinfo
   #+begin_src 
	__be32		forw;			/* previous block in list */
	__be32		back;			/* following block in list */
	__be16		magic;			/* validity check on block */
	__be16		pad;			/* unused */   
   #+end_src

** xlog_recover_do_reg_buffer(xfs_mount, xlog_recover_item, xfs_buf, xfs_buf_log_format)
   - 把xlog_reciver_item中的数据给xfs_buf. xlog_recover_item中是数据, xfs_buf_log_format里面说明数据的对应关系
   - 查找xlog_buf_log_format->blf_data_map中连续有效的bit位, 它对应一个计算xlog_recover_item->xfs_log_iovec
   - 把数据复制给xfs_buf.
   - xfs_buf的偏移是xfs_buf_log_format->blf_blkno + 位图偏移

** xlog_recover_buffer_pass2(xlog, list_head buffer_list, xlog_recover_item item)
   - xlog中有2中buffer, 一种是普通的,一种是inode使用的.
   - XFS_BLF_CANCEL表示buffer删除, 不需要recover他们,因为它可能被用于其他用途.
   - xlog的recover过程分成2步,第一步是统计cancel的buf, 第二步recover数据时, 跳过cancel的buf.
   - 处理xlog_recover_item的数据, 首先检查它要recover的数据是否在cancel中.
   - 获取xfs_buf_log_format, 它是xlog_recover_item->xfs_log_iovec[0]中, 它决定了recover的地址空间
   > xlog_check_buffer_cancelled(xlog, xfs_buf_log_format->blf_blkno, xfs_buf_log_format->blk_len, xfs_buf_log_format->blf_flags)
   - 如果没有覆盖,继续recover
   - 如果xfs_buf_log_format->blf_flags有XFS_BLF_INODE_BUF标志, 下面构造的xfs_buf使用XBF_UNMAPPED标志, 分配xfs_buf以及page后不用建立映射关系.
   - 先把原始数据读上来, 这里使用的xfs_buf是在xfs_perag中缓存的,没有使用buf_head或address_space
   > xfs_buf_read(xfs_mount->m_ddev_targp, xfs_buf_log_format->blf_blkno, xfs_buf_log_format->blk_len, buf_flags, NULL)
   - 检查xfs_buf_log_format->blf_flags, 不同的log使用不同的方式
   - 如果是XFS_BLF_INODE_BUF, 只处理unlink??
   > xlog_recover_do_inode_buffer(xfs_mount, xlog_recover_item, xfs_buf, xfs_buf_log_format)
   - 对应普通的
   > xlog_recover_do_reg_buffer(xfs_mount, xlog_recover_item, xfs_buf, xfs_buf_log_format)
   - 把修改后的xfs_buf写回磁盘, 尽量使用delayed write
   - 对于inode使用的buffer, 如果大小不是标准的,必须写回磁盘
   - xfs_buf开头是XFS_DINODE_MAGIC, xfs_buf->b_io_length != xfs_sb->sb_blocksize
   > MAX(xlog->xfs_mount->xfs_super->sb_blocksize, XFS_INODE_CLUSTER_SIZE(xlog->xfs_mount))
   - 为什么设为stale?? 应该是把它从lru队列中删除!
   > xfs_buf_stale(xfs_buf)
   - 写回数据
   > xfs_bwrite(xfs_buf)
   - 否则可以延时写回, 缓存在内存中.
   - 设置回调函数 xfs_buf->b_iodone = xlog_recover_iodone 
   - 提交到参数提供的队列, 设置_XBF_DELWRI_Q
   > xfs_buf_delwri_submit_nowait(xfs_buf, buffer_list)

** xlog_recover_inode_pass2(xlog, list_head, xlog_recover_item)
   - xlog_recover_item是inode的xlog, 它不使用xfs_log_buf_format, 而是xfs_inode_log_format
   - 如果xlog_recover_item->xfs_log_iovec[0]->i_len == sizeof(xfs_inode_log_format), 他就可以直接使用, 否则需要包装一下?? 
   - 创建一个xfs_inode_log_format, 是不是有32/64的区别??
   > xfs_inode_item_format_convert(xfs_log_iovec, xfs_inode_log_format)
   - 检查inode使用的buffer是否要释放
   > xlog_check_buffer_cancelled(xlog, xfs_inode_log_format->ilf_blkno, ilf_len, 0)
   - 如果不释放,修改数据
   - 先读数据, 直接设定xfs_buf->b_ops???
   > xfs_buf_read(xfs_mount->m_ddev_targp, xfs_inode_log_format->ilf_blkno, ilf_len, 0, xfs_inode_buf_ops)
   - xfs_inode_log_format->ilf_boffset是buffer的内部偏移,它是相对于ilf_blkno的偏移
   - 获取xfs_buf中的xfs_dinode位置
   > xfs_buf_offset(xfs_buf, xfs_inode_log_format->ilf_boffset)
   - 检查xfs_dinode->di_magic == XFS_DINODE_MAGIC
   - 从xlog_recover_item中取出xfs_icdinode, 它就是xlog_recover_item->xfs_log_iovec[1], 0是xfs_inode_log_format
   - 比较xfs_dinode->di_flushiter和xfs_icdinode->di_flushiter,如果xfs_buf的大,不用再更新
   - 检查xfs_icdinode的有效性, di_mode/di_format
   - 最后计算xfs_icdinode的数据长度
   > xfs_icdinode_size(xfs_icdinode->di_version)
   - 把xfs_icdinode给xfs_dinode
   > xfs_dinode_to_disk(xfs_dinode, xfs_icdinode)
   - 后面是ifork数据
   - 第3个xfs_log_iovec是attr数据
   - 把xfs_buf写回磁盘, 设置xfs_buf->b_iodone是xlog_recover_iodone
   - 这个回调函数只会检查结果,继续xfs_buf其他的回调函数.
   > xfs_buf_delwri_queue(xfs_buf, buffer_list)

** xlog_recover_quotaoff_pass1(xlog, xlog_recover_item)

** xfs_efi_log_format
   #+begin_src 
	__uint16_t		efi_type;	/* efi log item type */XFS_LI_EFI
	__uint16_t		efi_size;	/* size of this item */ 一直为1
	__uint32_t		efi_nextents;	/* # extents to free */
	__uint64_t		efi_id;		/* efi identifier */ //就是外层xfs_efi_log_item指针
	xfs_extent_t		efi_extents[1];	/* array of extents to free */        //里面包括extent的信息. 
   #+end_src

** xfs_efi_log_item
   #+begin_src 
	xfs_log_item_t		efi_item;
	atomic_t		efi_next_extent;
	unsigned long		efi_flags;	/* misc flags */
	xfs_efi_log_format_t	efi_format;   
        //xfs_efi_log_format保存efi的信息,就是一个简单的数组. 在xlog中被xlog_record_header包装, 在recovery中,使用xfs_log_iovec包装,在ail中,被xfs_efi_log_item包装.
   #+end_src

** xlog_recover_efi_pass2(xlog, xlog_recover_item, xfs_lsn_t)
   - 处理extent free intent item, efi, 从xlog_recover_item放到xfs_efi_log_item中.
   - xlog_recover_item->xfs_log_iovec[0]是xfs_efi_log_format
   - 创建xfs_efi_log_item
   > xfs_efi_init(xfs_mount, xfs_efi_log_format->efi_nextents)
   - 把xfs_efi_log_format的数据给xfs_efi_log_item->efi_format, 可能会转换32/64数据
   > xfs_efi_copy_format(xfs_log_iovec, xfs_efi_log_item->xfs_efi_log_format)
   - 把xfs_efi_log_item->xfs_log_item给xfs_trans.
   - 如果xfs_log_item已经在xfs_ail中,只有xfs_lsn_t大,才会填加.
   > xfs_trans_ail_update(xlog->xfs_ail, xfs_efi_log_item->xfs_log_item, xfs_lsn_t)

** xlog_recover_efd_pass2(xlog, xlog_recover_item)
   - efd是extent free done, 和efi对应.
   - 在efi中查找对应的efi, 删除对应的xfs_efi_log_item
   - 获取xfs_efd_log_format, xlog_recover_item->xfs_log_iovec[0]
   - 先找到它对应xfs_efi_log_item, 根据id, xfs_efd_log_format->efd_efi_id.
   - 遍历xfs_ail, 查找对应的xfs_log_item
   - 找一个最小的xfs_log_item
   - xfs_trans_ail_cursor_first(xfs_ail, xfs_ail_cursor, 0)
   - 挑选xfs_log_item
   - xfs_log_item->li_type == XFS_LI_EFI , xfs_efi_log_item->xfs_efi_log_format->efi_id == efi_id
   - 找到之后,删除它
   > xfs_trans_ail_delete(xfs_ail, xfs_efi_log_item, SHUTDOWN_CORRUPT_INCORE)
   - 释放xfs_efi_log_item
   > xfs_efi_item_free(xfs_efi_log_item)

** xlog_recover_free_trans(xlog_recover)
   - 释放xlog_recover, 以及它管理的xlog_recover_item
   - 首先遍历xlog_recover->r_itemq, 对每个xlog_recover_item
   - 释放它的xfs_log_iovec使用的内存
   
** xlog_recover_commit_pass1(xlog, xlog_recover, xlog_recover_item)
   - 处理xlog中的数据, commit表示把它提交到文件系统的数据区.
   - 检查xlog_recover_item的类型
   > ITEM_TYPE(xlog_recover_item)
   - 如果是XFS_LI_BUF, 只处理XFS_BLF_CANCEL的xfs_buf_log_format
   - 建立xlog->l_buf_cancel_table中的hash表
   > xlog_recover_buffer_pass1（xlog, xlog_recover_item)
   - 对于其他的XFS_LI_INODE/EFI/EFD/DQUOT什么也不做

** xfs_buf_log_format
   #+begin_src 
	unsigned short	blf_type;	/* buf log item type indicator */
	unsigned short	blf_size;	/* size of this item */ //表示xfs_log_iovec的数量
	ushort		blf_flags;	/* misc state */ //普通的buf,还是inode使用的
	ushort		blf_len;	/* number of blocks in this buf */
	__int64_t	blf_blkno;	/* starting blkno of this buf */
	unsigned int	blf_map_size;	/* used size of data bitmap in words */
	unsigned int	blf_data_map[XFS_BLF_DATAMAP_SIZE]; /* dirty bitmap */   
   #+end_src

** xlog_recover_commit_pass2(xlog, xlog_recover, list_head, xlog_recover_item)
   - 和上面一样,不同的类型使用上面不同的函数
   - xlog_recover_item的区别使用第一个xfs_log_iovec中的数据. 为何不用xlog_recover_item->ri_type?
   - 当然里面有各种xfs_*_log_format, 但第一个成员表示类型
   > ITEM_TYPE(xlog_recover_item)
   - 如果是XFS_LI_BUF, buf log有2中,一种是inode使用的buffer,另一种是普通的.
   - 对于inode使用的buf, 仅仅恢复unlink链表.
   - xlog_recover_buffer_pass2(xlog, list_head, xlog_recover_item)
   - 如果是XFS_LI_INODE, 恢复inode数据
   > xlog_recover_inode_pass2(xlog, buffer_list, xlog_recover_item)
   - 对于上面2中,都需要写回xfs_buf, 使用buffer_list缓存写会.
   - 如果是XFS_LI_EFI, 建立对应的ail的xfs_efi_log_item
   > xlog_recover_efi_pass2(xlog, xlog_recover_item, xfs_lsn_t)
   - 如果是XFS_LI_EFD, 释放对应的ail中的xfs_efi_log_item
   > xlog_recover_efd_pass2(xlog, xlog_recover_item)
   - 不看quota相关的东西.

** xlog_recover_commit_trans(xlog, xlog_recover, pass)
   - 处理xfs_trans->r_itemq中的xlog_recover_item.  pass有2中情况,对应recover的2个阶段
   - 首先调整顺序, 2次都调整?? 把不是cancelled的xfs_buf_log_format放到前面,其他放到后面.
   > xlog_recover_reorder_trans(xlog, xfs_trans, pass)
   - 如果pass是XLOG_RECOVER_PASS1, 建立xlog的cancelled xfs_buf的hash表.
   > xlog_recover_commit_trans_pass1(xlog, xlog_trans, xlog_recover_item)
   - 最后释放trans, 每次调用都会重新创建??
   > xlog_recover_free_trans(xfs_trans)
   - 写回list_head,里面是xfs_buf, 里面会检查pin???
   > xfs_buf_delwri_submit(list_head)

** xlog_recover_unmount_trans(xlog, xlog_recover)
   - 什么都不做

** xlog_recover_process_data(xlog, hlist_head, xlog_rec_header, xfs_caddr_t dp, int pass)
   - 处理一个xlog_rec_header, 数据范围是(dp, xlog_rec_header->h_len)
   - 里面有若干个xlog_op_header, xlog_rec_header->h_num_logops
   - 检查xlog_rec_header是否有效, uuid/magic/h_fmt
   > xlog_header_check_recover(xfs_mount, xlog_rec_header)
   - dp指向xlog数据, 数据长度是xlog_rec_header->l_len, xlog单位是xlog_op_header, xlog数量是xlog_rec_header->h_num_logops
   - 遍历这些xlog_op_header
   - 验证xlog_op_header->oh_clientid必须是XFS_TRANSACTION或XFS_LOG
   - xlog_op_header->oh_tid表示什么?? 对应xlog->recover->r_log_tid
   - 使用它查找xlog_op_header对应的xlog_recover. 
   > xlog_recover_find_tid(hlist_head, tid)
   - 参数hlist_head是hash表,hash索引根据oh_tid计算
   - 如果找不到, 而且xlog_op_header->oh_flags & XLOG_START_TRANS !=0, 创建一个新的. 开始trans.
   > xlog_recover_new_tid(hlist_head, xlog_oh_header->oh_tid, xfs_lsn_t)
   - 如果找到, 可能需要结束这个transaction,也可能合并数据
   - 检查xlog_op_header->oh_flags & ~ XLOG_END_TRANS
   - 对于XLOG_COMMIT_TRANS, 说明这个log已经提交, 可以完全recover xlog_recover..
   > xlog_recover_commit_trans(xlog, xfs_trans, pass)
   - 对于XLOG_UNMOUNT_TRANS
   > xlog_recover_unmount_trans(xlog, xfs_trans)
   - 对于XLOG_WAS_CONT_TRANS, xlog_op_header指向的log数据分成多份,集中到一个xlog_recover
   > xlog_recover_add_to_cont_trans(xlog, xlog_recover, xfs_caddr_t, xlog_op_header->oh_len)
   - 对于XLOG_START_TRANS, 这是错误的处理!!因为它应该是找不到对应的xlog_recover.
   - 对于XLOG_CONTINUE_TRANS/XLOG_END_TRANS, 同样合并
   > xlog_recover_add_to_trans(xlog, xfs_trans, xfs_caddr_t, xlog_op_header->oh_len)
   - 对于一个xlog, XLOG_START_TRANS和XLOG_COMMIT_TRANS应该是对应的
   - XLOG_CONTINUE_TRANS和XLOG_WAS_CONT_TRANS类似,但后者会合并数据到同一个xfs_log_iovec, 前者不会,但可能会创建新的xlog_recover_item.
   
** xfs_extent 
   #+begin_src 
	xfs_dfsbno_t	ext_start;
	xfs_extlen_t	ext_len;   
   #+end_src

** xlog_recover_process_efi(xfs_mount, xfs_efi_log_item)
   - recover xfs_efi_log_item, 在recover结束时,清除没有释放完成的efi. 释放extent必须有对应的efd, 这里需要创建对应的efd, 写到xlog中.
   - 首先检查xfs_efi_log_item的数据是否正确, 也就是xfs_efi_log_item->xfs_efi_log_format->efi_nextents数组里面的xfs_extent
   - 检查xfs_extent
   - xfs_extent->ext_start是组合地址,(agno,agbno), 转化为绝对地址, 检查是否超过文件系统大小
   > XFS_BB_TO_FSB(xfs_mount, XFS_FSB_TO_DADDR(xfs_mount, xfs_extent->ext_start))
   - startblock_fsb == 0, xfs_extent->ext_len == 0, xfs_extent->ext_len >= xfs_sb->sb_agblocks
   - 如果上面条件满足, 设置xfs_efi_log_item->efi_flags的XFS_EFI_RECOVERED, 释放释放它
   > xfs_efi_release(xfs_efi_log_item, xfs_extent)
   - 而且返回错误EIO
   - 如果没有问题, 创建xfs_trans 
   > xfs_trans_alloc(xfs_mount, 0)
   - 预留空间, 为何使用一个truncate? 现在为何要预留log空间?? 
   - logcount =0, 表示只用1个 xlog_ticket->t_cnt
   - xlog的预留空间使用xlog->l_tail_lsn和xlog->l_reserve_head.但这个分配同样增长xlog->l_write_head?
   > xfs_trans_reserve(xfs_trans, 0, XFS_ITRUNCATE_LOG_RES(xfs_mount), 0, 0, 0)
   - 构造对应的xfs_efd_log_item
   > xfs_trans_get_efd(xfs_trans, xfs_efi_log_item, xfs_efi_log_item->xfs_efi_log_format->efi_nextents)
   - 遍历这些xfs_extent,释放空间
   > xfs_free_extent(xfs_trans, xfs_extent->ext_start, xfs_extent->ext_len)
   - 填充xfs_efd_log_item->xfs_efd_log_format->xfs_extent数组
   > xfs_trans_log_efd_extent(xfs_trans, xfs_efd_log_item, xfs_extent->ext_start, xfs_extent->ext_)
   - 设置xfs_efi_log_item->efi_flags的XFS_EFI_RECOVERED, 
   - 提交transacton, 把这些信息写到xlog中,表示extent free item操作完成.
   > xfs_trans_commit(xfs_trans, 0)

** xlog_recover_process_efis(xlog)
   - 遍历xlog->xfs_ail里面的xfs_log_item
   > xfs_trans_ail_cursor_first(xfs_ail, xfs_ail_cursor, 0)
   > xfs_trans_ail_cursor_next(xfs_ail, xfs_ail_cursor)
   - 处理xfs_log_item, 检查li_type != XFS_LI_EFI, 直接退出.
   - 如果xfs_efi_log_item->efi_flags包含XFS_EFI_RECOVERED, 跳过
   > xlog_recover_process_efi(xfs_mount, xfs_efi_log_item)
   - 一个efi使用一个transaction..

** xlog_recover_clear_agi_bucket(xfs_mount, xfs_agnumber_t, bucket)
   - 处理xfs_agi->agi_unlinked[bucket]指针. 这是unlink链表已经清空,所以设置这个hash链表头为NULLAGINO
   - 创建xfs_trans, recovery操作也使用xfs_trans包装起来.
   > xfs_trans_alloc(xfs_mount, XFS_TRANS_CLEAR_AGI_BUCKET)
   - 预留空间
   > xfs_trans_reserve(xfs_trans, 0, XFS_CLEAR_AGI_BUCKET_LOG_RES(xfs_mount), 0, 0, 0)
   - 读取xfs_ag的xfs_agi
   > xfs_read_agi(xfs_mount, xfs_trans, agno, xfs_buf)
   - XFS_BUF_TO_AGI(xfs_buf)
   - 设置xfs_agi->agi_unlinked[bucket] = NULLAGINO
   - 虽然修改了磁盘,但这里没有直接写回去, 操作xfs_buf->b_fspriv, 也就是xfs_buf_log_item
   - 在xfs_buf_log_format的位图中标注出来
   > xfs_trans_log_buf(xfs_trans, xfs_agi, offset, offset + sizeof(xfs_agino_t)-1)
   - 提交transaction
   > xfs_trans_commit(xfs_trans, 0)

** xlog_recover_process_one_iunlink(xfs_mount, xfs_agnumber_t, xfs_agino_t, int bucket)
   - 处理unlink操作, 但这里仅仅获取xfs_dinode->di_next_unlinked
   - 使用xfs_agnumber/xfs_agino计算ino
   > XFS_AGINO_TO_INO(xfs_mount, agno, agino)
   - 根据ino获取xfs_inode
   > xfs_iget(xfs_mount, NULL, ino, 0, 0, xfs_inode)
   - 获取它在磁盘上的xfs_buf
   > xfs_imap_to_bp(xfs_mount, NULL, xfs_inode->i_imap, xfs_dinode, xfs_buf, 0, 0)
   - xfs_dinode->di_nlink必须 ==0 
   - 释放xfs_buf
   > xfs_buf_relse(xfs_buf)
   - 释放xfs_inode, 这里只释放inode使用计数  iput(inode)
   > IRELE(xfs_inode)
   - 返回xfs_dinode->di_next_unlinked
   - 这里没看到任务inode的删除动作???

** xlog_recover_process_iunlinks(xlog)
   - 遍历所有的xfs_ag, 处理它的unlink列表
   - xfs_mount->xfs_sb->sb_agcount表示ag数量
   - 首先获取对应的ag对应的xfs_buf
   > xfs_read_agi(xfs_mount, NULL, agno, xfs_buf)
   - 然后是xfs_agi
   > XFS_BUF_TO_AGI(xfs_buf)
   - 遍历xfs_agi->agi_unlinked队列, 一共有XFS_AGI_UNLINKED_BUCKETS个
   - xlog_recover_process_one_iunlink(agno, agino, bucket)

** xlog_unpack_data_crc(xlog_rec_header, xfs_caddr_t, xlog)
   - 验证xlog的crc
   > xlog_cksum(xlog, xlog_rec_header, xfs_caddr_t, xlog_rec_header->h_len)
   - 结果和xlog_rec_header->h_crc比较

** xlog_unpack_data(xlog_rec_header, xfs_caddr_t, xlog)
   - 首先验证crc
   > xlog_unpack_data_crc(xlog_rec_header, xfs_caddr_t, xlog)
   - dp指向xlog中的buf, 而且是block对齐的.
   - 设置每个block开头的cycle, 为xlog_rec_header->h_cycle_data[i]
   - 对于扩展的情况, xlog_in_core2[i]->xlog_rec_ext_header->xh_cycle_data[k]
   - 对于扩展情况,就是2维数组,低维是XLOG_HEADER_CYCLE_SIZE/BBSIZE=64
   - 高维是xlog_rec_header->h_len / 64

** xlog_valid_rec_header(xlog, xlog_rec_header, xfs_daddr_t blkno)
   - 验证xlog_rec_header->h_magicno 必须是XLOG_HEADER_MAGIC_NUM
   - 检查xlog_rec_header->h_len 不能超过INT_MAX
   - xfs_daddr_t不能超过xlog->l_logBBsize, 它应该是xlog的内部偏移

** xlog_do_recovery_pass(xlog, xfs_daddr_t head_blk, xfs_daddr_t tail_blk, pass)
   - 处理(tail_blk, head_blk)之间的xlog_rec_header
   - 如果xlog_in_core大小是固定的,每次读回的数据就是XLOG_BIG_RECORD_BSIZE
   - 对于logv2, 每个xlog_rec_header的大小由xlog_in_core决定, 先使用一个xfs_buf读取xlog_rec_header, 获取一个xlog_rec_header
   - xlog_rec_header->h_size就是xlog_in_core的大小.
   - 准备一个block的xfs_buf 
   > xlog_get_bp(xlog, 1)
   - 读回tail_blk对应的xlog_rec_header
   > xlog_valid_rec_header(xlog, xlog_rec_header, tail_blk)
   - 获取xlog_rec_header->h_size, 计算每次读回的数量是  xlog_rec_header->h_size / XLOG_HEADER_CYCLE_SIZE.. 
   - 貌似一部分头,后面是数据. 这里只是计算合理的xfs_buf的大小, 或者一个xlog_rec_header的header的block数量
   - 准备xfs_buf 
   > xlog_get_bp(xlog, BTOBB(h_size))
   - 准备一个hash队列,保存xlog_recover, 一个xlog_recover对应一个xlog_op_header, 或许也是一个transaction
   - 如果tail_blk <= head_blk, 没有跨循环队列的边界, 开始循环扫描
   - 先读头部, hblks表示头部的block
   > xlog_bread(xlog, blk_no, hblks, xfs_buf, offset)
   - 验证数据头xlog_rec_header 
   > xlog_valid_rec_header(xlog, xlog_rec_header, blk_no)
   - 根据xlog_rec_header->h_len读取xlog的block
   > xlog_bread(xlog, blk_no + hblks, xlog_rec_header->h_len, xfs_buf, offset)
   - 解数据包, 设置cycle
   > xlog_unpack_data(xlog_rec_header, offset, xlog)
   - 处理这个xlog_rec_header
   > xlog_recover_process_data(xlog, hlist_head, xlog_rec_header, offset, pass)
   - 每个xlog_rec_header有分成多个xlog_op_header. xlog_op_header只是包装了数据流,这些数据包是根据transaction包装的, 没有和xlog_recovery_item一一对应.
   - 数据流又分成xfs_*_log_format, 这些是连续的.
   - 可能会有多个transaction同时向xlog中写数据?? 但一个transaction的数据流分成多个xfs_*_log_format. 每个的格式或大小都是确定的
   - 如果blk_tail > blk_head, 要分成2部分,先处理队列尾部,再拐回来.

** xlog_do_log_recovery(xlog, xfs_daddr_t head_blk, xfs_daddr_t tail_blk)
   - xlog recover分2个过程,首先找出concel的log, 放到xlog->l_buf_cancel_table中 
   - 构造hash列表, 大小是XLOG_BC_TABLE_SIZE
   - 收集cancelled buf信息
   > xlog_do_recovery_pass(xlog, head_blk, tail_blk, XLOG_RECOVER_PASS1)
   - 然后第2个过程
   > xlog_do_recovery_pass(xlog, head_blk, tail_blk, XLOG_RECOVER_PASS2)

** xlog_do_recover(xlog, xfs_daddr_t head_blk, tail_blk)
   - recover xlog, 然后更新xfs_sb
   > xlog_do_log_recovery(xlog, head_blk, tail_blk)
   - 设置xlog->l_tail_lsn
   - 它会根据ail设置, 但这时可能没有,使用xlog->l_last_sync_lsn.
   - 它是在查找时发现的最后一个正确的xlog_rec_header的.
   > xlog_assign_tail_lsn(xfs_mount)
   - 更新xfs_sb
   - 读取第一个xfs_sb
   > xfs_getsb(xfs_mount, 0)
   - 去掉XFS_DONE标志
   > XFS_BUF_UNDONE(xfs_buf)
   - 设置XFS_READ, 去掉XFS_SYNC??
   > xfsbdstrat(xfs_mount, xfs_buf)
   - 等待读完成
   > xfs_buf_iowait(xfs_buf)
   - 把磁盘的xfs_sb, 给xfs_mount->xfs_sb
   > xfs_sb_from_disk(xfs_sb, xfs_dsb)
   - 重新设置一些percpu参数
   > xlog_recover_check_summary(xlog)
   - 去掉xlog->l_flags的XLOG_ACTIVE_RECOVEY
   - xfs_sb的buf可能会修改??? 所以重新读出来.

** xlog_recover(xlog)
   - 包装上面的函数,主要是找到头和尾
   > xlog_find_tail(xlog, head_blk, tail_blk)
   - 如果head_blk == tail_blk, 不用recover
   - 否则执行recover操作
   > xlog_do_recover(xlog, head_blk, tail_blk)
   - 最后添加xlog->l_flags的XLOG_RECOVERY_NEEDED标志, 在mount操作完成后清除recover中用的信息.

** xlog_recover_finish(xlog)
   - 这里处理extent free item和unlink inode
   - 首先xlog->l_flags & XLOG_RECOVER_NEEDED !=0, 才做这些操作
   - 首先efi
   > xlog_recover_process_efis(xlog)
   - 写回数据
   > xfs_log_force(xlog_mount, XFS_LOG_SYNC)
   - 然后是unlink
   > xlog_recover_process_unlinks(xlog)
   - 最后检查xfs_agl和xfs_agi
   > xlog_recover_check_summary(xlog)
   - 最后清除xlog->l_flags的XLOG_RECOVER_NEEDED标致
* xfs_trans_resv.c
  - 计算各种操作需要reserve的磁盘空间??

** xfs_buf_log_overhead(void)
   - 在log磁盘reserve空间,给xfs_log_item? 需要使用128对齐
   - sizeof(xlog_op_header) + sizeof(xfs_buf_log_format)

** xfs_calc_buf_res(nbufs, size)
   - 计算log buf需要的reserve?
   - 每个buf还需要一个头, 是否对应xfs_log_iovec
   - nbufs * (size + xfs_buf_log_overhead())

** xfs_calc_inode_res(xfs_mount, ninodes)
   - log整个xfs_dinode? 每个inode需要准备空间存储:
   - log op header
   - xfs_inode_log_format, xfs_dinode的位置信息
   - xfs_sb->sb_inodesize
   - 2个btree根结点的信息? 为何不在sb_inodesize里面?

** xfs_calc_write_reservation(xfs_mount)
   - 为何写操作可能会创建2个extent? 需要准备空间存储:
   - inode? 可能会修改size,time
   > xfs_calc_inode_res(xfs_mount, 1)
   - data fork中的 bmap btree
   > xfs_calc_buf_res(XFS_BM_MAXLEVELS(xfs_mount, XFS_DATA_FORK), 1)
   - 修改2次xfs_agf和xfs_sb
   > xfs_calc_buf_res(3, xfs_sb->sb_sectsize)
   - 修改2个btree, 对应blk,cnt, 而且会分配2个? 
   > xfs_calc_buf_res(XFS_ALLOCFREE_LOG_COUNT(xfs_mount, 2), 1)
   - 上面是分配,还需要为xfs_bmap_finish的transaction reserve空间
   - 2次xfs_agf和xfs_agfl?, 一次xfs_sb
   > xfs_calc_buf_res(5, xfs_sb->sb_sectsize)
   - 对应btree操作
   > xfs_calc_buf_res(XFS_ALLOCFREE_LOG_COUNT(xfs_mount, 2), XFS_FSB_TO_B(xfs_mount, 1))
   - 只需要使用分配和释放的最大值

** xfs_calc_itruncate_reservation(xfs_mount)
   - 可能xfs_transaction限制,最多操作2个extent?!
   - 在操作之前,需要reserve空间准备
   - inode的空间 
   > xfs_calc_inode_res(xfs_mount, 1)
   - inode的bmap操作  
   > xfs_calc_buf_res(XFS_BM_MAXLEVELS(xfs_mount, XFS_DATA_FORK) + 1, XFS_FSB_TO_B(xfs_mount, 1))
   - 在操作完成, 还需要为xfs_bmap_finish reserve空间
   - 4个xfs_agf/xfs_agfl?? 还有1个xfs_sb 
   > xfs_calc_buf_res(9, xfs_sb->sb_sectsize)
   - 在bmap操作中,每次可能会修改2次btree?? 
   > xfs_calc_buf_res(XFS_ALLOCFREE_LOG_COUNT(xfs_mount, 4), XFS_FSB_TO_B(xfs_mount, 1))
   - 这里会有5个xfs_log_item?
   > xfs_calc_buf_res(5, 0)
   - inode分配的btree也会修改? 
   > xfs_calc_buf_res(XFS_ALLOCFREE_LOG_COUNT(xfs_mount, 1), XFS_FSB_TO_B(xfs_mount, 1))
   - 2次修改alloc btree
   > xfs_calc_buf_res(2 + XFS_IALLOC_BLOCKS(xfs_mount) + xfs_mount->m_in_maxlevels, 0)

** xfs_calc_rename_reservation(xfs_mount)
   - 4个inode使用的空间 
   > xfs_calc_inode_res(xfs_mount, 4)
   - 2次directory btree的修改  
   > xfs_calc_buf_res(2 * XFS_DIROP_LOG_COUNT(xfs_mount), XFS_FSB_TO_B(xfs_mount, 1))
   - 然后是xfs_bmap_finish释放block使用的空间, 释放什么?
   - 3个xfs_agf/xfs_agfl? xfs_sb 
   > xfs_calc_buf_res(7, xfs_sb->sb_sectsize)
   - 为何还会分配空间? 而且分配3次
   > xfs_calc_buf_res(XFS_ALLOCFREE_LOG_COUNT(xfs_mount, 3), XFS_FSB_TO_B(xfs_mount, 1))

** xfs_calc_link_reservation(xfs_mount)
   - 操作中使用的空间包括
   - 修改父节点和目标结点
   > xfs_calc_inode_res(xfs_mount, 2)
   - directroy btree可能会分裂?
   > xfs_calc_buf_res(XFS_DIROP_LOG_COUNT(xfs_mount), XFS_FSB_TO_B(xfs_mount, 1))
   - xfs_bmap_finish释放block使用的空间?
   - xfs_agf/xfs_agfl/xfs_sb
   > xfs_calc_buf_res(3, xfs_sb->sb_sectsize)
   - 释放一次extent? 
   > xfs_calc_buf_res(XFS_ALLOCFREE_LOG_COUNT(xfs_mount, 1), XFS_FSB_TO_B(xfs_mount, 1))

** xfs_calc_remove_reservation(xfs_mount)
   - 修改父节点,还有要删除的结点  
   > xfs_calc_inode_res(xfs_mount, 2)
   - directory btree修改 
   > xfs_calc_buf_res(XFS_DIROP_LOG_COUNT(xfs_mount), 1)
   - xfs_bmap_finish释放block使用的空间
   - 可能会释放2次block? 所以2次xfs_agf/agfl
   > xfs_calc_buf_res(5, xfs_sb->sb_sectsize)
   - 修改alloc btree 
   > xfs_calc_buf_res(XFS_ALLOCFREE_LOG_COUNT(xfs_mount, 2), 1)

** xfs_calc_create_resv_modify(xfs_mount)
   - 创建好xfs_dinode之后的修改, 父目录和新建的inode 
   > xfs_calc_inode_res(xfs_mount, 2)
   - xfs_dinode使用的空间  
   > xfs_calc_buf_res(1, xfs_sb->sb_sectsize)
   - xfs_sb
   > XFS_FSB_TO_B(xfs_mount, 1)
   - directory btree的空间 
   > xfs_calc_buf_res(XFS_DIROP_LOG_COUNT(xfs_mount), 1)

** xfs_calc_create_resv_alloc(xfs_mount)
   - 分配xfs_dinode
   - xfs_agi, xfs_agf, xfs_sb
   > xfs_calc_buf_res(2, xfs_sb->sb_sectsize)
   - xfs_sb->sb_sectsize
   - 每次分配一个cluster的, 而不是1个
   > xfs_calc_buf_res(XFS_IALLOC_BLOCKS(xfs_mount), 1)
   - 修改ialloc btree使用的空间
   > xfs_calc_buf_res(xfs_mount->m_in_maxlevels, 1)
   - 分配1次block?
   > xfs_calc_buf_res(XFS_ALLOCFREE_LOG_COUNT(xfs_mount, 1), 1)

** __xfs_calc_create_reservation(xfs_mount)
   - 分成2个过程, 取较大的值
   > xfs_calc_create_resv_alloc(xfs_mount)
   > xfs_calc_create_resv_modify(xfs_mount)

** xfs_calc_icreate_resv_alloc
   - icreate和上面什么区别?
   - xfs_agi/xfs_agf使用的空间 
   > xfs_calc_buf_res(2, xfs_sb->sb_sectsize)
   - 需要一个sector? superblock里面的nlink标志? 使用额外的sb_sectsize
   - inode btree使用的空间 
   > xfs_calc_buf_res(xfs_mount->m_in_maxlevels, XFS_FSB_TO_B(xfs_mount, 1))
   - 释放什么空间?
   > xfs_calc_buf_res(XFS_ALLOCFREE_LOG_COUNT(xfs_mount, 1), 1)

** xfs_calc_icreate_reservation(xfs_mount)
   - 选择较大的一个  
   > xfs_calc_icreate_resv_alloc(xfs_mount)
   > xfs_calc_create_resv_modify(xfs_mount)

** xfs_calc_mkdir_reservation(xfs_mount)
   - 构造一个新文件? 
   > xfs_calc_create_reservation(xfs_mount)

** xfs_calc_symlink_reservation(xfs_mount)
   - 需要创建文件的空间,还有sympath的空间  
   > xfs_calc_create_reservation(xfs_mount)
   > xfs_calc_buf_res(1, MAXPATHLEN)

** xfs_calc_ifree_reservation(xfs_mount)
   - 释放的inode, 为何还要log? 
   > xfs_calc_inode_res(xfs_mount, 1)
   - agi的unlink表, 以及xfs_sb的计数 
   > xfs_calc_buf_res(1, xfs_sb->sb_sectsize)
   - 这是一个block?
   > xfs_calc_buf_res(1, 1)
   - 然后是xfs_dinode的修改? 
   > xfs_calc_buf_res(1, 0)
   - 需要修改cluster的xfs_inode空间 
   > XFS_INODE_CLUSTER_SIZE(xfs_mount)
   - 需要xfs_log_item 
   > xfs_calc_buf_res(1, 0)
   - 释放2次空间？ 
   > xfs_calc_buf_res(2, XFS_IALLOC_BLOCKS(xfs_mount) + xfs_mount->m_in_maxlevels, 0)
   - 修改inode btree
   > xfs_calc_buf_res(XFS_ALLOCFREE_LOG_COUNT(xfs_mount, 1), 1)

** xfs_calc_ichange_reservation(xfs_mount)
   - 修改xfs_dinode的一部分?
   > xfs_calc_inode_res(xfs_mount, 1)
   - 还会修改xfs_sb ? 
   > xfs_calc_buf_res(1, xfs_sb->sb_sectsize)

** xfs_calc_growdata_reservation(xfs_mount)
   - growfs准备的空间?
   - xfs_agi, xfs_agf, 还有xfs_sb 
   > xfs_calc_buf_res(3, xfs_sb->sb_sectsize)
   - 分配btree? 
   > xfs_calc_buf_res(XFS_ALLOCFREE_LOG_COUNT(xfs_mount, 1), 1)

** xfs_calc_growrtalloc_reservation(xfs_mount)

** xfs_calc_growrtzero_reservation(xfs_mount)

** xfs_calc_growrtfree_reservatino(xfs_mount)

** xfs_calc_swrite_reservation(xfs_mount)
   - 修改inode的timestamp? 
   > xfs_calc_inode_res(xfs_mount, 1)

** xfs_calc_writeid_reservation(xfs_mount)
   - 修改inode的uid/gid 
   > xfs_calc_inode_res(xfs_mount, 1)

** xfs_calc_addafork_reservation(xfs_mount)
   - 添加新的atrr fork
   - inode使用的空间 
   > xfs_calc_inode_res(xfs_mount, 1)

** xfs_trans_resv_calc(xfs_mount, xfs_trans_resv)
   - 构造xfs_mount->xfs_trans_resv数组,里面针对具体的操作计算需要的空间
   - 有些操作是vfs接口,但还有具体的??

* xfs_log.c 
  - xlog使用的磁盘空间是环形队列,长度是xlog->l_logsize

** xlog_grant_sub_space(xlog, head, bytes) 
   - 释放log空间时时用, 通过向前移动head实现
   - 分解head, 这里对它操作是不用锁,而是使用atomic操作
   > xlog_crack_grant_head_val(head, cycle, space)
   - 修改space -= bytes
   - 如果space<0, 跨越数组边界
   - 减小cycle--,  space += xlog->l_logsize
   - 设置xlog_grant_head->grant

** xlog_grant_add_space(xlog, head, bytes)
   - reserve log空间时使用,向后移动head
   - 首先分解出来cycle, space
   > xlog_crack_grant_head_val(head, cycle, space)
   - space += bytes
   - 如果space > xlog->l_logsize, 越过数组边界
   - space -= xlog->l_logsize

** xlog_grant_head_init(xlog_grant_head head)
   - 初始化xlog_grant_head->grant, 指向(1, 0), 不时应该根据log recover的情况而定?
   - 还有waiters队列

** xlog_grant_head_wake_all(xlog_grant_head head)
   - 唤醒xlog_grant_head->waiters中的所有的xlog_ticket
   > wake_up_process(xlog_ticket)

** xlog_ticket_reservation(xlog, xlog_grant_head, xlog_ticket)
   - 计算reserve空间的大小
   - 如果xlog_grant_head是xlog->l_write_head, 使用xlog_ticket->t_unit_res, 而且xlog_ticket->t_flags必须有XLOG_TICK_PERM_RESERVE
   - 否则xlog_grant_head就是xlog->l_reserve_head
   - 如果xlog_ticket->t_flags有XLOG_TIC_PERM_RESERV, 使用xlog_ticket->t_unit_res * xlog_ticket->t_cnt
   - 否则使用xlog_ticket->t_unit_res

** xlog_grant_head_wake(xlog, xlog_grant_head, free_bytes)
   - free_bytes表示xlog中的空闲空间, 检查是否能满足xlog_grant_head等待链表上的xlog_ticket
   - 遍历xlog_grant_head->waiters上的xlog_ticket
   - 重新计算xlog_ticket需要的空间need_bytes, 这里对于l_write_head和l_reserve_head处理不一样
   > xlog_ticket_reservation(xlog, xlog_grant_head, xlog_ticket)
   - 如果free_bytes > need_bytes, free_bytes -= need_bytes, 唤醒这个任务
   > wake_up_process(xlog_ticket->t_task)
   - 如果free_bytes < need_bytes, 直接退出
   - reserve log空间时,首先修改指针,然后等待, 所以l_write_head/l_reserve_head可能超出尾指针很多很多

** xlog_grant_head_wait(xlog, xlog_grant_head, xlog_ticket, need_bytes)
   - reserve log空间,如果空间不够,在xlog_grant_head上等待.
   - 先把xlog_ticket->t_queue放到xlog_grant_head->waiters
   - 等待在循环中实现, 所有的xlog_ticket是顺序获取log空间的, 所以它可能会唤醒前面的
   - xlog->l_tail_lsn表示xlog的空闲空间尾
   - 参数need_bytes表示需要的空间
   - 首先写回ail数据 也就是xfs_log_item. 异步唤醒xfsaild
   - 写回log数据没有用,需要把xfs_log_item的资源合并到fs中,才能释放log空间, 所以这里需要刷新fs数据
   > xlog_grant_push_ail(xlog, need_bytes)
   - 进入睡眠,等待其他函数唤醒xlog_grant_head->waiter队列上的xlog_ticket
   - 被唤醒后检查条件是否满足, 重新计算log的空闲空间free_space
   > xlog_space_left(xlog, xlog_grant_head->grant)
   - 如果free_space > need_bytes, 退出循环. 否则继续等待.
   - 最后从xlog_grant_head->t_waiter队列中释放

** xlog_grant_head_check(xlog, xlog_grant_head, xlog_ticket, need_bytes)
   - 检查xlog的空间空间, 如果不满足,在这里等待
   - 计算需要reserve的空间
   > xlog_ticket_reservation(xlog, xlog_grant_head, xlog_ticket)
   - 计算log的空闲空间, free_space
   > xlog_space_left(xlog, xlog_grant_head->grant)
   - 如果xlog_grant_head->t_waiters不是空,有xlog_ticket在等待
   - 尝试唤醒
   > xlog_grant_head_wake(xlog, xlog_grant_head, free_bytes)
   - 如果唤醒失败或者free_space < need_bytes, 去等待log空间
   > xlog_grant_head_wait(xlog, xlog_grant_head, need_bytes)
   - 如果没有等待的xlog_ticket, 但空间不够, free_bytes < need_bytes, 直接去等待 
   > xlog_grant_head_wait(xlog, xlog_grant_head, xlog_ticket, need_bytes)

** xlog_tic_reset_res(xlog_ticket)
   - 重值xlog_ticket->t_res_num = t_res_arr_sum  = t_res_num_ophdrs = 0

** xlog_tic_add_region(xlog_ticket, len, type)
   - xlog_ticket->t_res_arr是保存(len, type)的数组, t_res_arr_sum累计数组中的len
   - t_res_num是数组索引,把(len,type)放到t_res_arr[t_res_num]中
   - 但数组溢出时, t_res_num == XLOG_TIC_LEN_MAX, 从0重新开始
   - t_res_o_flow += t_res_arr_sum

** xfs_log_regrant(xfs_mount, xlog_ticket)
   - 重新为xlog_ticket reserve log空间, 这里使用xlog->l_write_head
   - 增加xlog_ticket->t_tid ++, 作为新的transaction
   - 让ail释放log空间, 当然只是检查后有必要才写回
   > xlog_grant_push_ail(xlog, xlog_ticket->t_unit_res)
   - 设置xlog_ticket->t_curr_res = xlog_ticket->t_unit_res
   - 清空原来的成员, t_res_num / t_res_arr_sum / t_res_num_ophdrs
   > xlog_tic_reset_res(xlog_ticket)
   - 如果xlog_ticket->t_cnt > 0, 表示它还有log空间
   - 检查空间是否够用,可能会等待, 如果不够用等待完成
   > xlog_grant_head_check(xfs_mount->xlog, xlog->l_write_head, xlog_ticket, need_bytes)
   - reserve空间,直接修改xlog->l_write_head,它是log空间的指针
   > xlog_grant_add_space(xlog, xlog->l_write_head->grant, need_bytes)
   - 验证xlog的l_write_head, l_tail_lsn, 分别指向环形队列的头尾
   > xlog_verify_grant_ail(xlog)

** xfs_log_reserve(xfs_mount, unit_bytes, cnt, xlog_ticket, client, permanent, t_type)
   - reserve log空间, 构造新的xlog_ticket
   - xlog_ticket里面只有空间大小,没有位置信息
   - log的使用者(client)必须是XFS_TRANSACTION, XFS_LOG, 还有一种是XFS_VOLUME??
   - 构造一个xfs_ticket, 使用参数初始化
   > xlog_ticket_alloc(xlog, unit_bytes, cnt, client, permanent, KM_SLEEP|KM_MAYFAIL)
   - 检查log空间是否足够,如果不够,通过ail释放空间
   > xlog_grant_push_ail(xlog, xlog_ticket->t_cnt ? t_cnt * t_unit_res : t_unit_res)
   - 如果log没有足够的空间, xlog_ticket等待ail
   - 这里使用xlog->l_reserve_head, 在上面是xlog->l_write_head
   > xlog_grant_head_check(xlog, xlog->l_reserve_head, xlog_ticket, need_bytes)
   - reserve log空间, 同时修改xlog->l_reserve_head和l_write_head指针
   > xlog_grant_add_space(xlog, xlog->l_reserve_head->grant, need_bytes)

   - 和上面的区别是
   - 使用不同的等待条件, reserve的空间也不一样多,l_reserve_head会多
   - 这里reserve时,同时移动l_reserve_head的指针

   - log空间的reserve使用2个log指针, xlog->l_write_head, l_reserve_head
   - xlog_ticket->t_flags的XLOG_TIC_PERM_RESERV对应xfs_trans->t_flags的XFS_TRANS_PERM_LOG_RES
   - 如果使用l_write_head, xlog_ticket必须有XLOG_TIC_PERM_RESERV, 而且log空间只使用t_unit_res
   - 否则, 可能会有XLOG_TIC_PERM_RESERV, 如果有,空间大小是t_unit_res * t_cnt, 如果没有, 空间就是t_unit_res

** xfs_log_done(xfs_mount, xlog_ticket, xlog_in_core, flags)
   - 释放xlog_ticket
   - 如果xlog_ticket->t_flags 没有XLOG_TIC_INITED, 说明它的数据写到了xlog_in_core中,需要写回一个trans结束的xfs_log_vec.
   > xlog_commit_record(xlog, xlog_ticket, xlog_in_core, xfs_lsn_t)
   - 如果xlog_ticket->t_flags 没有XLOG_TIC_PERM_RESERV, 或者参数flags 有XFS_LOG_REL_PERM_RESERV, 这里要释放xlog_ticket
   - 释放空间给xlog->l_reserve_head / l_write_head
   > xlog_ungrant_log_space(xlog, xlog_ticket)
   > xfs_log_ticket_put(xlog_ticket)
   - 否则重新reserve空间?
   > xlog_regrant_reserve_log_space(xlog, xlog_ticket)
   - 添加xlog_ticket->t_flags的XLOG_TIC_INITED

** xfs_log_callback 
   #+begin_src 
	struct xfs_log_callback	*cb_next;
	void			(*cb_func)(void *, int);
	void			*cb_arg;   
   #+end_src

** xfs_log_notify(xfs_mount, xlog_in_core, xfs_log_callback_t)
   - xlog_in_core->ic_callback/ic_callback_tail是使用xfs_log_callback->cb_next的单链表
   - 把xfs_log_callback放到链表尾

** xfs_log_release_iclog(xfs_mount, xlog_in_core)
   - 释放xlog_in_core
   > xlog_state_release_iclog(xfs_mount->xlog, xlog_in_core)

** xfs_log_mount(xfs_mount, xfs_bugtarg, xfs_daddr, intnum_blks)
   - 在mount操作中调用, 构造xlog, xlog_in_core
   - xfs_buftarg表示xlog设备, (blkoffset, num_bllks)表示xlog磁盘空间
   > xlog_alloc_log(xfs_mount, xfs_buftarg, blk_offset, num_bblks)
   - xfs_sb->sb_logblocks决定参数num_blks,检查是否有效, 太大太小都会警告
   - 构造一个xfsaild线程
   > xfs_trans_ail_init(xfs_mount)
   - 检查是否要recovery
   - mount option没有XFS_MOUNT_NORECOVERY, 需要去recovery
   > xlog_recover(xfs_mount->xlog)
   - 去掉xlog->l_flags的XLOG_ACTIVE_RECOVEY, xfs_trans可以使用了
   - 初始化cil, xfs_cil->xfs_cil_ctx
   > xlog_cil_init_post_recovery(xlog)

** xfs_log_mount_finish(xfs_mount)
   - mount过程中使用的, 清除xlog recovery中使用的数据
   - 它需要mount操作读取metadata的辅助,所以和上面函数分开
   > xlog_recover_finish(xfs_mount->xlog)
   - xlog->l_work在xlog_mount->work_queue中循环执行的,它做什么事情??
   > xfs_log_work_queue(xfs_mount)
   - 任务执行前等待10s, 延时异步任务

** xfs_log_unmount_write(xfs_mount)
   - 在umount操作中使用
   - 把cil/xlog_in_core的数据写到磁盘
   > _xfs_log_force(xfs_mount, XFS_LOG_SYNC, NULL)
   - unmount操作也需要log
   - 构造xlog_ticket
   > xfs_log_reserve(xfs_mount, 600, 1, xlog_ticket, XFS_LOG, 0, XLOG_UNMOUNT_REC_TYPE)
   - 使用xfs_log_vec / xfs_log_iovec包装一个简单的magic数据
   - magic数据是64位.  {XLOG_UNMOUNT_TYPE, 0, 0}
   - xlog_ticket->t_curr_res -= sizeof(magic), 使用了一部分reserve的空间
   - 写到xlog中
   > xlog_write(xlog, xfs_log_vec, xfs_lsn_t, NULL, XLOG_UNMOUNT_TRANS)
   - 上面返回xfs_lsn_t, 应该是log的磁盘位置
   - 获取xlog->xlog_in_core, 设置xlog_in_core的标志为sync, 切换xlog_in_core, 这里要使用独自的xlog_rec_header
   > xlog_state_want_sync(xlog, xlog_in_core)
   - 上面设置了sync标志,这里释放时肯定会写回磁盘
   > xlog_state_release_iclog(xlog, xlog_in_core)
   - 等待写操作完成, 前提是xlog_in_core->ic_state不是XLOG_STATE_ACTIVE|XLOG_STATE_DIRTY
   > xlog_wait(xlog_in_core->ic_force_wait, xlog->l_icloglock)
   - 释放上面使用的xlog_ticket
   > xlog_ungrant_log_space(xlog, xlog_ticket)
   > xfs_log_ticket_put(xlog_ticket)
   - 这里没有使用xfs_trans, 写入一个xfs_log_item
   
** xfs_log_quiesce(xfs_mount)
   - 在umount/freeze之前, 把xlog在内存中缓存的写回磁盘
   - 取消xlog->l_work, 应该是xlog_in_core使用?
   > cancel_delayed_work_sync(xlog->l_work)
   - 刷会数据cil/xlog_in_core
   > xfs_log_force(xfs_mount, XFS_LOG_SYNC)
   - 把ail数据写回磁盘
   > xfs_ail_push_all_sync(xfs_mount->m_ail)
   - 等待xfs_buf, 如果xfs_buf->b_hold > 1, 或者xfs_buf->b_lock被别人锁定,定等待0.1s
   > xfs_wait_buftarg(xfs_mount->m_ddev_targp)
   - 记录unmount的log
   > xfs_log_unmount_write(xfs_mount)

** xfs_log_unmount(xfs_mount) 
   - 实现umount操作
   - 首先把数据写回去, 包括fs数据和log数据
   > xfs_log_quiesce(xfs_mount) 
   - 释放ail, 关闭ail线程
   > xfs_trans_ail_destroy(xfs_mount)
   - 释放cil, xlog_in_core, xlog
   > xlog_delalloc_log(xfs_mount->xlog)

** xfs_log_item_init(xfs_mount, xfs_log_item, type, xfs_item_ops)
   - 初始化xfs_log_item, ail/cil都使用它

** xfs_log_space_wake(xfs_mount)
   - 检查log空间空间, 如果空间足够xlog_ticket的请求,唤醒等待的任务
   - 分别处理xlog->l_write_head / l_reserve_head, 空间的大小和等待任务的都是独自的
   - 先计算free_bytes
   > xlog_space_left(xlog, xlog->l_write_head->grant)
   - 然后分配给xlog_ticket
   > xlog_grant_head_wake(xlog, xlog->l_write_head, free_bytes)

** xfs_log_need_covered(xfs_mount)
   - xlog的定时工作先调用这个函数, 每等待一段时间就执行一次
   - 如果xlog->xfs_cil还有xfs_log_item, 返回0, 表示没有log数据可写
   > xlog_iclogs_empty(xlog)
   - 否则xfs_log_item处于什么状态?
   - 计算xlog->l_covered_state
   - 如果xlog->l_covered_state是XLOG_STATE_COVER_DONE/DONE2/IDLE, 返回0
   - 如果是XLOG_STATE_COVER_NEED/NEED2
   - 如果xlog->xfs_ail不是空, 返回0
   > xfs_ail_min_lsn(xlog->l_ailp)
   - 如果xlog_in_core不全是空的, 返回0
   > xlog_iclogs_empty(xlog)
   - 把XLOG_STATE_COVER_NEED改为XLOG_STATE_COVER_DONE,  NEED2改为DONE2, 返回1, 需要插入dummy log item

** 总结 xlog->l_covered_state 
   - 表示在flush xfs_cil时,是否需要借用dummy xfs_log_item
   - xfs需要写入2个dummy xfs_log_item, 保证recover的正常??
   - 如果xfs_cil中有xfs_log_item, 先flush有效的xfs_log_item, 不时用dummy
   - 如果l_covered_state是XLOG_STATE_COVER_DONE/DONE2/IDLE, 也不需要
   - 如果l_covered_state是XLOG_STATE_COVER_NEED/NEED2, xfs_ail/xfs_cil中有xfs_log_item, flush有效的log数据,不使用dummy
   - 否则xfs是空闲的, 而且还需要写回一个dummy xfs_log_item
   - 状态变为XLOG_STATE_COVER_DONE/DONE2
   - 在xlog_in_core的回调函数中,根据完成的xlog_in_core, 修改状态
   - 大部分都改为XLOG_STATE_COVER_NEED, 需要写入dummy
   - 只有刚才写入的是dummy时, XLOG_STATE_COVER_DONE变为XLOG_STATE_COVER_NEED2, XLOG_STATE_COVER_DONE2变为XLOG_STATE_COVER_IDLE
   
   - 只有写入dummy后, xlog->l_covered_state才变为DONE/DONE2
   - 对应的dummy结束后DONE表为NEED2, DONE2变为IDLE
   - NEED变为IDLE, 需要连续2个dummy
   - 任何状态经过非dummy,都变为NEED
   - 只有NEED/NEED2才会使用dummy

** xlog_assign_tail_lsn_locked(xfs_mount)
   - 设置xlog->l_tail_lsn, 并返回它. 它表示log队列的尾指针
   - 检查ail中的最前面的xfs_log_item
   > xfs_ail_min(xfs_mount, xfs_ail)
   - 如果有效返回xfs_log_item->li_lsn
   - 否则ail是空的,使用xlog->l_last_sync_lsn.
   - 把找到的tail_lsn保存到xlog->l_tail_lsn

** xlog_assign_tail_lsn(xfs_mount)
   - 使用xfs_ail->xa_lock保护上面的操作

** xlog_space_left(xlog, head)
   - 计算log的空闲空间, 也就是head和xlog->l_tail_lsn之外的空间
   - head是队列头,xlog->l_tail_lsn是尾, head > xlog->l_tail_lsn
   - xlog->l_tail_lsn也表示空间,使用(cycle/block)格式,block单位是BB
   - 分解head和l_tail_lsn
   > xlog_crack_grant_head(head, head_cycle, head_bytes)
   > xlog_crack_atomic_lsn(xlog->l_tail_lsn, tail_cycle, tail_bytes)
   - 如果tail_cycle = head_cycle & head_bytes > tail_bytes, 数据区域没有跨越数组边界, 其他的区域是空闲空间  xlog->l_logsize - (head_bytes - tail_bytes)
   - 如果tail_cycle < head_cycle -1, head_cycle应该是tail_cycle+2
   - 这时tail应该在数组尾,head在数组头, 实际上他们指向相同的位置
   - 如果tail_cycle < head_cycle, tail_cycle是head_cycle-1, 队列跨越数组边界
   - 怎么没有检查tail_bytes > head_bytes
   - 空闲空间是tail_bytes - head_bytes
   - 其他情况都是错误

** xlog_iodone(xfs_buf)
   - 这是xfs_buf的IO回调函数. 这些xfs_buf是xlog空间的
   - xfs_buf->b_fspriv 是 xlog_in_core, 而不是xfs_buf_log_item
   - 当前处理的是xfs_buf->b_fspriv = xlog_in_core
   - xfs_buf->b_flags必须有XBF_ASYNC
   > XFS_BUF_ISASYNC(xfs_buf)
   - 修改xlog_in_core的状态, 而且调用它的回调函数,释放xfs_cil_ctx
   > xlog_state_done_syncing(xlog_in_core, aborted)
   - 这个函数在创建xfs_buf时,给xfs_buf->b_iodone

** xlog_get_iclog_buffer_size(xfs_mount, xlog)
   - 设置xlog使用的xlog_in_core,默认系统使用 8个大小是32K的
   - 首先计算xlog_in_core的个数
   - 如果xfs_mount->m_logbufs <=0, 设置默认的, xlog->l_iclog_bufs = XLOG_MAX_ICLOGS (8)
   - 否则使用xfs_mount->m_logbufs, 使用mount参数logbufs
   - 然后计算xlog->l_iclog_size, 是一个xlog_in_core的大小
   - 如果xfs_mount->m_logbsize>0, 使用mount参数logbsize
   - 设置xlog->l_iclog_size = m_logbsize
   - 设置xlog->l_iclog_size_log = log(l_iclog_size)
   - 然后是xlog->l_iclog_heads, 表示一个xlog_in_core中head block的数量
   - 对于log中的数据使用的block, 开始的数据必须被cycle代替,被覆盖的数据保存到xlog_rec_ext_header
   - xlog_rec_ext_header保存到单独的一个block中. 
   - 如果xfs不支持haslogv2, 一个xlog_in_core最多使用一个xlog_rec_ext_header, 它的大小也就首先于XLOG_BIT_RECORD_BSIZE
   - xlog->l_iclog_hsize = BBSIZE, l_iclog_heads = 1
   - 如果xfs支持haslogv2, 可以使用多个xlog_rec_ext_header
   - xlog->l_iclog_heads = xfs_mount->m_logbsize / XLOG_HEADER_CYCLE_SIZE (32k)
   - xlog->l_iclog_hsize = l_iclog_heads << BBSHIFT (512)
   - 如果xfs_mount->m_logbufs = 0, 使用默认
   - xlog->l_iclog_hsize = BBSIZE,  l_iclog_heads = 1
   - xlog->l_iclog_size = XLOG_BIG_RECORD_BSIZE (32k)  l_iclog_size_log = 15
   - 最后把xlog->l_iclog_bufs / l_iclog_size给xfs_mount

** xfs_log_work_queue(xfs_mount)
   - 使用xfs_mount->m_log_workqueue执行异步的任务xlog->l_work,延时提交任务
   - 有系统参数xfssyncd_centisecs
   > queue_delayed_work(xfs_mount->m_log_workqueue, xlog->l_work, xfs_syncd_centisecs*10)
   - 执行的函数是xfs_log_worker

** xfs_log_worker(work_struct) 
   - 上面异步任务的实现
   - work_struct=>delayed_work=>xlog
   - 修改xlog->l_covered_state状态.
   > xfs_log_need_covered(xfs_mount)
   - 如果需要覆盖就写一个dummy的xfs_trans. 它重写一遍xfs_sb->uuid, 启动新的xfs_trans
   > xfs_fs_log_dummy(xfs_mount)
   - 否则就刷新log数据
   > xfs_log_force(xfs_mount, 0)
   - 刷新xfs_ail??
   > xfs_ail_push_all(xfs_mount->xlog_ail)
   - 等待10s,再执行一遍
   > xfs_log_work_queue(xfs_mount)
   - 这个是delayed_work, 它保证文件系统定期的提交数据.

** xlog_alloc_log(xfs_mount, xfs_buftarg, xfs_daddr blk_offset, int num_bblks)
   - 创建xlog, 参数表示log使用的磁盘空间
   - 设置参数l_targ / l_logsize / l_logBBstart / l_logBBsize
   - xlog->l_covered_state = XLOG_STATE_COVER_IDLE
   - 设置xlog->l_flags的XLOG_ACTIVE_RECOVERY标志, 需要处理之前的xlog数据
   - 初始化delayed_work, xlog->l_work
   - 初始化l_tail_lsn, l_tail_sync_lsn, 分别表示xlog有效数据的头和尾
   > xlog_assign_atomic_lsn(xlog->l_tail_lsn, 1, 0)
   - 初始化xlog_grant_head
   > xlog_grant_head_init(xlog->l_reserve_head / l_write_head)
   - 检查xlog的sectorsize, xfs_sb->sb_logsectlog, 转化为BB为单位, 给xlog->l_sectBBsize
   - 如果l_secBBsize > m_sectbb_log, 返回失败
   - 如果l_secBBsize > 0, xfs必须支持logv2
   - 计算xlog_in_core的大小和个数
   > xlog_get_iclog_buffer_size(xfs_mount,xlog) 
   - 分配辅助IO的xfs_buf, 大小是xlog->l_iclog_size, 给xlog->l_xbuf
   - 在写回xlog数据时使用,可能一个xlog_in_core会跨越数据边界,所以使用2个xfs_buf写回
   - 设置回调函数  xfs_buf->b_iodone = xlog_iodone
   > xfs_buf_alloc(xfs_mount->m_logdev_targp, 0, BTOBB(xlog->l_iclog_size), 0)
   - 初始化xlog->l_flush_wait, 在写xlog_in_core时使用,如果它不可用,在这个队列上等待. 在xlog_in_core可用时唤醒它.
   - 创建xlog_in_core链表, 个数是xlog->l_iclog_bufs, xlog_io_core->ic_bp
   > xfs_buf_get_uncached(xfs_mount->m_logdev_targp, xlog->l_iclog_size, 0)
   - 使用xlog_in_core->ic_prev/ic_next构成双链表
   - 关联xlog_in_core和xfs_buf, xlog_in_core->ic_bp = xfs_buf
   - xlog_in_core->ic_data = xlog_buf->b_addr
   - xfs_buf中数据格式是xlog_in_core2, 他使用大端数据类型,直接放到磁盘中存储
   - xlog_in_core->ic_head数据类型是xlog_in_core2
   - 初始化xlog_in_core2->hic_header, xlog_rec_header, 这里需要转化数据类型
   - 包括magic, version, fmt, uuid
   - xlog_rec_header->h_size = xlog->l_iclog_size 表示整个xlog_in_core大小
   - 然后初始化xlog_in_core
   - xlog_in_core->ic_size = xfs_buf->b_length - xlog->l_iclog_hsize, 除去头部的空间, 也就是xlog_rec_ext_header占用的空间
   - xlog_in_core->ic_state = XLOG_STATE_ACTIVE, ic_datap指向数据区, 偏移xlog->l_iclog_hsize
   - 最后构造xfs_cil和xfs_cil_ctx
   > xlog_cil_init(xlog)

** xlog_commit_record(xlog, xlog_ticket, xlog_in_core, xfs_lsn_t commitlsnp)
   - 写一个特殊的xfs_log_vec, 它没有携带xfs_log_item
   - 只有一个xfs_log_iovec, 里面是空的xlog_op_header
   - xlog_op_header->i_len = 0, xlog_op_header->oh_flags = XLOG_COMMIT_TRANS
   - 在xfs_cil_ctx提交的最后调用.
   - 把它写到xlog_in_core中
   > xlog_write(xlog, xfs_log_vec, xlog_ticket, xfs_lsn_t, xlog_in_core, XLOG_COMMIT_TRANS)
  
** xlog_grant_push_ail(xlog, need_bytes)
   - 在分配空间时,如果失败,把ail的修改数据写到metadata中,释放xlog空间
   - 计算log空闲空间,使用xlog->l_reserve_head
   > xlog_space_left(xlog, xlog->l_reserve_head->grant)
   - 计算阈值free_threshold = max(need_bytes, xlog->l_logBBsize /4, 256)
   - 如果free_bytes >= free_threshold 直接返回
   - 否则需要提交ail中的xfs_log_item, 释放log空间
   - 计算合适的xfs_lsn_t, 释放它之前的ail
   > xlog_crack_atomic_lsn(xlog->l_tail_lsn, threshold_cycle, threshold_block)
   - threshold_block += free_threshold, 如果threshold_block > l_logBBsize, threshold_cycle += 1
   > xlog_assign_lsn(threshold_cycle, threshold_block)
   - 这个新的xfs_lsn_t不能比xlog->l_last_sync_lsn小
   - 提交ail, 启动ail进程, 开始向磁盘提交数据
   > xfs_ail_push(xlog->l_ailp, threshold_lsn)

** xlog_rec_ext_header
   #+begin_src 
	__be32	  xh_cycle;	/* write cycle of log			: 4 */
	__be32	  xh_cycle_data[XLOG_HEADER_CYCLE_SIZE / BBSIZE]; /*	: 256 */    // 64
   #+end_src

** xlog_in_core2 
   - xlog_in_core使用xfs_buf把log数据写回log磁盘
   - xfs_buf中包含2部分,一个是头部, 后面是数据
   - 头部是xlog_in_core2数组, 数组第一个项是xlog_rec_header, 后面的是xlog_rec_ext_header
   - 数组长度是xlog->l_iclog_heads, 每一项长度是512, 但处理的block数量是XLOG_HEADER_CYCLE_SIZE/BBSIZE
   - 后面数据的block,开头被替换为cycle, 为了recover log任务识别数据, 被替换的数据放到xlog_in_core2中
   #+begin_src 
	xlog_rec_header_t	hic_header;
	xlog_rec_ext_header_t	hic_xheader;
	char			hic_sector[XLOG_HEADER_SIZE];   
        //XLOG_HEADER_SIZE=512, 每个xlog_rec_ext_header使用一个block, 浪费了接近1半
   #+end_src

** xlog_pack_data(xlog, xlog_in_core, roundoff)
   - 处理block/xfs_buf中的cycle数据
   - cycle使用xlog_in_core->xlog_in_core2->xlog_rec_header_t->h_cycle, 应该是初始化时设定, 指向log磁盘位置
   - xlog_in_core缓存的log数据大小是xlog_in_core->ic_offset + roundoff
   - 遍历这些block, 起始地址是xlog_in_core->ic_datap
   - 把每个block的开始32字节放到xlog_in_core->xlog_in_core2->xlog_rec_header->h_cycle_data[i]中
   - 使用cycle_lsn代替
   - 上面只是处理XLOG_HEADER_CYCLE_SIZE的数据, 如果xfs支持logv2, 继续处理
   - 把被覆盖的数据给xlog_in_core2->xlog_rec_ext_header_t->xh_cycle_data[k]中
   - 同时设置xlog_in_core2->xlog_rec_ext_header_t->xh_cycle

** xlog_cksum(xlog, xlog_rec_header, dp, size)
   - 计算xlog_in_core2->xlog_rec_header->h_crc
   - 首先使用xlog_rec_header的checksum, 但跳过xlog_rec_header->h_crc.
   > xfs_start_cksum(xlog_rec_header, sizeof(xlog_rec_header), offsetof(xlog_rec_header, h_crc))
   - 然后是后面的xlog_rec_ext_header数组
   > crc32c(crc, xlog_in_core2->hic_xheader, sizeof(xlog_rec_ext_header))
   - 最后还有dp/size指向的数据
   > crc32c(crc, dp, size)
   > xfs_end_cksum(crc)

** xlog_bdstrat(xfs_buf)
   - 发送log的IO请求, 应该是写操作
   - xfs_buf->b_fspriv是xlog_in_core
   - 检查xlog_in_core->ic_state
   - 如果有错误, xlog_in_core->ic_state有XLOG_STATE_IOERROR, 直接结束xfs_buf的IO
   > xfs_buf_ioerror(xfs_buf, EIO)
   > xfs_buf_stale(xfs_buf)
   > xfs_buf_ioend(xfs_buf)
   - 这里应该使用上面注册的回调函数xlog_iodone, 直接关闭FS
   - 如果没有,发送io
   > xfs_buf_iorequest(xfs_buf)

** xlog_sync(xlog, xlog_in_core)
   - 把xlog_in_core异步写回磁盘.
   - xlog_in_core->ic_offset表示它里面的数据量
   - 要写的数据量是 count_init = xlog->l_iclog_hsize + xlog_in_core->ic_offset
   - count_init向上对齐, 计算补充的数据量 roundoff
   - 如果xfs支持logv2, 使用xfs_sb->sb_logsunit对齐
   - 否则使用BB对齐
   - 为roundoff预留空间, l_reserve_head/l_write_head
   > xlog_grant_add_space(xlog, xlog->l_reserve_head->grant, roundoff)
   - 准备block的cycle数据
   > xlog_pack_data(xlog, xlog_in_core, roundoff)
   - 设置xlog_rec_header->h_len = xlog_in_core->ic_offset + roundoff
   - 设置xfs_buf的物理地址, 根据xlog_in_core->xlog_in_core2->xlog_rec_header->l_lsn
   - 使用xfs_lsn_t的block域, 这里只是log磁盘偏移
   > XFS_BUF_SET_ADDR(xfs_buf, BLOCK_LSN(h_lsn))
   - 检查xlog_in_core使用的磁盘空间超过log限制
   - XFS_BUF_ADDR(xfs_buf) + count > xlog->l_logBBsize, 碰到数组边界, 需要写2次, 设置xlog_in_core->ic_bwritten = 2
   - 对于超过边界的, 遍历这些block,增加cycle
   - 计算checksum, 放到xlog_in_core->xlog_in_core2->xlog_rec_header
   > xlog_cksum(xlog, xlog_in_core->ic_header, xlog_in_core->ic_datap, size)
   - 设置xfs_buf, xfs_buf->b_fspriv是xlog_in_core, b_io_length = count
   - 提交之后,不用等待, 设置xlog_buf->b_flags的XBF_ASYNC
   > XFS_BUF_ASYNC(xfs_buf)
   - IO执行是同步的  xfs_buf->b_flags |= XBF_SYNCIO
   - 如果mount参数使用barrier, 设置xfs_buf->b_flags的XFS_FUA
   - 如果log磁盘不是fs磁盘, 给fs磁盘发送flush操作
   > xfs_blkdev_issue_flush(xfs_mount->m_ddev_targp)
   - 否则设置xfs_buf->b_flags的XBF_FLUSH
   - 验证xlog_in_core是否有效
   > xlog_verify_iclog(xlog, xlog_in_core, count, true)
   - 偏移xfs_buf的位置, 偏移xlog->l_logBBstart
   > XFS_BUF_SET_ADDR(xfs_buf, XFS_BUF_ADDR(xfs_buf), xlog->l_logBBstart)
   - 设置xfs_buf->b_flags的XFS_WRITE
   > XFS_BUF_WRITE(xfs_buf)
   - 发送io请求
   > xlog_bdstrat(xfs_buf)
   - 如果上面一个log不够xlog_in_core使用的,还需要处理下一个. 
   - 这里使用额外的xfs_buf, xlog->l_xbuf
   - 处理的数据是xlog_in_core->xlog_in_core2->xfs_rec_header->ic_header + count
   > xfs_buf_associate_memory(xfs_buf, xlog_in_core->ic_header + count, split)
   - 设置xfs_buf的属性, XBF_SYNCIO, XFS_ASYNC
   - 设置xfs_buf对应的磁盘位置,xlog->l_logBBstart, 因为它从数据头开始写
   > XFS_BUF_SET_ADDR(xfs_buf, XFS_BUF_ADDR(xfs_buf) + xlog->l_logBBsize)
   - 设置XBF_WRITE
   > xlog_bdstrat(xfs_buf)

** 总结
   - 刚才看了xlog_verify_iclog, 了解xlog_in_core中xfs_buf数据的意义. 
   - xfs_buf中的数据就是格式化了的xfs_log_item, 使用xlog_op_header包装. 每个xlog_op_header挨着放置,没有地址对齐. xlog_op_header->oh_len表示这个包的数据长度, 不包括xlog_op_header的大小
   - 在写回磁盘时, 需要对xfs_buf中每个block的开头覆盖为cycle, 把原来的数据保存到xlog_rec_header->h_cycle_data, 或者xlog_rec_ext_header->xh_cycle_data中. 把xlog_rec_header->h_lsn中的cycle写到对应的位置, 实现函数是xlog_pack_data中

   - 如果在预留xlog空间时不够,在xlog_grant_head上等待. 等待之前让ail释放xlog的空间, 在释放xlog_ticket时也会唤醒这些等待.
   - l_reserve_head和l_write_head的区别. 预留空间不一样, l_write_head使用xlog_ticket->t_unit_res, l_reserve_head根据XLOG_TIC_PERM_RESERV, 使用t_cnt * t_unit_res或t_unit_res
   - 在大部分情况下,都是共同修改l_reserve_head, l_write_head. 只有在xfs_log_regrant时,去l_write_head中分配空间
   - xlog_ticket->t_curr_res = xlog_ticket->t_unit_res是在创建xlog_ticket时计算的空间,向xlog_in_core中写数据时,修改t_curr_res, 表示占用的xlog_in_core的空间
   - 在向xlog_in_core写数据时(xlog_write), 把xfs_log_vec中的数据统计到xlog_ticket->xlog_res中, 只有在错误时,才查看它
   - 在创建xfs_trans后,创建xlog_ticket, 给他分配空间. xfs_trans关联的xlog_ticket是普通的吧.
   - 在把xfs_trans的数据给xlog_in_core之后,可以释放xlog_ticket(xfs_log_done). 释放之前它会写XLOG_COMMIT_TRANS的xlog_op_header. 如果不是XLOG_TIC_PERM_RESERV, 直接释放掉xlog_ticket, 否则它可以使用多次, 先释放xlog_ticket->t_curr_res的空间, 如果 --t_cnt > 0, 说明它还要使用, 重新分配l_reserve_head的空间, 分配数量是xlog_ticket->t_unit_res. xlog_ticket->t_curr_res = xlog_ticket->t_unit_res. 
   - xfs_cil用来积累xfs_log_item_desc, 然后使用xfs_cil_ctx提交到xlog_in_core中, 而且提交完后使用它管理提交中的xfs_log_item
   - 下面这些xfs_lsn_t只是普通计数,为何不用普通数据类型?在xlog_cil_push中使用
     - xlog_in_core->xc_current_sequence
     - xfs_cil->xc_push_seq
     - xfs_cil_ctx->sequence
     - xfs_log_item->li_seq
     - xfs_inode_log_item->ili_last_lsn
     - xfs_inode_log_item->ili_flush_lsn  

   - 这些xfs_lsn_t应该表示xlog的数据位置
     - xfs_log_item->li_lsn
     - xfs_cil_ctx->start_lsn
     - xfs_cil_ctx->commit_lsn
     - xlog_grant_head->grant
     - xlog_rec_header->h_lsn, 它是硬盘中的格式

** xlog_dealloc_log(xlog)
   - 异步释放xlog
   - 首先是xfs_cil_ctx, xfs_cil
   > xlog_cil_destroy(xlog)
   - 释放辅助使用的xfs_buf , 清空它的指针,释放page等
   > xfs_buf_set_empty(xlog->l_xbuf, BTOBB(xlog->l_iclog_size))
   > xfs_buf_free(xlog->l_xbuf)
   - 处理xlog_in_core链表, 遍历ic_next链表
   - 释放关联的xfs_buf
   > xfs_buf_free(xlog_in_core->ic_bp)
   - 最后释放它自己xlog

** xlog_state_finish_copy(xlog, xlog_in_core, record_cnt, copy_bytes)
   - xlog_in_core->xlog_in_core_2->xlog_rec_header->h_num_logops += record_cnt, 表示xlog_in_core中的xlog_op_header的个数
   - xlog_rec_header是磁盘中的数据,使用大端类型
   - xlog_in_core->ic_offset += copy_bytes, 表示xlog_in_core的数据量

** xlog_res 
   #+begin_src 
	uint	r_len;	/* region length		:4 */
	uint	r_type;	/* region's transaction type	:4 */
	//记录xfs_log_iovec的信息. 没有用
   #+end_src

** xlog_print_tic_res(xfs_mount, xlog_ticket)
   - xlog_ticket对应一个xfs_trans, 对应一种文件系统的操作, xlog_ticket->t_trans_type
   - xlog_ticket->t_res_arr数据是什么,对应一个操作的分解动作?? xlog_ticket->xlog_res->r_type

** xlog_write_calc_vec_length(xlog_ticket, xfs_log_vec)
   - 第二个参赛使用xfs_log_vec->lv_next传递一个链表. 每个xfs_log_vec管理多个xfs_log_iovec
   - xlog_log_iovec中已经是格式化的数据. 数据在xfs_log_vec>lv_buf中.
   - 数据从xfs_log_vec转移到xlog_in_core的xfs_buf中,计算可能占用的xlog_in_core的空间大小
   - 遍历所有的xfs_log_vec
   - 如果xfs_log_vec->lv_buf_len == XFS_LOG_VEC_ORDERED,直接跳过
   - 累加所有的xfs_log_vec->lv_niovecs, 表示xlog_op_header的数量
   - 遍历所有的xfs_log_iovec,把所有的(len, type)放到xlog_ticket->t_res_arr
   > xlog_tic_and_region(xlog_ticket, xfs_log_iovec->i_len, xfs_log_iovec->i_type)
   - 累加xfs_log_iovec->i_len, 表示数据的长度
   - 每个xfs_log_iovec使用xlog_op_header包装,因此总的数据量还包还xlog_op_header使用的空间
   - 如果xlog_ticket->t_flags & XLOG_TIC_INITED, headers += 1
   - 这个多余的xlog_op_header是什么???
   - xlog_ticket->t_res_num_opheaders += headers

** xlog_write_start_rec(xlog_op_header, xlog_ticket)
   - 每个xfs_cil_ctx写到xlog_in_core时,第一个xlog_op_header是XLOG_START_TRANS
   - 它不包装数据,只是一个头, 对应的有一个尾XLOG_COMMIT_TRANS
   - xlog_ticket->t_flags & XLOG_TIC_INITED ==0, 表示它已经设置了xlog_op_header, 直接退出
   - 根据xlog_ticket初始化xlog_op_header
   - xlog_op_header->op_len = 0, oh_flags = XLOG_START_TRANS
   - 设置xlog_op_header->oh_tid = xlog_ticket->t_tid, t_clientid
   - 删除xlog_ticket->t_flags的XLOG_TIC_INITED
   
** xlog_write_setup_ophdr(xlog, xlog_op_header, xlog_ticket, flags)
   - 根据xlog_ticket初始化xlog_op_header
   - 设置xlog_op_header->oh_tic/oh_clientid
   - 这里检查xlog_op_header->oh_clientid, 如果不是XFS_TRANSACTION/XFS_VOLUME/XFS_LOG, 返回错误

** xlog_write_setup_copy(xlog_ticket, xlog_op_header, space_available, space_required, copy_offset, copy_len, last_was_partial_copy, bytes_consumed)
   - 参数大部分是指针,这里设置这些指针,为数据搬运准备.
   - space_available表示剩余的空间
   - space_required是需要的空间, 也就是总的数据量
   - bytes_consumed是已经复制的数据
   - 需要拷贝的 still_to_copy = space_required - bytes_consumed
   - copy_off表示这次拷贝的起始位置,也就是bytes_consumed
   - 如果still_to_copy < space_available, 空间足够, 这次可以完全拷贝
   - 搬运的数据量copy_len = space_required
   - 设置xlog_op_header->oh_len = copy_len
   - 如果last_was_partial_copy !=0, 它表示一个xlog_op_header分成多分, 当前是最后一部分
   - 设置xlog_op_header->oh_flags |= XLOG_END_TRANS | XLOG_WAS_CONT_TRANS
   - 清空last_was_partial_copy, bytes_consumed, 返回0
   - 否则,需要拷贝一部分
   - copy_len = space_available
   - 设置xlog_op_header->oh_len = copy_len
   - 设置xlog_op_header->oh_flags的XLOG_CONTINUE_TRANS
   - 如果last_was_partial_copy != 0, 设置XLOG_WAS_CONT_TRANS
   - bytes_consumed += copy_len, last_was_partial_copy ++
   - 既然一个包使用多个xlog_op_header, 增加消耗的log空间
   - xlog_ticket->t_curr_res -= sizeof(xlog_op_header) 
   - xlog_ticket->t_res_num_ophdrs ++

** xlog_write_copy_finish(xlog, xlog_in_core, flags, record_cnt, data_cnt, partial_copy, partial_copy_len, log_offset, xlog_in_core)
   - 复制完数据之后更新xlog_in_core的计数, 如果需要切换xlog_in_core, 还需要把推进xlog_in_core的状态
   - 如果partial_copy != 0, xfs_cil_ctx没有完全写在当前xlog_in_core,分裂到多个xlog_in_core中.
   - 增加xlog_in_core->xlog_in_core2->xlog_rec_header->h_num_logops, 表示xlog_op_header的数量
   - 增加xlog_in_core->ic_offset, 增加总数据量
   > xlog_state_finish_copy(xlog, xlog_in_core, record_cnt, data_cne)
   - 修改xlog_in_core的状态, 可能写回磁盘
   - 如果是XLOG_STATE_WANT_SYNC,改为XLOG_STATE_SYNCING, 设置xlog_rec_header->h_tail_lsn, 这个最小的ail的位置
   > xlog_state_release_iclog(xlog, xlog_in_core)
   - 否则partial_copy = 0, xfs_log_vec都转移完成, 可以继续下一个xfs_log_vec
   - 检查xlog_in_core是否满了, 如果满了需要自动切换
   - 如果xlog_in_core->ic_size - log_offset <= sizeof(xlog_op_header)
   - xlog_in_core的空闲空间无法存储xlog_op_header, 相当于满了
   - xlog_in_core->ic_size表示数据空间, 除了头之外的. log_offset应该是xlog_in_core->ic_offset
   - 更新xlog_in_core中的xlog_op_header统计数
   > xlog_state_finish_copy(xlog, xlog_in_core, record_cnt, data_cnt)
   - 向前移动它的状态
   > xlog_state_want_sync(xlog, xlog_in_core)
   - 但这种情况应该是另一种切换, 已经估计到需要多个xlog_in_core, 但整个在切换xfs_log_vec时碰到, 在查找xlog_in_core时已经切换xlog的当前的xlog_in_core, 所以这个xlog_in_core的状态不需要修改
   - 同时设置record_cnt = 0, 调用者会在切换xfs_log_vec后退出内层循环,去重新查找可用的xlog_in_core
   - 如果参数指针commit_iclog ==0, 尝试提交这个xlog_in_core
   > xlog_state_release_iclog(xlog, xlog_in_core)
   - 否则通过指针返回, 设置commit_iclog = xlog_in_core

** xlog_write(xlog, xfs_log_vec, xlog_ticket, xfs_lsn_t start_lsn, xlog_in_core commit_iclog, flags)
   - 把xfs_log_vec的数据写到xlog_in_core中
   - 参数start_lsn用来记录使用的第一个xlog_in_core->xlog_in_core2->xlog_rec_header->h_lsn
   - 首先计算需要log的空间大小
   > xlog_write_calc_vec_length(xlog_ticket, xfs_log_vec)
   - 如果xlog_ticket->t_flags有XLOG_TIC_INITED, 它预留一个xlog_op_header, 保存XLOG_START_TRANS信息
   - 减小reserve log空间, xlog_ticket->t_curr_res -= sizeof(xlog_op_header)
   - 如果flags包含XLOG_COMMIT_TRANS|XLOG_UNMOUNT_TRANS, 同样需要专门的xlog_op_header,写入XLOG_COMMIT_TRANS.
   - 减小reserve log空间, xlog_ticket->t_curr_res -= sizeof(xlog_op_header)
   - 如果xlog_ticket->t_curr_res <0, 应该是有问题, 打印调试信息
   > xlog_print_tic_res(xlog->xfs_mount, xlog_ticket)
   - 使用双重循环遍历所有的xfs_log_iovec, 
   - 外层用来切换xlog_io_core, 里面用来遍历xfs_log_iovec, 数据转移是以xlog_log_iovec为单位, 当然一个xlog_log_iovec可能太大,占用多个xlog_in_core
   - 获取xlog_in_core, 里面会检查当前的xlog_in_core, 如果需要切换，等待或者初始化
   - log_offset表示xlog_in_core的内部偏移,开始写数据的位置, contwr表示使用多个xlog_in_core
   > xlog_state_get_iclog_space(xlog, len, xlog_io_core, xlog_ticket, contwr, log_offset)
   - 把第一个xlog_in_core->xlog_in_core2->xlog_rec_header->l_lsn给参数start_lsn, 它表示这个xlog_in_core在log磁盘的位置
   - 开始向xlog_in_core中转移数据, 获取xfs_log_iovec
   - 如果xfs_log_vec->lv_buf_len是XFS_LOG_VEC_ORDERED, 跳过不处理
   - 获取xlog_op_header, 也就是xlog_in_core中的指针, ptr = xlog_in_core->ic_datap + log_offset
   - 如果xlog_ticket->t_flags有XLOG_TIC_INITED, 写入XLOG_START_TRANS使用的xlog_op_header
   > xlog_write_start_rec(ptr, xlog_ticket)
   - 移动指针ptr, 增加log_offset, 表示xlog_in_core的数据量, 减小len, 表示剩余的数据量. 每次写了数据的都需要这些移动
   > xlog_write_adv_cnt(xlog_op_header, len, log_offset, start_rec_copy)
   - 处理当前xfs_log_iovec使用的xlog_op_header, 做一些初始化
   - flags是参数传进来的, 只有2种特殊,一种是umount, 另一种是commit空的xfs_trans
   > xlog_write_setup_ophdr(xlog, xlog_op_header, xlog_ticket, flags)
   - 写入xlog_op_header, 移动指针
   > xlog_write_adv_cnt(xlog_op_header, len, log_offset, sizeof(xlog_op_header))
   - 搬运数据,来源是xfs_log_iovec, 目的是xlog_in_core中的buf/ptr
   - xlog_in_core空间可能不够, 这里先准备好指针，偏移，长度等
   - xlog_in_core->ic_size - log_offset表示xlog_in_core还剩余的空间
   - xfs_log_iovec->i_len是需要拷贝的数据
   - partial_copy_len表示已经复制的部分, 表示xfs_log_vec中的偏移, 它返回下次移动的数据开始地址
   - copy_len表示这次可以复制的长度
   - copy_offset = partial_copy_len, 表示这次复制开始的偏移
   - partial_copy 表示是否只处理一部分.
   > xlog_write_setup_copy(xlog_ticket, xlog_op_header, xlog_in_core->ic_size - log_offset, xfs_log_iovec->i_len, copy_offset, copy_len, partial_copy, partial_copy_len)
   - 验证xlog_op_header的指针在某个(xlog->l_iclog_bak, xlog->l_iclog_size)范围内. 这表示每个xlog_in_core的范围.
   > xlog_verify_dest_ptr(xlog, xlog_op_header)
   - 把数据复制过去
   > memcpy(ptr, xfs_log_iovec->i_addr + copy_off, copy_len)
   - 移动xlog_in_core中的指针ptr
   > xlog_write_adv_cnt(xptr, len, log_offset, copy_len)
   - 这一次循环移动的数据量copy_len包括xlog_op_header数据,xfs_log_vec的数据,可能一部分, 还有可能包括前面XLOG_START_TRANS的数据
   - 然后更新xlog_in_core的计数
   - 上面查找xlog_in_core时,如果只需要一个xlog_in_core, 已经更新xlog_rec_header->ic_offset, 否则需要这里更新
   > xlog_write_copy_finish(xlog, xlog_in_core, flags, record_cnt, data_cnt, partial_copy, partial_copy_len, log_offset, commit_iclog)
   - 如果partial_copy !=0, 退出内层循环,重新获取一个xlog_in_core
   - 否则切换xfs_log_vec / xfs_log_iovec
   - 如果上面record_cnt ==0, 也需要重新查找xlog_in_core
   - 最后循环结束后还需要更新xlog_in_core的计数
   > xlog_state_finish_copy(xlog, xlog_in_core, record_cnt, data_cnt)
   - 释放xlog_in_core,可能会推进xlog_in_core状态,写回磁盘
   > xlog_state_release_iclog(xlog, xlog_in_core)

   - 这么复杂的逻辑,不知道developer会不会记住!!
   - 对于xfs_log_vec/xfs_log_iovec的推进, 使用3个全局变量(循环之外变量)
   - lv指向当前处理的xfs_log_vec, index指向当前处理的xfs_log_iovec, partial_copy_len指向当前需要移动的xfs_log_iovec中的数据
   - 对于xlog_in_core,使用log_offset, 在查找xlog_in_core时获取, 在转移数据时向前推进
   - 在内部循环中有3种情况, 一种时不需要切换
   - 一种时xfs_log_iovec截断, 需要切换xlog_in_core
   - 一种时切换xfs_log_iovec时,发现xlog_in_core空间太少, 同时切换

   - 在查找xlog_in_core时增加使用计数, 在切换或移动完成时释放计数, 同时推进它的状态
   - 在查找xlog_in_core时,如果发现一个xlog_in_core不够用,提前切换, 而且后面使用时需要更新它的ic_offset, 其他任务使用下一个
   - 否则提前更新ic_offset, 其他任务可以同时使用

** xlog_state_clean_log(xlog)
   - 在xlog_in_core的回调中使用, 把XLOG_STATE_DIRTY变为XLOG_STATE_ACTIVE
   - xlog_in_core顺序使用好理解, 只要检查xlog->xlog_in_core的状态. 如果有任务等待xlog_in_core完成, 是否也需要等待前面的xlog_in_core完成??
   - 遍历xlog_in_core链表
   - 如果xlog_in_core->ic_state == XLOG_STATE_DIRTY, 把状态变为XLOG_STATE_ACTIVE
   - 设置xlog_in_core->ic_offset = 0
   - 在处理过程种xlog_in_core, 计算改变状态
   - 如果只有一个dirty的xlog_in_core, 而且它只有5 xlog_op_header, 设置change=1, 否则有多个xlog_in_core, 或者xlog_in_core中有多个xlog_in_header
   - xlog_in_core->xlog_in_core2->xlog_rec_header->h_num_logops 为XLOG_COVER_OPS(5), 表示这里xlog_in_core里面只有一个dummy transaction的commit操作
   - 重新设置xlog_in_core中的参数 xlog_rec_header->h_num_logops = 0
   - xlog_in_core->xlog_rec_header->h_lsn = 0
   - 继续重值xlog_in_core->xlog_in_core2->xlog_rec_header, h_num_logops, h_cycle_data, h_lsn都设为0
   - 如果xlog_in_core状态是XLOG_STATE_ACTIVE,直接跳过
   - 对于其他状态,停止遍历
   - 所以这里状态的只是处理局部的dirty的xlog_in_core
   - 根据上面change != 0,改变xlog的状态
   - 如果xlog->l_covered_state是XLOG_STATE_COVER_IDLE/NEED/NEED2,改为XLOG_STATE_COVER_NEED
   - 如果是XLOG_STATE_COVER_DONE, 如果changed=1, 改为XLOG_STATE_COVER_NEED2, 否则改为XLOG_STATE_COVER_NEED
   - NEED2是一个暂时状态,表示前面有一个空的xlog_in_core
   - 如果是XLOG_STATE_COVER_DONE2, changed=1, 改为XLOG_STATE_COVER_IDLE, 如果changed=2，改为XLOG_STATE_COVER_NEED
   - 如果change = 2都要改为XLOG_STATE_COVER_NEED. 如果change = 1, 表示里面有一个, 这样如果2次提交dummy的,就不用专门添加一个dummy的xlog_in_core

** xlog_get_lowest_lsn(xlog)
   - 遍历xlog->l_iclog队列，这是xlog_in_core队列.
   - 过滤工作中的xlog_in_core, 只处理已经提交的xlog_in_core
   - xlog_in_core->ic_state & ( XLOG_STATE_ACTIVE|XLOG_STATE_DIRTY ) == 0
   - 找到磁盘位置最小的xlog_in_core->xlog_in_core2->xlog_rec_header->h_lsn.

** xlog_state_do_callback(xlog, aborted, xlog_in_core)
   - 在xlog_in_core的xfs_buf的IO回调函数中使用
   - 遍历xlog_in_core->ic_state， 处理队列尾部处于XLOG_STATE_DONE_SYNC|XLOG_STATE_DO_CALLBACK的, 把它的状态改为XLOG_STATE_DO_CALLBACK, 调用它的回调函数
   - 从当前xlog_in_core下一个开始遍历, 相当于队尾
   - 如果碰到xlog_in_core->ic_state & (XLOG_STATE_ACTIVE|XLOG_STATE_DIRTY), 直接跳过
   - 如果xlog_in_core->ic_state没有XLOG_STATE_IOERROR, 表示xlog_in_core没有错误
   - 如果有错误不管它状态,直接处理
   - 如果xlog_in_core->ic_state不是XLOG_STATE_DONE_SYNC或XLOG_STATE_DO_CALLBACK
   - 结束遍历, 后面即使有XLOG_STATE_DONE_SYNC|XLOG_STATE_DO_CALLBACK的xlog_in_core, 也等待这个xlog_in_core的状态变为XLOG_STATE_DONE_SYNC|XLOG_STATE_DO_CALLBACK之后处理
   - 同时把当前xlog_in_core的状态从XLOG_STATE_DONE_SYNC改为XLOG_STATE_DO_CALLBACK, 其他xlog_in_core的回调可以处理它
   - 否则获取一个xlog_in_core, 它的状态是XLOG_STATE_DONE_SYNC或者XLOG_STATE_DO_CALLBACK
   - 检查他的xfs_lsn_t, 先获取xlog的最小lsn
   > xlog_get_lowest_lsn(xlog)
   - 如果xlog_in_core->xlog_op_header->h_lsn不是最小的,也不处理
   - xlog_in_core应该按照h_lsn排序?? 现在已经按顺序访问, 为何还有这种情况??
   - 到这里就只处理lsn最小的,而且状态是XLOG_STATE_DONE_SYNC|XLOG_STATE_DO_CALLBACK状态的, 改为XLOG_STATE_CALLBACK
   - 如果xlog_in_core->ic_callback != 0, 更新xlog->l_last_sync_lsn = xlog_in_core->xlog_in_core2->xlog_rec_header->h_lsn
   - 遍历xfs_log_callback队列,调用它的回调函数
   > xfs_log_callback->cb_func(xfs_log_callback->cb_arg, aborted)
   - 设置xlog_in_core->ic_state = XLOG_STATE_DIRTY
   - 然后把它的状态改为ACTIVE, 同时更新xlog->l_covered_state
   > xlog_state_clean_log(log)
   - 唤醒等待这个xlog_in_core的任务
   > wake_up_all(xlog_in_core->ic_force_wait)
   - 最外层循环的退出条件是没有callback可调用.也就是没有合适的xlog_in_core
   - 最后如果xlog->l_iclog->ic_state是XLOG_STATE_ACTIVE, 唤醒等待xlog的任务
   > wake_up_all(xlog->l_flush_wait)

** xlog_state_done_syncing(xlog_in_core, aborted)
   - 这是从xfs_buf的回调函数调用的 xlog_indone
   - xlog_in_core->ic_state必须是XLOG_STATE_SYNCING或XLOG_STATE_IOERROR
   - xlog_in_core->ic_refcnt必须是0, 没有任务正在写
   - xlog_in_core->ic_bwritecnt应该是1或2, 因为一个xlog_in_core的写回,可能使用2次,碰到数组边界.
   - 减小xlog_in_core->ic_bwritecnt --, 如果减为1, 直接退出. 
   - 否则减为0,xlog_in_core的写回任务完成
   - 把xlog_in_core->ic_state改为XLOG_STATE_DONE_SYNC
   - 唤醒等待的任务, flush任务
   > wake_up_all(xlog_in_core->ic_write_wait)
   - 处理callback
   > xlog_state_do_callback(xlog, aborted, xlog_in_core)

** xlog_state_get_iclog_space(xlog, len, xlog_in_core, xlog_ticket, coutinued_write, logoffsetp)
   - 获取可用的xlog_in_core,写xfs_log_vec时调用
   - len表示将要写的xfs_log_vec占用的数据量
   - xlog_in_core必须有序使用
   - 检查xlog->xlog_in_core, 如果xlog_in_core->ic_state不是XLOG_STATE_ACTIVE
   - 在callback处理后, xlog_in_core变为XLOG_STATE_DIRTY,然后变为XLOG_STATE_ACTIVE, 唤醒xlog->l_flush_wait队列
   > xlog_wait(xlog->l_flush_wait, xlog->l_icloglock)
   - 增加xlog_rec_header->ic_refcnt, 别的任务不会把它写入磁盘, 当前任务操作完成后,才会释放计数
   - 获取xlog_in_core->xlog_in_core2->xlog_rec_header,可能做一些初始化
   - 获取它的空闲空间偏移, xlog_rec_header->ic_offset, 就是xfs_log_vec写入的位置
   - 如果xlog_in_core->ic_offset = 0, 初始化这个xlog_in_core
   - 减小xlog_ticket reserve的log空间, 因为这些xlog_in_core2数组也会写到log空间
   - xlog_ticket->t_curr_res -= xlog->l_iclog_hsize
   - 把xlog_in_core2数组的内存指针放到xlog_ticket->t_res_arr数组中
   > xlog_tic_add_region(xlog_ticket, xlog->l_iclog_hsize, XLOG_REG_TYPE_LRHEADER)
   - 设置xlog_rec_header->h_cycle = xlog->l_curr_cycle
   - 设置xlog_rec_header->h_lsn = xlog_assign_lsn(xlog->l_curr_cycle, xlog->l_curr_block), 这就log空间真正的头指针,而不是reserve的头指针
   - 检查剩余空间是否够2个xlog_op_header.
   - xlog_in_core->ic_size - xlog_in_core->ic_offset < 2 * sizeof(xlog_op_header)
   - 如果不够, 切换这个xlog_in_core
   > xlog_state_switch_iclogs(xlog, xlog_in_core, xlog_in_core->ic_size)
   - 释放使用计数, xlog_in_core->ic_refcnt --
   - 如果计数减为0, 推进xlog_in_core的状态
   > xlog_state_release_iclog(xlog, xlog_in_core)
   - 重新获取xlog的当前可用的xlog_in_core
   - 如果空间足够多,超过2个xlog_op_header的大小,使用它保存xfs_log_vec
   - 检查xlog_in_core的空闲空间, 如果超过len
   - xlog_in_core->ic_size - xlog_in_core->ic_offset >= len
   - 表示当前xlog_in_core不仅支持这次xfs_log_vec,其他人也可使用它
   - 增加xlog_in_core->ic_offset += len, coutinued_write = 0
   - 否则需要两个, 设置continued_write = 1
   - 切换当前使用的xlog_in_core, 别人会使用新的
   > xlog_state_switch_iclogs(xlog, xlog_in_core, xlog_in_core->ic_size)
   - 对于第二个xlog_in_core没有初始化, 让使用者去做. 这样也无法保证xfs_log_vec数据的连续性!
   - logoffsetp指向数据在xlog_in_core中的位置

** xlog_regrant_reserve_log_space(xlog, xlog_ticket)
   - 重新为xlog_ticket reserve空间
   - 如果t_cnt > 0, 减小xlog_ticket->t_cnt --
   - 释放没有使用的reserve空间, xlog_ticket->t_curr_res
   - 包括xlog->l_reserve_head / l_write_head
   > xlog_grant_sub_space(xlog, xlog->l_reserve_head->grant, xlog_ticket->t_curr_res)
   - 设置xlog_ticket->t_curr_res = xlog_ticket->t_unit_res, 恢复满的reserve空间的大小
   - 总的reserve的空间是t_unit_res, t_curr_res表示剩余的reserve空间
   - 重置xlog_ticket->xlog_res数组的索引和计数
   > xlog_tic_reset_res(xlog_ticket)
   - 如果xlog_ticket->t_cnt > 0, 就不需要reserve, xlog_ticket还有足够的
   - 否则reserve空间, 这里使用xlog->l_reserve_head
   > xlog_grant_add_space(xlog, xlog->l_reserve_head->grant, xlog_ticket->t_unit_res)
   - 又要重新设置xlog_ticket->t_curr_res = t_unit_res? 别的地方会修改???
   > xlog_tic_reset_res(xlog_ticket)

** xlog_ungrant_log_space(xlog, xlog_ticket)
   - 释放xlog_ticket所有reserve的空间
   - 如果t_cnt > 0, 减小xlog_ticket->t_cnt --
   - 如果xlog_ticket->t_cnt > 0,它必须是permanent 
   - xlog_ticket->t_flags有XLOG_TIC_PERM_RESERV
   - 计算需要释放的空间
   - xlog_ticket->t_curr_res + xlog_ticket->t_unit_res * t_cnt
   - 移动xlog_grant_head / xlog_write_head指针
   > xlog_grant_sub_space(xlog, xlog->l_reserve_head->grant, bytes)
   - 唤醒等待空间的任务
   > xfs_log_space_wake(xlog->xfs_mount)

** xlog_state_release_iclog(xlog, xlog_in_core)
   - 释放xlog_in_core的使用计数
   > atomic_dec_and_lock(xlog_in_core->ic_refcnt, xlog->l_icloglock)
   - 如果不是0, 直接退出
   - 否则处理xlog_in_core的状态
   - xlog_in_core->ic_state应该是XLOG_STATE_ACTIVE或XLOG_STATE_WANT_SYNC
   - 如果不是XLOG_STATE_WANT_SYNC, 不再继续处理, 直接退出
   - 否则把它写回磁盘
   - 设置xlog_rec_header->h_tail_lsn为当前xfs_ail中最小的xfs_log_item的位置
   - 这个xfs_log_item已经写回log队列, 但没有提交到FS空间, 所以他是log队列的尾
   > xlog_assign_tail_lsn(xlog->xfs_mount)
   - 所以对于一个xlog_in_core, 他可以确定log队列的尾,他当前就是log队列的头
   - 修改xlog_in_core的状态
   - xlog_in_core->ic_state设置XLOG_STATE_SYNCING
   - xlog_in_core->xlog_in_core2->xlog_rec_header->h_tail_lsn = tail_lsn
   > xlog_verify_tail_lsn(xlog, xlog_in_core, tail_lsn)
   - 提交对应的xfs_buf的写请求
   > xlog_sync(xlog, xlog_in_core)

** xlog_state_switch_iclogs(xlog, xlog_in_core)
   - 切换xlog当前指向的xlog_in_core
   - 设置旧的xlog_in_core, 没有初始化新的xlog_in_core, 通过xlog->l_curr_block/cycle, 计算下一个xlog_in_core的磁盘位置
   - 当前xlog_in_core->ic_state必须是XLOG_STATE_ACTIVE, 把它改为XLOG_STATE_WANT_SYNC
   - 获取它的xlog_in_core2->xlog_rec_header
   - 设置xlog_rec_header->h_prev_block = xlog->l_prev_block, 相当于建造一个回朔的链表, 可以倒序遍历xlog_in_core
   - 把xlog->l_curr_block/cycle给xlog->l_prev_block/cycle
   - 计算xlog->l_curr_block/cycle, 也就是下一个xlog_in_core的磁盘位置
   - 向前偏移当前xlog_in_core的大小
   - eventual_size是xlog_in_core->ic_size或者0
   - ic_size表示xlog_in_core的数据空间, 即使没有完全用完,浪费了空间
   - 如果eventual_size是0, 替换为ic_offset, 表示实际有的数据量, 没有浪费
   - xlog->l_curr_block += BTOBB(eventual_size + xlog->l_iclog_hsize)
   - 如果xfs支持logv2, 让xlog->l_curr_block对齐到super_block->sb_logsunit
   - 如果xlog->l_curr_block超过l_logBBsize, 增加xlog->l_curr_cycle
   - 最后设置xlog->l_iclog = xlog_in_core->ic_next

** _xfs_log_force(xfs_mount, flags, log_flushed)
   - 把xfs_cil积累的xfs_log_item写到xlog_in_core
   > xlog_cil_force(xlog)
   - 如果log_in_core->ic_state != XLOG_STATE_DIRTY|XLOG_STATE_ACTIVE, 必须等待, 至少当前xlog_in_core在写回或回调状态
   - 否则检查具体的xlog_in_core, 可能不需要等待
   - 如果xlog_in_core->ic_state == XLOG_STATE_DIRTY, 而且xlog_in_core->ic_refcnt == 0或者xlog_in_core->ic_offset = 0, 这个xlog_in_core没有使用
   - 检查前一个xlog_in_core->ic_prev, 数据提交到前一个xlog_in_core中，它肯定指向log队列的头
   - 如果它也是XLOG_STATE_ACTIVE|DIRTY, 也就是他的写回和回调完成，整个队列的xlog_in_core都完成, 不需要等待；否则它在写回或回调状态，等待它完成
   - 否则处理当前xlog_in_core的其他状态，至少xlog_in_core->ic_state是XLOG_STATE_ACTIVE
   - 如果xlog_in_core->ic_refcnt ==0, 肯定xlog_in_core->ic_offset>0, 根据上面的判断条件，没人在使用它
   - 当前xlog_in_core有数据没有提交, 这里需要提交它，先切换xlog, 然后通过释放计数进一步推进ic_state
   - 增加xlog_in_core->ic_refcnt, 切换xlog 
   > xlog_state_switch_iclogs(xlog, xlog_in_core, 0)
   - 然后释放计数, 写回xlog_in_core
   > xlog_state_release_iclog(xlog, xlog_in_core)
   - 这里需要设置log_flushed, 表示当前任务写回log队列
   - 锁住xlog_in_core, 计算是否要等待
   - 这时xlog_in_core可能已经完成,虽然时间很短
   - xlog_in_core->xlog_in_core2->xlog_rec_header->h_lsn可能会改变, 和上面不一样，而且ic_state变为XLOG_STATE_DIRTY, 不需要等待
   - 否则需要等待
   - 如果xlog_in_core->ic_refcnt !=0, 其他人正在使用, 只需要切换它, 别人释放时会掉交写回操作
   - 然后等待这个xlog_in_core的完成
   - 这里切换时直接限定xlog_in_core的大小, 虽然有别人在使用；别人不会继续改动ic_offset;否则会先切换它，然后修改.
   > xlog_state_switch_iclogs(xlog, xlog_in_core, 0)
   - 最后是等待处理 如果参数flags没有XFS_LOG_SYNC, 直接退出
   - 等待xlog_in_core->ic_force_wait, 在xlog_in_core的回调完成后会唤醒
   > xlog_wait(xlog_in_core->ic_force_wait, xlog->l_icloglock)

** xfs_log_force(xfs_mount, flags)
   > _xfs_log_force(xfs_mount, flags, NULL)

** _xfs_log_force_lsn(xfs_mount, xfs_lsn_t, flags, log_flushed)
   - xfs_lsn_t是sequence, 把它对应的xfs_cil_ctx写回xlog_in_core
   > xlog_cil_force_lsn(xlog, xfs_lsn_t)
   - 它也返回了最后一个xlog_in_core的 xlog_rec_header->h_lsn
   - 遍历xlog->l_iclog, 找到对应的xlog_in_core
   - 如果xlog_in_core->ic_state == XLOG_STATE_DIRTY, 直接退出, 已经提交完成
   - 如果xlog_in_core->ic_state == XLOG_STATE_ACTIVE, 正在使用中,需要写回并等待
   - 等待分成2次，先检查前一个xlog_in_core, xlog_in_core->ic_prev
   - 如果它的状态是XLOG_STATE_WANT_SYNC|SYNCING, 等待它的IO完成,然后再提交当前的xlog_in_core
   > xlog_wait(xlog_in_core->ic_prev->ic_write_wait, xlog->l_icloglock)
   - 在xlog_in_core的IO回调中唤醒这个等待, 在callback之前
   - 然后重新扫描，可能xlog_in_core已经完成，重复使用， xfs_lsn_t已经改变
   - 如果还是XLOG_STATE_ACTIVE, 需要切换，写回并等待回调完成
   - xlog_in_core->ic_refcnt ++
   - 切换,可能推进它的状态
   > xlog_state_switch_iclogs(xlog, xlog_in_core, 0)
   - 释放计数，可能推进它的状态
   > xlog_state_release_iclog(xlog, xlog_in_core)
   - 最后是等待处理
   - 如果xlog_in_core->ic_state不是XLOG_STATE_ACTIVE|DIRTY, 而且flags & XFS_LOG_SYNC != 0, 才需要等待
   - 使用force的等待队列
   > xlog_wait(xlog_in_core->ic_force_wait, xlog->l_iclogwork)

** xfs_log_force_lsn(xfs_mount, xfs_lsn_t, flags)
   > _xfs_log_force_lsn(xfs_mount, xfs_lsn_t, flags, NULL)

** xlog_state_want_sync(xlog, xlog_in_core)
   - 在xlog_in_core空间无法容纳更多xlog_op_header时使用
   - 改变xlog_in_core的状态,让他变为XLOG_STATE_WANT_SYNC
   - 如果xlog_in_core->ic_state是XLOG_STATE_ACTIVE, 通过切换实现
   > xlog_state_switch_iclogs(xlog, xlog_in_core, 0)
   - 否则必须保证xlog_in_core->ic_state是XLOG_STATE_WANT_SYNC|IOERROR

** xfs_log_ticket_put(xlog_ticket) 
   - 释放xlog_ticket, xlog_ticket->t_ref --
   - 如果变为0,释放它.

** xfs_log_ticket_get(xlog_ticket)
   - xlog_ticket->t_ref ++

** xfs_log_calc_unit_res(xfs_mount, unit_bytes)
   - 计算xlog_ticket占用的最大空间, 额外空间包括
   - 包括xfs_trans_header的xlog_op_header
   - XLOG_START_TRANS使用的xlog_op_header
   - xfs_log_vec使用的xlog_op_header应该在参数里面, 但它可能会放在多个xlog_in_core中
   - 需要多余的xlog_op_header, 和xlog_in_core2->xlog_rec_header数组的空间
   - 但xlog_op_header的增长又会导致使用多余的xlog_in_core, 所以这里使用while循环处理
   - 最后还有commit-rec, 使用一个xlog->l_iclog_hsize???
   - 还有对齐空间2个BBSIZE,或sb_logsunit

** xlog_ticket_alloc(xlog, unit_bytes, cnt, client, permanent, xfs_km_flags_t)
   - 创建xlog_ticket, 它对应一个transaction. 
   - 计算一次xfs_trans需要的空间
   > xfs_log_calc_unit_res(xfs_mount, unit_bytes)
   - 设置xlog_ticket->t_unit_res / t_curr_res = unit_bytes
   - 设置xlog_ticket->t_cnt / t_ocnt = cnt
   - 设置xlog_ticket->t_flags = XLOG_TIC_INITED
   - 如果permanent != 0, 设置xlog_ticket->t_flags的XLOG_TIC_PERM_RESERV
   - 重置计数
   > xlog_tic_reset_res(xlog_ticket)

** xlog_verify_dest_ptr(xlog, ptr)
   - xlog_ticket里面存储xfs_log_iovec数据的内存区域
   - 检查ptr是否在这些范围内

** xlog_verify_grant_tail(xlog)
   - 检查xlog->l_write_header和xlog->l_tail_lsn, l_write_head不能是log队列的头, 但还是检查是否2者覆盖
   - l_write_head为何不能多reserve??

** xlog_verify_tail_lsn(xlog, xlog_in_core, xfs_lsn_t tail_lsn)
   - 检查log队列的长度, 头是xlog->l_prev_cycle, 当前xlog_in_core没有写回
   - 尾是xlog->l_tail_lsn
   - 空闲空间不能超过当前xlog_in_core的长度, 也就是参数xlog_in_core
   - xlog_in_core->ic_offset + xlog->l_iclog_hsize

** xlog_verify_iclog(xlog, xlog_in_core, count, syncing)
   - 在写回xlog_in_core之前,检查它的参数
   - xlog_in_core的xfs_buf中每个block开头都不是XLOG_HEADER_MAGIC_NUM, 特殊的magic, 只有第一个才是
   - 检查里面的每个xlog_op_header
   - xlog_op_header->oh_clientid必须是XFS_LOG或XFS_TRANSACTION
   - 根据xlog_op_header->oh_len查找下一个

** xlog_state_ioerror(xlog)
   - 设置xlog_in_core的错误标志
   - 对于xlog_in_core->ic_state 没有XLOG_STATE_IOERROR, 添加标志.
   - 遍历所有的xlog_in_core

** xfs_log_force_umount(xfs_mount, logerror)
   - 强制关闭文件系统时使用, 因为io错误关闭
   - 如果文件系统在recovery log?  xlog->l_flags & XLOG_ACTIVE_RECOVERY
   - 设置xlog_mount->m_flags的XFS_MOUNT_FS_SHUTDOWN
   > XFS_BUF_DONE(xfs_mount->m_sb_bp)
   - 直接退出??
   - 如果xlog->xlog_in_core->ic_state有XLOG_STATE_IOERROR, 直接退出
   - 如果logerror ==0, 写回xfs_cil
   > xlog_cil_force(xlog)
   - 添加标志xfs_mount->m_flags的XFS_MOUNT_FS_SHUTDOWN
   - 设置XBF_DONE,表示缓存的数据都是uptodate
   > XFS_BUF_DONE(xfs_mount->m_sb_bp)
   - 唤醒等待xlog空间的任务
   > xlog_grant_head_wake_all(xlog->l_reserve_head)
   - 如果当前xlog_in_core->ic_state没有XLOG_STATE_IOERROR, log没有错误,FS有严重错误
   - 写回当前xlog_in_core, 也就是把所有的xlog_in_core都写回
   > _xlog_log_force(xfs_mount, XFS_LOG_SYNC, NULL)
   - 设置所有的xfs_in_core的错误标志
   > xlog_state_ioerror(xlog)
   - 执行callback任务,唤醒等待xlog_in_core的任务
   > xlog_state_do_callback(xlog, XFS_LI_ABORTED, NULL)
   
** xlog_iclogs_empty(xlog)
   - 检查所有的xlog_in_core->xlog_in_core2->xlog_rec_header->h_num_logops
   - 表示xlog_in_core包含的xlog_op_header的个数
   - 如果都为0返回1, 整个xlog都是空的

** 总结
   - xlog_in_core的状态
     #+begin_src 
#define XLOG_STATE_ACTIVE    0x0001 /* Current IC log being written to */
#define XLOG_STATE_WANT_SYNC 0x0002 /* Want to sync this iclog; no more writes */
#define XLOG_STATE_SYNCING   0x0004 /* This IC log is syncing */
#define XLOG_STATE_DONE_SYNC 0x0008 /* Done syncing to disk */
#define XLOG_STATE_DO_CALLBACK \
			     0x0010 /* Process callback functions */
#define XLOG_STATE_CALLBACK  0x0020 /* Callback functions now */
#define XLOG_STATE_DIRTY     0x0040 /* Dirty IC log, not ready for ACTIVE status*/
#define XLOG_STATE_IOERROR   0x0080 /* IO error happened in sync'ing log */
#define XLOG_STATE_ALL	     0x7FFF /* All possible valid flags */
#define XLOG_STATE_NOTUSED   0x8000 /* This IC log not being used */
     #+end_src
     - XLOG_STATE_ACTIVE: 表示xlog_in_core可用,可能在使用中已有了数据. 初始化时设置为ACTIVE,xlog_state_clean_log把它从DIRTY变为ACTIVE. 装满数据或它不在是xlog当前的xlog_in_core时把它变为WANT_SYNC状态. 在xfs_cil使用它时,必须保证xlog_in_core是ACTIVE状态,如果不是要等待.
     - XLOG_STATE_WANT_SYNC表示需要sync, 在没人使用它,使用计数变为0时,变为XLOG_STATE_SYNCING. 在xlog切换xlog_in_core时,改为XLOG_STATE_WANT_SYNC.
     - XLOG_STATE_SYNCING: 设这这个状态后,启动xlog_sync;表示xlog_in_core在提交并等待IO过程中. 在IO完成后,必须是这个状态.然后启动io回调,状态改为XLOG_STATE_DONE_SYNC.
     - XLOG_STATE_DONE_SYNC, 这个状态是一个过度状态,我觉得可以被XLOG_STATE_DO_CALLBACK代替
     - XLOG_STATE_DO_CALLBACK, 表示它等待处理回调. 因为xlog_in_core的回调处理需要保证顺序,所以使用这个状态同步.
     - XLOG_STATE_CALLBACK, 表示它开始处理回调函数.它也是累赘,没必要.
     - XLOG_STATE_DIRTY, 表示它已经没用,在回调完成后设置为这个状态, 它变很快变为XLOG_STATE_ACTIVE.
   - xlog->l_covered_state表示是否需要xlog_in_core的提交任务去故意的添加一个dummy transaction的xlog_in_core
     #+begin_src 
#define XLOG_STATE_COVER_IDLE	0     #不用
#define XLOG_STATE_COVER_NEED	1     #需要
#define XLOG_STATE_COVER_DONE	2     #不用
#define XLOG_STATE_COVER_NEED2	3     #需要
#define XLOG_STATE_COVER_DONE2	4     #需要
     #+end_src
     - XLOG_STATE_COVER_IDLE 初始化的状态, 不需要dummy transaction. 在xlog_in_core写入磁盘后变为XLOG_STATE_COVER_NEED(xlog_state_clean_log)
     - XLOG_STATE_COVER_NEED, xlog->l_work开始执行时,它会写一个dummy transaction,而不是提交xfs_log_item/xlog_in_core. 它变为XLOG_STATE_COVER_DONE.
     - XLOG_STATE_COVER_NEED2, 在XLOG_STATE_COVER_DONE写了一个dummy transaction,变为这个状态. 决定写dummy之后,变为XLOG_STATE_COVER_DONE2.
     - XLOG_STATE_COVER_DONE, 在XLOG_STATE_COVER_NEED,而且决定写一个dummy transaction, 变为这个状态. 在写了dummy之后,变为XLOG_STATE_COVER_NEED2, 普通的为XLOG_STATE_COVER_NEED
     - XLOG_STATE_COVER_DONE2, 在XLOG_STATE_COVER_NEED2,决定要写一个dummy, 变为这个状态. 下次再写一个dummy, 变为IDLE状态. 如果写了一个普通的xlog_in_core, 变为XLOG_STATE_COVER_NEED

   - 等待队列的使用
     - xlog->l_flush_wait, 用来等待整个xlog
       - 唤醒操作在xlog_in_core的回调处理, 可能完成一些xlog_in_core,如果当前xlog_in_core->ic_state是XLOG_STATE_ACITVE|XLOG_STATE_IOERROR时唤醒
       - 等待操作是在查找当前可用的xlog_in_core,发现不是XLOG_STATE_ACTIVE
     - xlog_in_core->ic_force_wiat, 等待单独的xlog_in_core
       - 唤醒操作在xlog_in_core的callback阶段完成中,它的状态可能是XLOG_STATE_IOERROR|XLOG_STATE_ACTIVE, 也可能是XLOG_STATE_CALLBACK, 等待前面的没有变为XLOG_STATE_DIRTY的xlog_in_core
       - 等待操作是在flush中, 如果xlog_in_core不是XLOG_STATE_DIRTY|XLOG_STATE_ACTIVE
     - xlog_in_core->ic_write_wait, 等待xlog_in_core的写回完成
       - 唤醒操作在xlog_in_core的回调中, IO完成后直接唤醒
       - 等待操作仅仅在flush中,如果前一个xlog_in_core的状态是XLOG_STATE_SYNCING, 等待这个xlog_in_core的IO完成后,再提交当前xlog_in_core的IO

   - xfs_buf的回调函数在xfslogd_workqueue工作队列中执行.

   - xlog_in_core的状态转换
     - XLOG_STATE_ACTIVE:初始状态或者可用的状态. 从XLOG_STATE_DIRTY变为这个状态,需要所有的xlog_in_core有序的进入这个状态
     - XLOG_STATE_WANT_SYNC: 等待IO状态. 在xlog_in_core切换出去后变为这个状态,在xlog_in_core空间已满后切换,或者force flush中切换. 如果还有人使用,还在往里面放xfs_log_vec, 等待任务完成, 完成后直接变为下一个状态。即使没有人使用,要想推进到下一个状态也是通过计数的增减实现
     - XLOG_STATE_SYNCING:IO状态. 替换block的cycle, 计算checksum, 提交xfs_buf的IO
     - XLOG_STATE_DONE_SYNC: 完成IO.在IO的回调函数中, 如果没有错误, 设置为这个状态.
     - XLOG_STATE_DO_CALLBACK: 等待其他xlong_in_core的IO状态. 所有的xlog_in_core需要顺序的执行callback. 如果前面的xlog_in_core还没有完成IO,设置为XLOG_STATE_DO_CALLBACK, 让后面的xlog_in_core IO完成后执行它, 执行它时变为下一个XLOG_STATE_CALLBACK. 它也可能直接从XLOG_STATE_SYNCING变为XLOG_STATE_CALLBACK, IO完成后不需要等待别人,直接执行callback
     - XLOG_STATE_CALLBACK: callback阶段, 开始处理callback回调
     - XLOG_STATE_DIRTY:等待其他xlog_in_core的callback状态.  在callback完成之后,如果没有IOERROR,变为这个状态, 如果前面的xlog_in_core状态都变为XLOG_STATE_ACTIVE, 它也变为XLOG_STATE_ACTIVE,否则等待前面的xlog_in_core

   - 这里的主要功能
   - 管理xlog空间, 预留xlog空间, 无法分配时等待
   - mount操作,启动recovery操作, 初始化xlog,xlog_in_core, xfs_cil, xfs_ail等.
   - umount操作, 刷新xlog数据,以及ail数据, 提交umount的xlog_op_header.
   - 管理xlog_in_core的状态变化, 不会给外部接口.
   - 使用mp->m_log_workqueue / xlog->l_work定期的提交xfs_cil_ctx/xlog_in_core的信息
   - 实现了xlog数据从xfs_log_vec向xlog_in_core转移的功能,并给xfs_cil提供接口,写xfs_log_vec数据 xlog_write
   - 实现了xlog_in_core写回磁盘的功能,并且使用xfs_buf的回调,触发xlog_in_core的状态变化
   - 给外部提供接口,写回xfs_cil/xlog_in_core数据,可以全部写回xfs_cil (xfs_log_force),也可以写回指定的xfs_cil_ctx (xfs_log_force_lsn)
     
* xfs_log_cil.c
  
** xfs_cil_ctx 
   #+begin_src 
	struct xfs_cil		*cil;
	xfs_lsn_t		sequence;	/* chkpt sequence # */ //xlog->xfs_cil是唯一的,sequence表示xfs_cil_ctx的次序. 
	xfs_lsn_t		start_lsn;	/* first LSN of chkpt commit */ //表示它使用的第一个xlog_in_core的标示
	xfs_lsn_t		commit_lsn;	/* chkpt commit record lsn */
 //标示它使用的最后一个的xlog_in_core的标示
	struct xlog_ticket	*ticket;	/* chkpt ticket */
	int			nvecs;		/* number of regions */  //xfs_log_iovec的数量
	int			space_used;	/* aggregate size of regions */  //xfs_log_item需要占用的xlog的数量
	struct list_head	busy_extents;	/* busy extents in chkpt */
	struct xfs_log_vec	*lv_chain;	/* logvecs being pushed */ //xfs_log_vec / xfs_log_item
	xfs_log_callback_t	log_cb;		/* completion callback hook. */
	struct list_head	committing;	/* ctx committing list */   //xfs_cil->xc_committing队列
   #+end_src

** 总结
   - xfs_cil_ctx管理提交中的xfs_log_item. 它应该包含多个xfs_trans的xfs_log_item.
   - 整个xfs_cil_ctx提交时使用一个xfs_log_vec链表, 里面包装xlog_op_header是XFS_TRANS_CHECKPOINT
   = 最后使用一个空的xfs_log_vec,没有数据, xfs_log_iovec->i_type = XLOG_REG_TYPE_COMMIT, xfs_op_header->oh_flags = XLOG_COMMIT_TRANS. 它只会写一个空的xlog_op_header.
   - xfs_cil_ctx的提交是有序的, 写入的XLOG_COMMIT_TRANS是有序的,其他数据不保证. 使用xfs_cil_ctx->xc_commit_wait队列等待, 提交到xlog_in_core后会设置xfs_cil_ctx->commit_lsn, 根据它表示已经提交
   - 在xlog_in_core写到磁盘后触发xfs_cil_ctx->xfs_log_callback_t回调函数, 把xfs_log_item放到xfs_ail中

   - 这里对外的功能就是2个. xfs_cil就是缓存层, xfs_cil缓存xfs_trans的xfs_log_item. xfs_cil_ctx管理xfs_log_item, 在提交之前缓存，提交之后等待结构,把它转移给ail
   - 提供接口提交xfs_trans到xfs_cil
   - 提供接口提交xfs_cil_ctx, 还有一个回调接口,在xfs_log_item写到xlog_in_core中,转移给ail

   - xfs_cil提供一个xfs_log_item的缓存,批量提交给xlog_in_core. xfs_cil中xfs_log_item是有序的,但不保证他们在log队列中的顺序, 但它不保证xfs_ail中的顺序
   - 只能保证xfs_log_rec在xlog_in_core中的顺序和xfs_ail中的顺序一致

** xlog_cil_ticket_alloc(xlog)
   - 创建xlog_ticket,不会reserve任何空间. 虽然创建时会分配一些多余的,但后面重置为0, 但t_curr_unit不是0
   > xlog_ticket_alloc(xlog, 0, 1, XFS_TRANSACTION, 0, KM_SLEEP|KM_NOFS)
   - 设置xlog_ticket->t_trans_type = XFS_TRANS_CHECKPOINT
   - xlog_ticket->t_curr_res = 0, 不预留空间, 使用xfs_trans的空间

** xlog_cil_init_post_recovery(xlog)
   - 在创建xfs_cil时,创建第一个xlog_cil_ctx. 
   - 这个函数是recovery xlog之后调用的, 现在log队列已经准备好,可以预留空间.
   - 估计是创建xlog_ticket就需要xlog的信息,所以需要在恢复xlog之后才能使用.
   - xlog->xlog_cil->xfs_cil_ctx->ticket分配特殊的xlog_ticket
   - xfs_cil_ctx操作时使用的log空间来自于xfs_trans->xlog_ticket的空间
   > xlog_cil_ticket_alloc(xlog)
   - xfs_cil_ctx->sequence = 1
   - xfs_cil_ctx->commit_lsn指向log队列的头(xlog->l_curr_cycle, xlog->l_curr_block)

** xlog_cil_lv_item_format(xfs_log_item, xfs_log_vec)
   - 格式化xfs_log_item的数据, 至于数据放到哪里不清楚, 但指针在xfs_log_iovec中
   > xfs_log_item->xfs_item_ops->iop_format(xfs_log_item, xfs_log_vec->xfs_log_iovec)
   - 然后遍历这些xfs_log_iovec,把他们指向的内存数据复制到xfs_log_vec->lv_buf中
   - 然后再把xfs_log_iovec的指针指向xfs_log_vec中的空间
     
** xfs_cil_prepare_item(xlog, xfs_log_vec lv, xfs_log_vec old_lv, diff_len, diff_iovecs)
   - 在xfs_log_item放到cil之前, 更新它使用的xfs_log_vec. 而且累计它需要使用的空间
   - diff_len表示log的数据量, 每个item都有一个头部, diff_iovecs表示头的数量
   - 如果old_lv == NULL, xfs_log_item原来没有关联xfs_log_vec, 需要锁定资源
   > xfs_log_item->xfs_log_ops->iop_pin(xfs_log_item)
   - 否则不需要锁定资源, 但释放旧的xfs_log_vec, 并释放计数
   - 设置xfs_log_vec->xfs_log_item->li_seq = xlog->xfs_cil->xfs_cil_ctl->sequence

** xlog_cil_insert_format_items(xlog, xfs_trans, diff_len, diff_iovecs)
   - 如果xfs_trans->t_items为空, 严重错误!
   - 把xfs_log_item中的数据格式化,放到那里??
   - 遍历xfs_trans->t_items队列上的xfs_log_item_desc
   - 如果xfs_log_item_desc->lid_flags没有XFS_LID_DIRTY, 不需要处理
   - 计算需要的空间, 如果返回niovecs ==0, 不需要处理
   > xfs_log_item->xfs_log_ops->iop_size(xfs_log_item, niovecs, nbytes）
   - 如果返回XFS_LOG_VEC_ORDERED,表示什么??
   - 准备xfs_log_item->xfs_log_vec成员,保存log的数据
   - 如果xfs_log_item已经有,而且足够大xfs_log_vec->lv_size, 直接使用它
   - 格式化xfs_log_item的数据
   > xlog_cil_lv_item_format(xfs_log_item, xfs_log_vec)
   - 如果原来不存在,或者不够大,直接分配新的
   - 初始化新的xfs_log_vec, 它使用xfs_log_iovec数组内存在后面, xfs_log_vec->li_buf指向的内存在最后面, 里面存放格式化后的log数据
   - 同样转移数据
   > xlog_cil_lv_item_format(xfs_log_item, xfs_log_vec)
   - 最后关联xfs_log_vec和xfs_log_item
   > xfs_cil_prepare_item(xlog, xfs_log_vec lv, xfs_log_vec old_lv, diff_len, diff_iovecs)

** xlog_cil_insert_items(xlog, xfs_trans)
   - 把xfs_log_vec->xfs_log_item放到xfs_cil中
   - 准备xfs_log_item, 分配xfs_log_vec空间,并转移数据
   > xlog_cil_insert_format_items(xlog, xfs_trans, len, diff_iovecs)
   - 遍历xfs_trans->t_items队列上的xfs_log_item_desc，把对应的xfs_log_item放到xlog->xfs_cil中
   - 增加xfs_cil_ctx->nvecs += diff_iovecs
   - 把xfs_trans->t_busy中的xfs_extent_busy给xfs_cil_ctx->busy_extents
   - xfs_cil_ctx->xlog_ticket没有reserve空间
   - 他向log队列写数据需要多余的数据, xlog_ticket->t_unit_res, 使用xfs_trans->xlog_ticket->t_curr_res填充这些空间
   - 然后是xfs_log_vec使用的空间, 包括头xfs_log_iovec使用的xlog_op_header
   - len += sizeof(xlog_op_header) * diff_iovecs
   - 如果len需要多个xlog_in_core, 也就是使用额外的xlog_op_header, 还有xlog->l_iclog_hsize
   - 同样增大xfs_cil_ctx->xlog_ticket->t_unit_res / t_curr_res
   - 然后在xfs_trans->xlog_ticket->t_curr_res中减去这些空间, 预计消耗这些log空间
   - 修改xfs_cil_ctx计数
   - xfs_cil_ctx->nvecs += diff_iovecs
   - xfs_cil_ctx->space_used += len

   - 这里功能是把xfs_trans放到xfs_cil中,而且转移log空间
   - 只有在这里才消耗了xlog_ticket的预留空间

** xlog_cil_free_logvec(xlog_log_vec)
   - 释放xfs_log_vec链表
   - xfs_log_iovec->i_addr指向xfs_log_vec->lv_buf, 没有他分配内存.

** xlog_cil_committed(args, abort)
   - args就是xfs_cil_ctx,这个函数是xlog_in_core写回数据后的回调函数.可以释放xfs_cil_ctx.
   - 通知xfs_cil_ctx, 把xlog_log_item转移到ail中.
   > xfs_trans_committed_bulk(xfs_cil_ctx->xfs_cil->xlog->xfs_ail, xfs_cil_ctx->xfs_log_vec, xfs_cil_ctx->start_lsn, abort)
   - 处理xfs_busy_extent, 先按照ag排序
   - xfs_extent_busy_sort(xfs_cil_ctx->busy_extents)
   - 释放xfs_busy_extent,可能发送discard请求
   > xfs_extent_busy_clear(xfs_mount, xfs_cil_ctx->busy_extents, ( xfs_mount->m_flags & XFS_MOUNT_DISCARD) && !abort)
   - 释放xfs_cil_ctx->committing队列关系
   - 释放xfs_log_vec
   > xlog_cil_free_logvec(xfs_cil_ctx->lv_china)
   - 发送discard请求, 上面不会释放要求discard操作的xfs_busy_extent
   > xfs_discard_extents(xfs_mount, xfs_cil_ctx->busy_extents)
   > xfs_extent_busy_clear(xfs_mount, xfs_cil_ctx->busy_extents, false)
   - 最后释放xfs_cil_ctx使用的内存

** xlog_cil_push(xlog)
   - 把xfs_cil积累的xfs_log_item提交给xlog_in_core
   - 每次提交一匹,使用xfs_log_ctx管理他们.
   - 首先创建新的xfs_cil_ctx new_ctx, 后面代替xfs_cil->xc_ctx
   - 给它分配xfs_cil_ctx->xlog_ticket
   > xlog_cil_ticket_alloc(xlog)
   - 获取原来xfs_cil->xfs_cil_ctx ctx,下面的操作使用xfs_cil_ctx->xc_ctx_lock保护
   - 保证xfs_cil->xc_push_seq <= xfs_cil_ctx->sequence
   - sequence仅仅是一个计数,下面设置xfs_cil_ctx->sequence = old->sequence + 1
   - 传递给xfs_log_item->li_seq, 用来区分xfs_cil_ctx
   - xfs_cil->xc_cil队列中是xfs_log_item, 如果为空,就没有可处理的,直接退出.
   - xc_push_seq是调用者设定, 表示有条件的写回xfs_cil_ctx
   - 如果xfs_cil->xc_push_seq < xfs_cil_ctx->sequence, 直接退出
   - 遍历xfs_cil->xc_cil队列的xfs_log_item
   - 这是xfs_cil积累的, 在提交xfs_trans时把xfs_log_item转移到这里来.
   - 把他们管理的xfs_log_item放到xfs_cil_ctx->lv_chain链表中
   - 然后从xfs_cil中释放xfs_log_item, 而且释放对xfs_log_vec的管理
   - 后面再通过xfs_log_vec,访问xfs_log_item, 放到xfs_ail管理中
   - 初始化新的xfs_cil_ctx, 让他代替旧的
   - xfs_cil_ctx->sequence = ctx->sequence + 1
   - xfs_cil_ctx->cil = xfs_cil, 建立关联关系 
   - xfs_cil->xc_current_sequence = xfs_cil_ctx->sequence
   - 把新的xfs_cil_ctx->committing放到队列xfs_cil->xc_committing

   - 开始处理old xfs_cil_ctx, 把xfs_log_vec数据写到xlog_in_core
   - 首先写入带有xfs_trans_header的xlog_op_header
   - 创建xfs_trans_header, 使用xfs_log_vec/xfs_log_iovec包装起来
   - xfs_trans_header->th_magic = XFS_TRANS_HEADER_MAGIC, ty_type = XFS_TRANS_CHECKPOINT
   - xfs_trans_heaer->th_tid = xlog_ticket->t_tid, 这是随机数, 用来区别xfs_trans
   - 准备一个xfs_log_iovec, 指向上面的内存数据
   - xfs_log_iovec->i_type = XLOG_REG_TYPE_TRANSHDR
   - 准备一个xfs_log_vec, 容纳这一个特殊的xfs_log_iovec
   - 把xfs_cil_ctx->lv_chain链表放到这个特殊的xfs_log_vec后面,写回xlog_in_core
   > xlog_write(xlog, xfs_log_vec, xlog_ticket, xfs_cil_ctx->start_lsn, NULL, 0)
   - xfs_cil_ctx->start_lsn记录使用的第一个xlog_in_core

   - 遍历xfs_cil->xc_committing的xfs_cil_ctx
   - 处理老的xfs_cil_ctx, sequence < ctx->sequence
   - 如果哪些xfs_cil_ctx->commit_lsn = 0, 说明没有提交xfs_cil_ctx
   - 什么情况下会乱序提交, 等待他们提交完成
   > xlog_wait(xfs_cil->xc_commit_wait, xfs_cil->xc_cil_lock)

   - 如果前面的xfs_cil_ctx都提交完成, 当前xfs_cil_ctx才能算完成
   - 写回一个XLOG_CIMMIT_TRANS的包, 然后释放xlog_ticket 
   > xfs_log_done(xlog->xfs_mount, xlog_ticket, xlog_in_core, 0)
   - 这里返回一个xlog_in_core, 它不一定是上面xfs_cil_ctx->start_lsn对应的

   - 初始化xfs_cil_ctx->xfs_log_callback, 回调函数是xlog_cil_committed
   - 把回调函数给对应的xlog_in_core, XLOG_COMMIT_TRANS所在的xlog_in_core
   > xfs_log_notify(xlog->xfs_mount, xlog_in_core, xfs_cil_ctx->log_cb)

   - 设置xfs_cil_ctx->commit_lsn, 唤醒其他等待的xfs_cil_ctx的处理
   > wake_up_all(xfs_cil_ctx->xc_commit_wait)
   - 最后使用的xlog_in_core计数,可能会写回xlog_in_core
   > xfs_log_release_iclog(xlog->xfs_mount, xlog_in_core)

   - 通过等待xfs_cil_ctx的提交,保证XLOG_COMMIT_TRANS的有序写入, 同样保证注册回调函数的有序, 同样保证了xfs_cil_ctx释放的有序,保证了xfs_ail中xfs_log_item的有序

** xlog_cil_push_work(work_struct)
   - work_struct是xfs_cil->xc_push_work, 执行上面的任务
   > xlog_cil_push(xfs_cil->xc_log)

** xlog_cil_push_background(xlog)
   - 把xfs_cil上的xfs_log_item写到xlog_in_core中.
   - 如果xlog->xfs_cil->xfs_cil_ctx->space_used的数据总量没有超过阈值,直接退出. 
   - 在xfs_trans提交时,xfs_log_item直接到xfs_cil_ctx中,而且增长xfs_cil_ctx->space_used
   > XLOG_CIL_SPACE_LIMIT(xlog)   xlog->l_logsize/8
   - 如果xfs_cil->xc_push_seq < xfs_cil->xc_current_sequence, 才会提交work_struct
   - 设置xfs_cil->xc_push_seq = xfs_cil->xc_current_sequence
   > queue_work(xlog->xfs_mount->m_cil_workqueue, xfs_cil->xc_push_work)

   - 阈值这么大, 可能会有大量的缓存, 但应该不会有太多的xfs_cil_ctx
   - 而xlog_in_core相对来说较小, 会有xfs_cil_ctx的积累

** xlog_cil_push_foreground(xlog, xfs_lsn_t push_seq)
   - 处理xlog->xfs_cil, sequence应该是sequence之类的
   - 刷新xfs_cil->xc_push_work, 它是其他异步提交xfs_cil的任务
   > flush_work(xfs_cil->xc_push_work)
   - 如果xfs_cil->xc_cil为空 或者 xfs_cil->xc_push_seq >= push_seq, 不需要处理这个xfs_cil
   - xfs_cil->xc_push_seq = push_seq
   - 直接执行写回
   > xlog_cil_push(xlog)
   - 这里push_seq应该是最新的xfs_cil_ctx使用的,仅仅提交最新的xfs_cil_ctx, 或者强制提交特定的xfs_cil_ctx

** 总结consequence
   - xfs_cil->xc_current_sequence表示当前xfs_cil_ctx->sequence
   - xfs_cil->xc_push_seq表示正在或已经提交的xfs_cil_ctx->sequence, 在提交过程中,如果没有xfs_log_item, 会设置为0
   - xfs_cil_ctx->sequence, 根据这个排序, 或者唯一识别它

** xlog_cil_empty(xlog)
   - 检查xfs_cil->xc_cil是否为空,没有xfs_log_item
   
** xfs_log_commit_cil(xfs_mount, xfs_trans, xfs_lsn_t commit_lsn, flags)
   - 把xfs_trans的数据放到xfs_cil_ctx中
   - xfs_cil的log数据提交以xfs_cil_ctx为单位
   - 如果flags包含XLOG_TRANS_RELEASE_LOG_RES, log_flags使用XFS_LOG_REL_PREM_RESERV, 表示最后xlog_ticket被直接释放掉,不要重复使用??
   - 把xfs_log_vec中的xfs_log_item给xfs_cil_ctx, 使用xfs_log_item->li_cil链表
   - 同时准备好xfs_log_vec, 转移xlog_ticket空间等
   > xlog_cil_insert_items(xlog, xfs_log_vec, xfs_trans->xlog_ticket)
   - xlog_ticket->t_curr_res < 0, reserve的空间不够? 关闭文件系统
   - 设置xfs_trans->t_commit_lsn = xfs_cil_ctx->sequence, 记录xfs_trans使用的xfs_cil_ctx
   - 如果xfs_trans是同步的, 根据它来flush xfs_cil_ctx
   - 释放xlog_ticket,这里不会写xlog_in_core的,因为xlog_ticket之前没有写过,所以t_flags & XLOG_TIC_INITED ==1, 但xfs_cil_ctx->xlog_ticket是被work_struct写过??
   > xfs_log_done(xfs_mount, xfs_trans->xlog_ticket, NULL, log_flags)
   - 释放reserve的fs空间,不是log空间
   - 修改xfs_sb计数在xfs_trans中的修改
   > xfs_trans_unreserve_and_mod_sb(xfs_trans)
   - 释放xfs_trans中的xfs_log_item_desc,把sequence传递给xfs_log_item
   > xfs_trans_free_items(xfs_trans, commit_lsn, 0)
   - 写回xfs_cil_ctx,当xfs_cil_ctx->space_used超过阈值,启动cil的work_struct, 写回xfs_cil_ctx
   > xlog_cil_push_background(xlog)
   
** xlog_cil_force_lsn(xlog, xfs_lsn_t sequence)
   - 根据xfs_lsn_t / sequence, 把合适的xfs_cil_ctx放到log中
   - sequence <= xfs_cil->xc_current_sequence
   - 启动写回工作
   - xlog_cil_push_foreground(xlog, xfs_lsn_t sequence)
   - 然后等待xfs_cil_ctx的完成,同样等待它之前的xfs_cil_ctx
   - 遍历xfs_cli->xc_committing队列的xfs_cil_ctx
   - 如果发现没有写进去的, 去xfs_cil->xc_commit_wait上等待
   > xlog_wait(xfs_cil->xc_commit_wait, xfs_cil->xc_cil_lock)
   - 这里返回xfs_cil_ctx使用的最后一个xlog_in_core的xfs_lsn_t, 可以用来flush xlog_in_core
  
** xfs_log_item_in_current_chkpt(xfs_log_item)
   - 检查xfs_log_item是不是在当前xfs_cil_ctx中, 他所在的xfs_trans已经提交,而且提交在xfs_cil中 
   - 如果xfs_log_item->li_cil队列为空,返回false
   - 返回xfs_log_item->li_seq == xlog->xfs_cil->xfs_cil_ctl->sequence

** xlog_cil_init(xlog)
   - 初始化xlog->l_cilp, xfs_cil
   - 创建xfs_cil, xfs_cil_ctx
   - xfs_cil_ctx->sequence = 1

** xlog_cil_destroy(xlog)
   - 销毁xlog的xfs_cil
   - 先释放xfs_cil_ctx->xlog_ticket
   > xfs_log_ticket_put(xlog_ticket)
   - 然后释放xfs_cil_ctx / xfs_cil

* xfs_trans.c

** xfs_trans_init(xfs_mount)
   - 初始化xfs_mount->xfs_trans_resv
   > xfs_trans_resv_calc(xfs_mount, xfs_mount->m_resv)

** xfs_trans_alloc(xfs_mount, type)
   - 等待内核frozen? 或者修改相关计数
   > sb_start_intwrite(xfs_mount->super_block)
   - 使用下面的函数构造xfs_trans
   > _xfs_trans_alloc(xfs_mount, type, KM_SLEEP)
   - 设置xfs_trans->t_flags |= XFS_TRANS_FREEZE_PROT
   
** _xfs_trans_alloc(xfs_mount, type, memflags)
   - 内核没有在frozen状态
   - super_block->s_writers->frozen != SB_FREEZE_COMPLETE
   - 增加xfs_mount->m_active_trans
   - 构造xfs_trans, 设置type/xfs_mount, 初始化其他成员
   - 设置xfs_trans->t_magic = XFS_TRANS_HEADER_MAGIC, 表示已经设置super_block

** xfs_trans_free(xfs_trans)
   - 释放xfs_trans
   - 先释放xfs_busy_extent队列,这些extent已经释放给AG, 只是别人在重复使用时检查,提交log
   > xfs_extent_busy_sort(xfs_trans->t_busy)
   > xfs_extent_busy_clear(xfs_trans->t_busy)
   - 减小 xfs_mount->m_active_trans --
   - 如果xfs_trans->t_flags & XFS_TRANS_FREEZE_PROT !=0, 释放super_block计数
   > sb_end_intwrite(xfs_trans->xfs_mount->super_block)

** xfs_trans_dup(xfs_trans)
   - 复制xfs_trans, 使用原来reserve的空间
   - 首先分配内存 xfs_trans
   - 初始化 t_magic/t_type/xfs_mount
   - 原来的xfs_trans必须有xlog_ticket
   - t_flags有XFS_TRANS_PERM_LOG_RES, 表示permanent log? 
   - 它和xfs_trans_resv->tr_logflags有关??
   - 设置新的t_flags的XFS_TRANS_PERM_LOG_RES, 继承原来t_flags的XFS_TRANS_RESERVE
   - 如果原来有XFS_TRNS_FREEZE_PORT, 转移到新的t_flags中, 去掉原来的标志
   - old->t_flags &= ~XFS_TRANS_FREEZE_PROT
   - 使用原来的xlog_ticket
   > xfs_log_ticket_get(old->xlog_ticket)
   - 把xfs_trans中剩余的reserve空间给新的xfs_trans
   - 设置new->t_blk_res = old->t_blk_res - old->t_blk_res_used
   - 更新old->t_blk_res = old->t_blk_res_used
   - rt的参数不看
   - 保存task_struct的trans相关参数
   - new->t_pflags = old->t_pflags
   - 增加xfs_mount->m_active_trans ++

** xfs_trans_reserve(xfs_trans, xfs_trans_resv, blocks, rtextents)
   - reserve磁盘空间和log空间, 如果没有磁盘空间返回-ENOSPC, 如果没有log空间等待回收.
   - 设置current->flags标志, 原来的标志备份到xfs_trans->t_pflags中
   - 当前任务在transaction中, 怎么锁住这些操作?
   > current_set_flags_nested(xfs_trans->t_pflags, PF_FSTRANS)
   - reserve磁盘空间, 修改xfs_sb计数
   > xfs_icsb_modify_counters(xfs_trans->xfs_mount, XFS_SBS_FDBLOCKS, -blocks, rsvd)
   - 把分配的空间给xfs_trans->t_blk_res += blocks 
   - 分配log空间, xfs_trans_resv->tr_logres
   - 如果xfs_trans_resv->tr_logflags有XFS_TRANS_PERM_LOG_RES, 使用永久空间, 设置xfs_trans->t_flags的XFS_TRANS_PERM_LOG_RES
   - 否则xfs_trans->t_ticket == NULL, 而且xfs_trans->t_flags没有XFS_TRANS_PERM_LOG_RES, 2个必须一致
   - 如果xfs_trans->xlog_ticket != NULL, 已有存在xlog_ticket, 重新分配空间
   > xfs_log_regrant(xfs_trans->xfs_mount, xfs_trans->xlog_ticket)
   - 否则创建xlog_ticket, 分配参数指定的空间
   > xfs_log_reserve(xfs_trans->xfs_mount, xfs_trans_resv->tr_logres, xfs_trans_resv->tr_logcount, xfs_trans->xlog_ticket, XFS_TRANSACTION, permanent, xfs_trans->t_type)
   - 把xfs_trans_resv的参数给xfs_trans, t_log_res / t_log_count
   - 最后rtextents, realtime extent

** xfs_trans_mod_sb(xfs_trans, field, delta)
   - 对xfs_sb修改时,先把改动记录在xfs_trans, 在提交xfs_trans时,再修改xfs_sb
   - field表示那些成员的变化, 更新xfs_trans中的变量
   - XFS_TRANS_SB_ICOUNT, xfs_trans->t_icount_delta += delta
   - XFS_TRANS_SB_IFREE, xfs_trans->t_ifree_delta += delta
   - XFS_TRANS_SB_FDBLOCKS, 记录分配的block, xfs_trans->t_fdblocks_delta += delta
   - 如果delta<0,更新xfs_trans->t_blk_res_used -= delta, 分配了空间还是预留了空间??
   - XFS_TRANS_SB_RES_FDBLOCKS, xfs_trans->t_res_fdblocks_delta += delta
   - XFS_TRANS_SB_FREXTENTS, 如果delta < 0, xfs_trans->t_rtx_res_used += -delta, xfs_trans->t_frextents_delta += delta
   - XFS_TRANS_SB_RES_FREXTENTS, xfs_trans->t_res_frextents_delta += delta
   - XFS_TRANS_SB_DBLOCKS, xfs_trans->t_dblocks_delta += delta
   - XFS_TRANS_SB_AGCOUNT, xfs_trans->t_agcount_delta += delta
   - XFS_TRANS_SB_IMAXPCT, xfs_trans->imaxpct_delta += delta
   - 最后设置xfs_trans->t_flags的XFS_TRANS_DIRTY|XFS_TRANS_SB_DIRTY
   - 如果支持lazy sb count,去掉XFS_TRANS_SB_DIRTY
   - 它表示提交xfs_trans时需要修改xfs_sb
   > xfs_sb_version_haslazysbcount(xfs_sb)

** xfs_trans_apply_sb_deltas(xfs_trans)
   - 把针对xfs_sb的修改写到xfs_log_item中
   - 获取xfs_sb使用的xfs_buf, 里面是xfs_dsb
   > xfs_trans_getsb(xfs_trans, xfs_mount, 0)
   - 如果不支持lazy sb, 先更新icount, i_free, fdbocks, res_fdblocks
   > xfs_sb_version_haslazysbcount(xfs_sb)
   - 把这4个统计量直接给xfs_dsb
   - 最后把xfs_buf放到xfs_trans里
   > xfs_trans_log_buf(xfs_trans, xfs_buf, 0, sizeof(xfs_dsb)-1)
   - 或者写一部分
   > xfs_trans_log_buf(xfs_trans, xfs_buf, offsetof(xfs_dsb, sb_icount), offsetof(xfs_dsb, sb_frextents) + sizeof(xfs_dsb->sb_frextents) -1)

** xfs_mod_sb 
   #+begin_src 
	xfs_sb_field_t	msb_field;	/* Field to modify, see below */
	int64_t		msb_delta;	/* Change to make to specified field */   
   #+end_src

** xfs_trans_unreserve_and_mod_sb(xfs_trans)
   - 释放没有使用的预留的空间,而且更新xfs_trans中缓存的对xfs_dsb的修改
   - xfs_trans->t_flags & XFS_TRANS_RESERVE影响reserve空间, 如果空间不够,可以使用特殊的空间, xfs_sb->m_resblks_avail
   - 处理磁盘空间, 包括reserve的空间xfs_trans->t_blk_res
   - 还有xfs_trans中保存的对xfs_sb的修改, xfs_trans->t_fdblocks_delta 
   - realtime空间
   - rtxdelta = xfs_trans->t_rtx_res + t_frextents_delta
   - 如果lazy sb count有效,或者xfs_trans->t_flags有XFS_TRANS_SB_DIRTY
   - 更新xfs_dsb的inode计数
   - xfs_trans->t_icount_delta / xfs_trans->t_ifree_delta
   - 处理磁盘空间
   > xfs_icsb_modify_counters(xfs_mount, XFS_SBS_FDBLOCKS, rsvd)
   - 处理inode计数
   > xfs_icsb_modify_counters(xfs_mount, XFS_SBS_ICOUNT, idelta, rsvd)
   - 处理空间的inode计数
   > xfs_icsb_modify_counters(xfs_mount, XFS_SBS_IFREE, ifreedelta, rsvd)
   - 如果xfs_trans->t_flags & XFS_TRANS_SB_DIRTY有效, 处理其他计数
   > xfs_mod_incore_sb_batch(xfs_mount, xfs_mod_sb, count, rsvd)

** xfs_trans_add_item(xfs_trans, xfs_log_item)
   - 把xfs_log_item放到xfs_trans管理中
   - 构造新的xfs_log_item_desc, 建立xfs_log_item_desc / xfs_log_item的对应关系
   - 把xfs_log_item_desc->lid_trans放到xlog_trans->t_items队列中
   - 通过xfs_log_item_desc把2者关联起来

** xfs_trans_free_item_desc(xfs_log_item_desc)
   - 释放xfs_log_item_desc->lid_trans队列, 释放它自己.

** xfs_trans_del_item(xfs_log_item)
   - 释放xfs_log_item->xfs_log_item_desc 
   > xfs_trans_free_item_desc(xfs_log_item->li_desc)
   
** xfs_trans_free_items(xfs_trans, xfs_lsn_t, flags)
   - 提交xfs_trans的xfs_log_item
   - 遍历xfs_trans->t_items队列上的xfs_log_item_desc，管理xfs_log_item
   - 如果xfs_lsn_t != NULLCOMMITLSN, 需要先commit
   > IOP_COMMITTING(xfs_log_item, xfs_lsn_t)
   - 如果flags & XFS_TRANS_ABORT, 设置xfs_log_item->li_flags的XFS_LI_ABORTED
   - 释放xfs_log_item中资源的锁, 什么地方锁住的??
   > IOP_UNLOCK(xfs_log_item)
   - 释放xfs_log_item_desc, 但没有释放xfs_log_item??
   > xfs_trans_free_item_desc(xfs_log_item_desc)

** xfs_log_item_batch_insert(xfs_ail, xfs_ail_cursor, xfs_log_item, nr_items, xfs_lsn_t)
   - xfs_log_item提交到xlog_in_core中,它就到xfs_ail中
   > xfs_trans_ail_update_bulk(xfs_ail, xfs_ail_cursor, xfs_log_item, nr_items, xfs_lsn_t)
   - 然后释放xfs_log_item的资源, 这时已经把数据写到ail中,所以不需要锁定原来的资源??
   - unpin操作是什么?? 
   - 遍历xfs_log_item
   > IOP_UNPIN(xfs_log_item, 0)

** xfs_trans_committed_bulk(xfs_ail, xfs_log_vec, xfs_lsn_t start_lsn, aborted)
   - 把xfs_log_vec链表插到AIL中, 在释放xfs_cil_ctx时使用.
   - 准备xfs_ail_cursor, 它用于遍历xfs_ail. 根据xfs_lsn_t找到对应的.
   > xfs_trans_ail_cursor_last(xfs_ail, xfs_ail_cursor, xfs_lsn_t start_lsn)
   - 遍历xfs_log_vec链表, 处理对应xfs_log_item
   - 如果参数aborted !=0, 设置xfs_log_item->li_flags的XFS_LI_ABORTED
   - 检查xfs_log_item是否在log中,获取对应的位置
   > xfs_log_item->xfs_log_ops->iop_committed(xfs_log_item, commit_lsn)
   - 如果item_lsn == -1,跳过这个xfs_log_item
   - 如果aborted !=0, 文件系统有严重错误, 检查xfs_mount->m_flags的XFS_MOUNT_FS_SHUTDOWN
   - 直接释放xfs_log_item的资源,继续循环
   > IOP_UNPIN(xfs_log_vec, 1)
   - 如果item_lsn != commit_lsn, 他们使用不同的xlog_in_core
   - 如果item_lsn > xfs_log_item->li_lsn, 直接把它加到ail队列中; 如果已经在xfs_ail中,会直接删除它
   > XFS_LSN_CMP(item_lsn, xfs_log_item->li_lsn)
   > xfs_trans_ail_update(xfs_ail, xfs_log_item, xfs_lsn_t)
   - 如果它的lsn和commit_lsn一样,暂存到一个数组中
   - 最后数组积累满了,一块提交
   > xfs_log_item_batch_insert(xfs_ail, xfs_ail_cursor, xfs_log_item, LOG_ITEM_BATCH_SIZE, commit_lsn)
   - 释放xfs_ail_cursor
   > xfs_trans_ail_cursor_done(xfs_ail, xfs_ail_cursor)
   - 这里把xfs_log_vec中的xfs_log_item放到xfs_ail的链表中

** xfs_trans_commit(xfs_trans, flags)
   - 提交xfs_trans给xfs_cil_ctx
   - flags&XFS_TRANS_RELEASE_LOG_RES表示永久释放xlog_ticket. ???
   - 如果 xfs_trans->t_flags & XFS_TRANS_DIRTY = 0, 表示没有可提交的,直接退出
   - xfs_trans->xlog_ticket 不能为 NULL, 它里面记录空间使用情况.
   - 如果xfs_trans->t_flags & XFS_TRANS_SB_DIRTY有效, 修改xfs_dsb计数, 并把对应的xfs_buf放到xfs_trans中
   - 那里修改xfs_sb? 和xfs_trans同时修改?
   > xfs_trans_apply_sb_deltas(xfs_trans)
   - dquots
   - xfs_trans_apply_dquot_deltas(xfs_trans)
   - 处理xfs_trans中的xfs_log_item_desc, 把它索引的xfs_log_item给xfs_cil->xc_cil队列
   > xfs_log_commit_cil(xfs_mount, xfs_trans, commit_lsn, flags)
   - 恢复current标志
   > current_restore_flags_nested(xfs_trans->t_pflags, PF_FSTRANS)
   - 释放xfs_trans
   > xfs_trans_free(xfs_trans)
   - 如果xfs_trans->t_flags & XFS_TRANS_SYNC有效, 需要把对应的xlog_in_core数据写回磁盘
   - 使用xfs_lsn_t刷新cil
   > _xfs_log_force_lsn(xfs_mount, commit_lsn, XFS_LOG_SYNC, NULL)

** 总结
   - commit xfs_trans, 只是把它的资源转移给xfs_cil_ctx
   - 转移之前为xfs_log_item准备好xfs_log_vec
   - 同时计算log的data使用的空间, 相应的减小xlog_ticket->t_curr_res
   - 把缓存的xfs_sb计数给xfs_dsb/xfs_sb
   - 最后释放xfs_trans的资源,包括reserve的fs空间, xlog_ticket reserve的log空间


** xfs_trans_cancel(xfs_trans, flags)
   - cancel xfs_trans, 释放xfs_trans的资源
   - 如果xfs_trans->t_flags没有XFS_TRANS_DIRTY,xfs_trans中没有修改? 去掉flags的XFS_TRANS_ABORT
   - 否则, 需要关闭xfs 
   > xfs_force_shutdown(xfs_mount, SHUTDOWN_CORRUPT_INCORE)
   - 释放xfs_trans reserve的空间和xfs_sb的计数缓存 
   > xfs_trans_unreserve_and_mod_sb(xfs_trans)
   - 如果flags有XFS_TRANS_RELEASE_LOG_RES, 强制释放xlog_ticket的空间, 否则根据xlog_ticket的情况而定
   > xfs_log_done(xfs_mount, xfs_trans->xlog_ticket, NULL, log_flags)
   - 恢复current状态  
   > current_restore_flags_nested(xfs_trans->t_pflags, PF_FSTRANS)
   - 释放xfs_log_item_desc
   - 这里传入的参数是NULLCOMMITLSN, 不会commit xfs_log_item, 但也没有释放xfs_log_item?
   > xfs_trans_free_items(xfs_trans, NULLCOMMITLSN, flags)
   - 释放自己
   > xfs_trans_free(xfs_trans)

** xfs_trans_roll(xfs_trans, xfs_inode)
   - log xfs_inode
   - 只是修改xfs_trans, xfs_inode->xfs_inode_log_item的标记, 并没有把xfs_log_item_desc放到xfs_trans中
   > xfs_trans_log_inode(xfs_trans, xfs_inode, XFS_INODE_CORE)
   - 复制xfs_trans, 继承reserve的fs空间和xlog_ticket
   > xfs_trans_dup(xfs_trans)
   - 提交原来的xfs_trans 
   > xfs_trans_commit(xfs_trans, 0)
   - 原来的xfs_trans已经释放, 对应的释放xlog_ticket的使用计数
   > xfs_log_ticket_put(xfs_trans->xlog_ticket)
   - 构造xfs_trans_res, 决定xlog_ticket使用的参数
   - xfs_trans_res(tr_logres, tr_logcount), xfs_trans(t_log_res, t_log_count), xlog_ticket(t_unit_res, t_cnt)
   - 设置xfs_trans_res->tr_logflags = XFS_TRANS_PERM_LOG_RES, 持续使用xlog_ticket??
   - 重新reserve log空间
   > xfs_trans_reserve(xfs_trans, xfs_trans_res, 0, 0)
   - 把xfs_inode的xfs_inode_log_item放到新的xfs_trans中
   > xfs_trans_ijoin(xfs_trans, xfs_inode, 0)

* xfs_trans_ail.c 

** 总结
   - xfs_ail管理的xfs_log_item是已经写到磁盘中的,但这些xfs_log_item还没有合并到磁盘的metadata中. 这时系统崩溃了,可以根据xlog的数据来回复
   - 这里和xfs_log_item有交互, 在释放时需要调用push操作
   - 这里提供给log接口,来释放log队列的数据. 只要xfs_log_item合并到磁盘的metadata,对应的log数据就能释放.
   - 这里提供给cil接口, 当xlog_in_core提交到磁盘时,它管理的xfs_log_item可以放到ail中.

** xfs_ail_check(xfs_ail, xfs_log_item)
   - 检查xfs_log_item的参数, xfs_log_item->li_flags有XFS_LI_IN_AIL
   - 表示xfs_log_item->li_ail在xfs_ail->xa_ail队列中
   - 而且xfs_log_item->li_lsn是有序的. 
   - xfs_log_item->li_lsn表示它所在的xlog_in_core的xlog_rec_header->h_lsn
   - 参数xfs_log_item->li_lsn必须在xfs_ail的xfs_log_item的链表的表头和表尾的xfs_lsn_t之间

** xfs_ail_min(xfs_ail)
   - 返回双链表的表头
   > list_first_entry(xfs_ail->xa_ail, xfs_log_item, li_ail)

** xfs_ail_max(xfs_ail)
   - 双链表的最后一个
   > list_entry(xfs_ail->xa_ail->prev, xfs_log_item, li_ail)

** xfs_ail_next(xfs_ail, xfs_log_item)
   - 如果它是链表最后一个,返回NULL
   - xfs_ail->xa_ail->prev == xfs_log_item->li_cil
  
** xfs_ail_min_lsn(xfs_ail)
   - 先获取双链表表头xfs_log_item, 返回xfs_log_item->li_lsn
   > xfs_ail_min(xfs_ail)
   - 如果没有xfs_log_item, 返回0

** xfs_ail_max_lsn(xfs_ail)
   - 返回最大的xfs_lsn_t
   > xfs_ail_max(xfs_ail)

** xfs_trans_ail_cursor_init(xfs_ail, xfs_ail_cursor)
   - 当xfs_ail_cursor使用时,把xfs_ail_cursor->list放到xfs_ail->xa_cursors链表中.
   - 在xfs_ail的xfs_log_item链表有变化时,需要让xfs_ail_cursor重新设置.
     
** xfs_trans_ail_cursor_next(xfs_ail, xfs_ail_cursor)
   - xfs_ail_cursor->xfs_log_item向后移动
   > xfs_ail_next(xfs_ail, xfs_log_item)
   - 如果xfs_ail_cursor->item & 1, 如果无效,它应该从头重新查找
   > xfs_ail_min(xfs_ail)

** xfs_trans_ail_cursor_done(xfs_ail, xfs_ail_cursor)
   - 释放xfs_ail_cursor->list队列

** xfs_trans_ail_cursor_clear(xfs_ail, xfs_log_item)
   - 使xfs_ail上指向xfs_log_item的xfs_ail_cursor无效.
   - 遍历xfs_ail->xa_cursors, 判断xfs_ali_cursor->item == xfs_log_item
   - 设置xfs_ail_cursor->xfs_log_item |= 1

** xfs_trans_ail_cursor_first(xfs_ail, xfs_ail_cursor, xfs_lsn_t)
   - 先初始化xfs_ail_cursor
   > xfs_trans_ail_cursor_init(xfs_ail, xfs_ail_cursor)
   - 根据xfs_lsn_t找一个xfs_log_item, 它是超过xfs_lsn_t最小的
   - 如果xfs_lsn_t是0，找整个队列最小的
   > xfs_ail_min(xfs_ail)
   - 遍历xfs_ail->xa_ail队列, 找到xfs_log_item->xfs_lsn_t >= 参数xfs_lsn_t
   - 使xfs_ail指向xfs_log_item
   > xfs_ail_next(xfs_ail, xfs_log_item)

** __xfs_trans_ail_cursor_last(xfs_ail, xfs_lsn_t)
   - 找到小于xfs_lsn_t的最大的xfs_log_item

** xfs_trans_ail_cursor_last(xfs_ail, xfs_ail_cursor, xfs_lsn_t)
   - 初始化xfs_ail_cursor->xfs_log_item
   > __xfs_trans_ail_cursor_last(xfs_ail, xfs_lsn_t)

** xfs_ail_splice(xfs_ail, xfs_ail_cursor, list_head, xfs_lsn_t)
   - 把list_head中的xfs_log_item放到xfs_ail->xa_ail队列中.
   - 插入操作要保证队列中xfs_lsn_t的顺序,先找到合适的位置.
   - 如果xfs_ail_cursor有效,而且xfs_ail_cursor->item & 1 = 0, 可以使用它指向的位置
   - 否则,根据xfs_lsn_t去xfs_ail->xa_ail中找一个合适的位置
   > __xfs_trans_ail_cursor_last(xfs_ail, xfs_lsn_t)
   - 如果xfs_ail->xa_ail队列为空,只能插入队头.
   - 更新xfs_ail_cursor->item, 它指向list_head最后一个元素.

** xfs_ail_delete(xfs_ail, xfs_log_item)
   - 从xfs_ail中释放xfs_log_item
   > xfs_ail_check(xfs_ail, xfs_log_item)
   > xfs_trans_ail_cursor_clear(xfs_ail, xfs_Log_item)

** xfsaild_push(xfs_ail)
   - xfs_ail中的xfs_log_item合并到文件系统, 它对应的log空间也可以释放.
   - 检查是否需要写当前使用的xfs_cil_ctx, xlog_in_core
   - xfs_ail->xa_log_flush != 0 表示上次刷新没有完成,因为pin,或其他原因
   - xfs_ail->xa_last_pushed_lsn == 0 表示ail上次没有操作完所有的xfs_log_item
   - xfs_ail->xa_buf_list队列不是空  表示有xfs_buf没有写回, 也是因为pin
   - xfs_ail_min_lsn(xfs_ail)   表示xfs_ail中有xfs_log_item
   - 同时满足上面4个条件,也就是需要写回
   - 设置xfs_ail->xa_log_flush = 0
   > xfs_log_force(xfs_mount, XFS_LOG_SYNC)

   - xfs_ail->xa_target是xfs_lsn_t, 它表示要释放的xfs_log_item.  target
   - 根据xfs_ail->xa_last_pushed_lsn找到对应的xfs_log_item, 并创建xfs_ail_cursor
   - 从上次遍历的地方开始处理
   > xfs_trans_ail_cursor_first(xfs_ail, xfs_ail_cursor, xfs_ail->xa_last_pushed_lsn)
   - 如果找不到,直接退出

   - 下面处理的xfs_log_item->xfs_lsn_t不能超过它xfs_ail->xa_target
   - 遍历xfs_ail->xa_ail队列, 停止条件是xfs_log_item->li_lsn >= target

   - push xfs_log_item, 针对不同的xfs_log_item,处理不同 
   - 同时收集释放的内存
   > xfs_log_item->xfs_item_ops->iop_push(xfs_log_item, xfs_ail->xa_buf_list)
   - 根据返回结果,继续处理
   - 如果是XFS_ITEM_SUCCESS, 设置xfs_ail->xa_last_pushed_lsn = xfs_log_item->li_lsn. 
   - 如果是XFS_ITEM_FLUSHING, flushing++,  同样设置xa_last_pushed_lsn
   - 如果是XFS_ITEM_PINNED,   stuck ++, xfs_ail->xa_log_flush ++, 被阻塞了
   - 如果是XFS_ITEM_LOCKED, stuck ++
   - 处理下一个xfs_log_item
   > xfs_trans_ail_cursor_next(xfs_ail, xfs_ail_cursor)
   - 如果stuck > 100, 停止循环, 被阻塞的太多

   - 最后处理xfs_ail->xa_buf_list 上面的xfs_buf, 写回磁盘中
   > xfs_buf_delwri_submit_nowait(xfs_ail->xa_buf_list)

   - 根据上面统计的检查,更新结果.
   - 如果lsn >= target, 或者上面没有处理xfs_log_item, 说明xfs_ail空了, 可以等待一段时间再提交IO, xfs_ail->xa_last_pushed_lsn = 0, 返回50. 下次扫描是从头开始,因为xa_last_pushed_lsn是0
   - 如果(flushing + stuck) / count > 90%, 也需要等待一段时间, 一些xfs_log_item不可用,  返回20, 设置xfs_ail->xa_last_pushed_lsn = 0, 下次从头开始扫描.
   - 否则返回10.

   - 这里只是push xfs_log_item, 并没有在xfs_ail中释放对应的xfs_log_item

** xfsaild(void) 
   - 循环调用上面的函数,写回ail中的xfs_log_item
   - 检查xfs_ail->xa_target == xfs_ail->xa_target_prev, 说明没有新的任务
   - xfs_ail_min(xfs_ail) == 0, 没有xfs_log_item可处理
   - 等待时间根据上面返回的值决定
   - 如果需要处理,调用上面的函数, 根据返回值等待
   > xfsaild_push(xfs_ail)
   - 在调度之前,把任务设为TASK_INTERRUPTIBLE状态

** xfs_ail_push(xfs_ail, xfs_lsn_t)
   - 启动xfsaild任务
   - 检查是否有xfs_log_item，如果没有就不用启动
   - xfs_ail_min(xfs_ail)
   - 如果参数xfs_lsn_t < xfs_ail->xa_target, 也不需要启动
   - xfsaild已经push了对应的xfs_log_item
   - 否则设置xfs_ail->xa_target = 参数xfs_lsn_t
   > xfs_trans_ail_copy_lsn(xfs_ail, xfs_ail->xa_target, threshold_lsn)
   - 唤醒xfsaild任务
   > wake_up_process(xfs_ail->xa_task

** xfs_ail_push_all(xfs_ail)
   - 把xfs_ail中所有xfs_log_item都push到log中.
   - 只需要选一个最大的xfs_lsn_t
   > xfs_ail_max(xfs_ail)
   - 调用上面的函数
   > xfs_ail_push(xfs_ail, threshold_lsn)

** xfs_ail_push_all_sync(xfs_ail)
   - 这里发起push操作后,在xfs_ail->xa_empty上等待
   - 这里循环操作, 停止条件是xfs_ail为空
   > xfs_ail_max(xfs_ail)
   - 准备等待
   > prepare_to_wait(xfs_ail->xa_empty, wait, TASK_UNINTERRUPTIBLE)
   - xfs_ail->xa_target = xfs_log_item->li_lsn
   > 唤醒xfsaild任务
   
** xfs_trans_ail_update_bulk(xfs_ail, xfs_ail_cursor, xfs_log_item, nr_items, xfs_lsn_t)
   - 处理多个xfs_log_item, 在第3个参数是xfs_log_item指针数组.
   - 遍历这些xfs_log_item, 放到xfs_ail管理中, 同时设置xfs_log_item->li_lsn = xfs_lsn_t
   - 如果xfs_log_item已经在xfs_ail队列中, xfs_log_item->li_flags 有XFS_LI_IN_AIL
   - 检查参数xfs_lsn_t <= xfs_log_item->li_lsn, xfs_log_item已经在log队列中, 而且数据更新
   - 否则要从队列中释放, 下面会更新它的li_lsn, 重新添加到队列中
   > xfs_ail_delete(xfs_ail, xfs_log_item)
   - 如果没有在xfs_ail中, 放到临时链表中
   - 循环完成后,把积累的xfs_log_item给xfs_ail->xa_ail链表
   > xfs_ail_splice(xfs_ail, xfs_ail_cursor, list_head, lsn)
   - 如果上面删除的xfs_log_item是xfs_ail中最小的
   > xfs_ail_min(xfs_ail)
   - log队列的尾指针可以向前移动,相当于释放了log空间
   - 修改xfs_mount->xlog->l_tail_lsn, 指向xfs_ail中最小的xfs_log_item->li_lsn
   > xfs_assign_tail_lsn_locked(xfs_ail->xa_mount)
   - 唤醒等待log空间的xfs_ticket, 唤醒xlog->l_write_head/l_reserve_head队列中的任务
   > xfs_log_space_wake(xfs_ail->xa_mount)

** xfs_trans_ail_delete_bulk(xfs_ail, xfs_log_item, nr_items, shutdown_type)
   - 删除参数数组中的xfs_log_item
   - 遍历这些xfs_log_item, xfs_log_item->li_flags & XFS_LI_IN_AIL必须有效.
   - 如果碰到无效的,错误退出.
   - 释放队列关系 
   > xfs_ail_delete(xfs_ail, xfs_log_item)
   - 去掉xfs_log_item->li_flags的XFS_LI_IN_AIL标志
   - 如果删除了第一个xfs_log_item, 还要修改xlog的变量
   > xlog_assign_tail_lsn_locked(xfs_ail->xa_mount)
   - 如果xfs_ail->xa_ail队列为空, 唤醒xfs_ail->xa_empty. 上面有任务在等待它
   - 唤醒等待xlog空间的任务
   > xfs_log_space_wake(xfs_ail->xfs_mount)

   - 应该是在unpin操作中,释放资源后,自动释放对应的xfs_log_item

** xfs_trans_ail_init(xfs_mount)
   - 初始化xfs_mount->xfs_ail, 这个也是全局的.
   - 启动线程

** xfs_trans_ail_destroy(xfs_mount)
   - 销毁xfs_mount->xfs_ail


* 总结
  - permanent的xlog_ticket是什么意思?
  - 如何区分xlog->l_write_head / xlog->l_reserve_head










